{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "class MissingEntryDataset(Dataset):\n",
    "    def __init__(self, data: torch.tensor, min_missing: float, max_missing: float):\n",
    "        self.data = data\n",
    "\n",
    "        n, d = data.shape\n",
    "        self.min_missing = min_missing\n",
    "        self.max_missing = max_missing\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        \n",
    "        prob = np.random.uniform(self.min_missing, self.max_missing)\n",
    "        mask = np.random.binomial(1, prob, sample.shape)\n",
    "        mask = torch.tensor(mask).bool()\n",
    "\n",
    "        return sample, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3784, 946)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"TCPA_data_sel.csv\")\n",
    "\n",
    "# select the 189 real valued columns only\n",
    "X = df.iloc[:, 2:].values.astype(\"float32\")\n",
    "Xs = (X - X.mean(axis=0)) / X.var(axis=0)\n",
    "\n",
    "# split train/test\n",
    "n = len(Xs)\n",
    "idx = np.arange(len(Xs))\n",
    "ncut = int(n * 0.8)\n",
    "Xtrain = MissingEntryDataset(torch.tensor(Xs[idx[:ncut]]), 0.1, 0.1)\n",
    "Xtest = MissingEntryDataset(torch.tensor(Xs[idx[ncut:]]), 0.1, 0.1)\n",
    "len(Xtrain), len(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (enc): Sequential(\n",
      "    (0): Linear(in_features=189, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mean): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (log_variance): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (dec): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=512, out_features=189, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, ins=189, hidden=512, latent=64, variational=True):\n",
    "        super(VAE, self).__init__()\n",
    "        self.variational = variational\n",
    "        \n",
    "        self.enc = nn.Sequential(nn.Linear(ins, hidden), \n",
    "                                nn.ReLU(),\n",
    "                                #nn.BatchNorm1d(hidden),\n",
    "                                #nn.Linear(hidden, hidden),\n",
    "                                #nn.ReLU(),\n",
    "                                nn.BatchNorm1d(hidden))\n",
    "        \n",
    "        self.mean = nn.Linear(hidden, latent)\n",
    "        self.log_variance = nn.Linear(hidden, latent)\n",
    "        \n",
    "        self.dec = nn.Sequential(nn.Linear(latent, hidden),\n",
    "                                nn.ReLU(),\n",
    "                                #nn.BatchNorm1d(hidden),\n",
    "                                #nn.Linear(hidden, hidden),\n",
    "                                #nn.ReLU(),\n",
    "                                nn.BatchNorm1d(hidden),\n",
    "                                nn.Linear(hidden, ins))\n",
    "\n",
    "    def sample(self, mean, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu = self.mean(x)\n",
    "        log_var = self.log_variance(x)\n",
    "        z = self.sample(mu, log_var) if self.variational else mu\n",
    "        x = self.dec(z)\n",
    "        return x, mu, log_var\n",
    "    \n",
    "    def gibbs(self, x0, mask):\n",
    "        # initalize unobserved (masked out) with random entries\n",
    "        xn = x0[:]\n",
    "        xn[mask] = torch.randn(mask.shape)[mask]\n",
    "        # iterativly predict\n",
    "        for _ in range(20):\n",
    "            # reconstruction step\n",
    "            xn,_,_ = self.forward(xn)\n",
    "            # reset observed values\n",
    "            xn[~mask] = x0[~mask]\n",
    "        return xn\n",
    "    \n",
    "vae = VAE(hidden=512, latent=64, variational=True)\n",
    "print(vae)\n",
    "assert vae(torch.tensor(np.random.randn(20, 189).astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.0001)\n",
    "\n",
    "def train(epoch):\n",
    "    sample, mask = Xtrain[:]\n",
    "    reconstruction = sample[:]\n",
    "    reconstruction[mask] = torch.randn(mask.shape)[mask]\n",
    "    for n in range(10):\n",
    "        vae.train()\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction, mu, log_var = vae(reconstruction)\n",
    "        mse = F.mse_loss(reconstruction[mask], sample[mask], reduction=\"sum\")\n",
    "        kl = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = mse + 1 * kl  # set to 1 for variational regularization (centered gaussian)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Train Epoch {epoch}.{n}\", \n",
    "              f\"var loss {loss.item()}\", \n",
    "              f\"reconstruction mse {mse.item()}\",\n",
    "              f\"imputation mse {F.mse_loss(reconstruction[mask], sample[mask], reduction='mean')}\")\n",
    "        reconstruction = reconstruction.detach() # drop previous computation graph before going into next iter\n",
    "    \n",
    "def test():\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        sample, mask = Xtest[:]\n",
    "        reconstruction = vae.gibbs(sample, mask)   \n",
    "        test_loss = F.mse_loss(reconstruction[mask], sample[mask], reduction=\"mean\").item()\n",
    "    print('====> Test imputation mse: {:.8f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test imputation mse: 1.01799130\n",
      "====> Test imputation mse: 1.01581061\n",
      "====> Test imputation mse: 1.01678932\n",
      "Train Epoch 1.0 var loss 71933.34375 reconstruction mse 71746.5 imputation mse 0.9986845850944519\n",
      "Train Epoch 1.1 var loss 71865.53125 reconstruction mse 71821.2421875 imputation mse 0.9997249841690063\n",
      "Train Epoch 1.2 var loss 71783.0390625 reconstruction mse 71746.8359375 imputation mse 0.9986892938613892\n",
      "Train Epoch 1.3 var loss 71735.7890625 reconstruction mse 71706.3046875 imputation mse 0.9981250762939453\n",
      "Train Epoch 1.4 var loss 71832.6796875 reconstruction mse 71807.4296875 imputation mse 0.9995326995849609\n",
      "Train Epoch 1.5 var loss 71751.8671875 reconstruction mse 71728.625 imputation mse 0.9984357953071594\n",
      "Train Epoch 1.6 var loss 71800.0703125 reconstruction mse 71777.5078125 imputation mse 0.9991162419319153\n",
      "Train Epoch 1.7 var loss 71786.09375 reconstruction mse 71763.6328125 imputation mse 0.9989230632781982\n",
      "Train Epoch 1.8 var loss 71729.6171875 reconstruction mse 71707.203125 imputation mse 0.9981375932693481\n",
      "Train Epoch 1.9 var loss 71727.7578125 reconstruction mse 71705.4296875 imputation mse 0.9981129169464111\n",
      "Train Epoch 2.0 var loss 72756.921875 reconstruction mse 72592.4375 imputation mse 1.008060336112976\n",
      "Train Epoch 2.1 var loss 72461.8671875 reconstruction mse 72440.328125 imputation mse 1.0059480667114258\n",
      "Train Epoch 2.2 var loss 72571.25 reconstruction mse 72550.484375 imputation mse 1.0074777603149414\n",
      "Train Epoch 2.3 var loss 72494.390625 reconstruction mse 72474.8046875 imputation mse 1.0064268112182617\n",
      "Train Epoch 2.4 var loss 72514.0859375 reconstruction mse 72495.75 imputation mse 1.0067176818847656\n",
      "Train Epoch 2.5 var loss 72560.703125 reconstruction mse 72543.3984375 imputation mse 1.0073792934417725\n",
      "Train Epoch 2.6 var loss 72445.984375 reconstruction mse 72429.640625 imputation mse 1.005799651145935\n",
      "Train Epoch 2.7 var loss 72455.5859375 reconstruction mse 72439.8671875 imputation mse 1.00594162940979\n",
      "Train Epoch 2.8 var loss 72573.7890625 reconstruction mse 72558.4609375 imputation mse 1.007588505744934\n",
      "Train Epoch 2.9 var loss 72498.7265625 reconstruction mse 72483.71875 imputation mse 1.0065505504608154\n",
      "Train Epoch 3.0 var loss 71464.109375 reconstruction mse 71308.875 imputation mse 0.9997318983078003\n",
      "Train Epoch 3.1 var loss 71369.9140625 reconstruction mse 71354.921875 imputation mse 1.0003774166107178\n",
      "Train Epoch 3.2 var loss 71260.5703125 reconstruction mse 71245.421875 imputation mse 0.9988422989845276\n",
      "Train Epoch 3.3 var loss 71195.390625 reconstruction mse 71180.5703125 imputation mse 0.9979330897331238\n",
      "Train Epoch 3.4 var loss 71231.1953125 reconstruction mse 71216.8203125 imputation mse 0.9984412789344788\n",
      "Train Epoch 3.5 var loss 71228.8828125 reconstruction mse 71214.9765625 imputation mse 0.998415470123291\n",
      "Train Epoch 3.6 var loss 71212.078125 reconstruction mse 71198.78125 imputation mse 0.9981883764266968\n",
      "Train Epoch 3.7 var loss 71321.5390625 reconstruction mse 71308.8203125 imputation mse 0.9997311234474182\n",
      "Train Epoch 3.8 var loss 71199.0234375 reconstruction mse 71186.7890625 imputation mse 0.9980202317237854\n",
      "Train Epoch 3.9 var loss 71273.6953125 reconstruction mse 71261.8671875 imputation mse 0.9990728497505188\n",
      "Train Epoch 4.0 var loss 71747.59375 reconstruction mse 71598.609375 imputation mse 1.0040754079818726\n",
      "Train Epoch 4.1 var loss 71607.8984375 reconstruction mse 71596.125 imputation mse 1.0040405988693237\n",
      "Train Epoch 4.2 var loss 71421.1875 reconstruction mse 71409.3984375 imputation mse 1.0014219284057617\n",
      "Train Epoch 4.3 var loss 71617.6484375 reconstruction mse 71605.8984375 imputation mse 1.0041776895523071\n",
      "Train Epoch 4.4 var loss 71516.75 reconstruction mse 71505.1015625 imputation mse 1.002764105796814\n",
      "Train Epoch 4.5 var loss 71598.4609375 reconstruction mse 71587.1875 imputation mse 1.0039151906967163\n",
      "Train Epoch 4.6 var loss 71519.4296875 reconstruction mse 71508.4453125 imputation mse 1.0028109550476074\n",
      "Train Epoch 4.7 var loss 71616.078125 reconstruction mse 71605.4375 imputation mse 1.0041711330413818\n",
      "Train Epoch 4.8 var loss 71522.640625 reconstruction mse 71512.3125 imputation mse 1.002865195274353\n",
      "Train Epoch 4.9 var loss 71529.328125 reconstruction mse 71519.21875 imputation mse 1.0029621124267578\n",
      "Train Epoch 5.0 var loss 72455.3203125 reconstruction mse 72310.6171875 imputation mse 1.0135060548782349\n",
      "Train Epoch 5.1 var loss 72342.765625 reconstruction mse 72332.640625 imputation mse 1.0138146877288818\n",
      "Train Epoch 5.2 var loss 72284.4609375 reconstruction mse 72274.171875 imputation mse 1.0129952430725098\n",
      "Train Epoch 5.3 var loss 72204.140625 reconstruction mse 72193.8828125 imputation mse 1.0118699073791504\n",
      "Train Epoch 5.4 var loss 72330.4296875 reconstruction mse 72320.21875 imputation mse 1.0136406421661377\n",
      "Train Epoch 5.5 var loss 72260.5078125 reconstruction mse 72250.4453125 imputation mse 1.012662649154663\n",
      "Train Epoch 5.6 var loss 72231.0546875 reconstruction mse 72221.1875 imputation mse 1.0122525691986084\n",
      "Train Epoch 5.7 var loss 72182.9375 reconstruction mse 72173.3671875 imputation mse 1.011582374572754\n",
      "Train Epoch 5.8 var loss 72288.28125 reconstruction mse 72278.875 imputation mse 1.0130611658096313\n",
      "Train Epoch 5.9 var loss 72287.9296875 reconstruction mse 72278.7421875 imputation mse 1.0130592584609985\n",
      "Train Epoch 6.0 var loss 72440.421875 reconstruction mse 72299.96875 imputation mse 1.0112025737762451\n",
      "Train Epoch 6.1 var loss 72317.8359375 reconstruction mse 72308.703125 imputation mse 1.0113246440887451\n",
      "Train Epoch 6.2 var loss 72310.5390625 reconstruction mse 72301.375 imputation mse 1.011222243309021\n",
      "Train Epoch 6.3 var loss 72289.046875 reconstruction mse 72279.9765625 imputation mse 1.010922908782959\n",
      "Train Epoch 6.4 var loss 72312.0703125 reconstruction mse 72303.09375 imputation mse 1.0112462043762207\n",
      "Train Epoch 6.5 var loss 72309.484375 reconstruction mse 72300.6953125 imputation mse 1.011212706565857\n",
      "Train Epoch 6.6 var loss 72255.3671875 reconstruction mse 72246.7734375 imputation mse 1.0104584693908691\n",
      "Train Epoch 6.7 var loss 72261.0859375 reconstruction mse 72252.6171875 imputation mse 1.010540246963501\n",
      "Train Epoch 6.8 var loss 72218.7734375 reconstruction mse 72210.453125 imputation mse 1.0099505186080933\n",
      "Train Epoch 6.9 var loss 72365.515625 reconstruction mse 72357.28125 imputation mse 1.0120041370391846\n",
      "Train Epoch 7.0 var loss 72673.375 reconstruction mse 72535.625 imputation mse 1.010189175605774\n",
      "Train Epoch 7.1 var loss 72572.875 reconstruction mse 72564.5078125 imputation mse 1.0105913877487183\n",
      "Train Epoch 7.2 var loss 72542.4140625 reconstruction mse 72533.9453125 imputation mse 1.010165810585022\n",
      "Train Epoch 7.3 var loss 72430.6484375 reconstruction mse 72422.2109375 imputation mse 1.008609652519226\n",
      "Train Epoch 7.4 var loss 72458.6171875 reconstruction mse 72450.296875 imputation mse 1.0090008974075317\n",
      "Train Epoch 7.5 var loss 72574.5625 reconstruction mse 72566.3125 imputation mse 1.0106165409088135\n",
      "Train Epoch 7.6 var loss 72483.6015625 reconstruction mse 72475.3828125 imputation mse 1.0093501806259155\n",
      "Train Epoch 7.7 var loss 72436.671875 reconstruction mse 72428.6171875 imputation mse 1.0086989402770996\n",
      "Train Epoch 7.8 var loss 72499.53125 reconstruction mse 72491.5390625 imputation mse 1.0095752477645874\n",
      "Train Epoch 7.9 var loss 72492.5703125 reconstruction mse 72484.6484375 imputation mse 1.009479284286499\n",
      "Train Epoch 8.0 var loss 71981.0859375 reconstruction mse 71846.7109375 imputation mse 1.0079928636550903\n",
      "Train Epoch 8.1 var loss 71871.0078125 reconstruction mse 71862.984375 imputation mse 1.0082212686538696\n",
      "Train Epoch 8.2 var loss 71921.8046875 reconstruction mse 71913.6484375 imputation mse 1.0089319944381714\n",
      "Train Epoch 8.3 var loss 71870.5 reconstruction mse 71862.34375 imputation mse 1.0082122087478638\n",
      "Train Epoch 8.4 var loss 71858.75 reconstruction mse 71850.5859375 imputation mse 1.0080472230911255\n",
      "Train Epoch 8.5 var loss 71847.4921875 reconstruction mse 71839.4296875 imputation mse 1.0078907012939453\n",
      "Train Epoch 8.6 var loss 71866.8046875 reconstruction mse 71858.828125 imputation mse 1.0081628561019897\n",
      "Train Epoch 8.7 var loss 71867.2578125 reconstruction mse 71859.4609375 imputation mse 1.008171796798706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 8.8 var loss 71805.1484375 reconstruction mse 71797.5234375 imputation mse 1.0073028802871704\n",
      "Train Epoch 8.9 var loss 71847.4296875 reconstruction mse 71839.8984375 imputation mse 1.0078973770141602\n",
      "Train Epoch 9.0 var loss 72218.3125 reconstruction mse 72086.8125 imputation mse 1.0044842958450317\n",
      "Train Epoch 9.1 var loss 72155.421875 reconstruction mse 72147.9453125 imputation mse 1.005336046218872\n",
      "Train Epoch 9.2 var loss 72055.546875 reconstruction mse 72047.96875 imputation mse 1.0039429664611816\n",
      "Train Epoch 9.3 var loss 72107.484375 reconstruction mse 72099.8984375 imputation mse 1.0046665668487549\n",
      "Train Epoch 9.4 var loss 72108.6796875 reconstruction mse 72101.15625 imputation mse 1.0046840906143188\n",
      "Train Epoch 9.5 var loss 72080.7421875 reconstruction mse 72073.2265625 imputation mse 1.004294991493225\n",
      "Train Epoch 9.6 var loss 72099.1953125 reconstruction mse 72091.7734375 imputation mse 1.0045534372329712\n",
      "Train Epoch 9.7 var loss 72035.9375 reconstruction mse 72028.5859375 imputation mse 1.0036729574203491\n",
      "Train Epoch 9.8 var loss 72074.5390625 reconstruction mse 72067.265625 imputation mse 1.0042119026184082\n",
      "Train Epoch 9.9 var loss 72070.46875 reconstruction mse 72063.203125 imputation mse 1.0041552782058716\n",
      "Train Epoch 10.0 var loss 71997.28125 reconstruction mse 71868.1328125 imputation mse 1.0007258653640747\n",
      "Train Epoch 10.1 var loss 71866.0 reconstruction mse 71858.640625 imputation mse 1.0005937814712524\n",
      "Train Epoch 10.2 var loss 71834.3671875 reconstruction mse 71826.90625 imputation mse 1.0001518726348877\n",
      "Train Epoch 10.3 var loss 71879.4453125 reconstruction mse 71871.953125 imputation mse 1.000779151916504\n",
      "Train Epoch 10.4 var loss 71815.078125 reconstruction mse 71807.65625 imputation mse 0.9998838305473328\n",
      "Train Epoch 10.5 var loss 71912.25 reconstruction mse 71904.8671875 imputation mse 1.001237392425537\n",
      "Train Epoch 10.6 var loss 71823.046875 reconstruction mse 71815.75 imputation mse 0.999996542930603\n",
      "Train Epoch 10.7 var loss 71872.5546875 reconstruction mse 71865.3984375 imputation mse 1.000687837600708\n",
      "Train Epoch 10.8 var loss 71867.203125 reconstruction mse 71860.15625 imputation mse 1.000614881515503\n",
      "Train Epoch 10.9 var loss 71899.1953125 reconstruction mse 71892.3046875 imputation mse 1.0010625123977661\n",
      "====> Test imputation mse: 0.99545366\n",
      "====> Test imputation mse: 0.98660845\n",
      "====> Test imputation mse: 1.00866473\n",
      "Train Epoch 11.0 var loss 71112.6640625 reconstruction mse 70986.4140625 imputation mse 0.9964404106140137\n",
      "Train Epoch 11.1 var loss 70980.3203125 reconstruction mse 70973.328125 imputation mse 0.9962567090988159\n",
      "Train Epoch 11.2 var loss 71008.453125 reconstruction mse 71001.390625 imputation mse 0.9966506361961365\n",
      "Train Epoch 11.3 var loss 70992.6484375 reconstruction mse 70985.5859375 imputation mse 0.9964287877082825\n",
      "Train Epoch 11.4 var loss 71014.34375 reconstruction mse 71007.3125 imputation mse 0.9967337250709534\n",
      "Train Epoch 11.5 var loss 71040.671875 reconstruction mse 71033.7109375 imputation mse 0.997104287147522\n",
      "Train Epoch 11.6 var loss 70990.3671875 reconstruction mse 70983.546875 imputation mse 0.9964001774787903\n",
      "Train Epoch 11.7 var loss 71001.03125 reconstruction mse 70994.2421875 imputation mse 0.9965502619743347\n",
      "Train Epoch 11.8 var loss 71006.1015625 reconstruction mse 70999.4140625 imputation mse 0.9966228604316711\n",
      "Train Epoch 11.9 var loss 70948.9921875 reconstruction mse 70942.359375 imputation mse 0.995822012424469\n",
      "Train Epoch 12.0 var loss 71866.78125 reconstruction mse 71742.625 imputation mse 1.0030145645141602\n",
      "Train Epoch 12.1 var loss 71740.7265625 reconstruction mse 71733.9921875 imputation mse 1.0028939247131348\n",
      "Train Epoch 12.2 var loss 71766.7890625 reconstruction mse 71759.921875 imputation mse 1.0032564401626587\n",
      "Train Epoch 12.3 var loss 71767.71875 reconstruction mse 71760.8359375 imputation mse 1.0032691955566406\n",
      "Train Epoch 12.4 var loss 71735.90625 reconstruction mse 71729.0390625 imputation mse 1.0028246641159058\n",
      "Train Epoch 12.5 var loss 71709.6875 reconstruction mse 71702.9375 imputation mse 1.0024597644805908\n",
      "Train Epoch 12.6 var loss 71706.8671875 reconstruction mse 71700.1875 imputation mse 1.002421259880066\n",
      "Train Epoch 12.7 var loss 71722.5703125 reconstruction mse 71715.953125 imputation mse 1.0026416778564453\n",
      "Train Epoch 12.8 var loss 71722.46875 reconstruction mse 71715.90625 imputation mse 1.0026410818099976\n",
      "Train Epoch 12.9 var loss 71694.3359375 reconstruction mse 71687.78125 imputation mse 1.0022478103637695\n",
      "Train Epoch 13.0 var loss 72238.921875 reconstruction mse 72116.9375 imputation mse 0.9999713897705078\n",
      "Train Epoch 13.1 var loss 72189.296875 reconstruction mse 72182.59375 imputation mse 1.0008817911148071\n",
      "Train Epoch 13.2 var loss 72166.265625 reconstruction mse 72159.46875 imputation mse 1.0005611181259155\n",
      "Train Epoch 13.3 var loss 72119.0546875 reconstruction mse 72112.1953125 imputation mse 0.9999056458473206\n",
      "Train Epoch 13.4 var loss 72167.84375 reconstruction mse 72161.0546875 imputation mse 1.0005831718444824\n",
      "Train Epoch 13.5 var loss 72109.9609375 reconstruction mse 72103.1953125 imputation mse 0.9997808337211609\n",
      "Train Epoch 13.6 var loss 72164.6796875 reconstruction mse 72158.0234375 imputation mse 1.000541090965271\n",
      "Train Epoch 13.7 var loss 72175.0625 reconstruction mse 72168.4296875 imputation mse 1.0006853342056274\n",
      "Train Epoch 13.8 var loss 72200.390625 reconstruction mse 72193.75 imputation mse 1.001036524772644\n",
      "Train Epoch 13.9 var loss 72112.3515625 reconstruction mse 72105.734375 imputation mse 0.9998160600662231\n",
      "Train Epoch 14.0 var loss 71149.6875 reconstruction mse 71030.03125 imputation mse 0.9954875707626343\n",
      "Train Epoch 14.1 var loss 71050.921875 reconstruction mse 71044.1796875 imputation mse 0.995685875415802\n",
      "Train Epoch 14.2 var loss 71024.078125 reconstruction mse 71017.2890625 imputation mse 0.9953089952468872\n",
      "Train Epoch 14.3 var loss 71083.9609375 reconstruction mse 71077.125 imputation mse 0.996147632598877\n",
      "Train Epoch 14.4 var loss 71055.7734375 reconstruction mse 71048.9296875 imputation mse 0.9957524538040161\n",
      "Train Epoch 14.5 var loss 71031.3828125 reconstruction mse 71024.609375 imputation mse 0.9954116344451904\n",
      "Train Epoch 14.6 var loss 71071.5703125 reconstruction mse 71064.828125 imputation mse 0.9959752559661865\n",
      "Train Epoch 14.7 var loss 71071.796875 reconstruction mse 71065.1640625 imputation mse 0.9959799647331238\n",
      "Train Epoch 14.8 var loss 71098.546875 reconstruction mse 71092.015625 imputation mse 0.9963563084602356\n",
      "Train Epoch 14.9 var loss 71014.3203125 reconstruction mse 71007.859375 imputation mse 0.9951768517494202\n",
      "Train Epoch 15.0 var loss 71829.359375 reconstruction mse 71711.734375 imputation mse 1.0030595064163208\n",
      "Train Epoch 15.1 var loss 71781.7421875 reconstruction mse 71775.109375 imputation mse 1.0039459466934204\n",
      "Train Epoch 15.2 var loss 71745.1328125 reconstruction mse 71738.453125 imputation mse 1.0034332275390625\n",
      "Train Epoch 15.3 var loss 71689.640625 reconstruction mse 71682.875 imputation mse 1.0026558637619019\n",
      "Train Epoch 15.4 var loss 71770.5390625 reconstruction mse 71763.7578125 imputation mse 1.0037871599197388\n",
      "Train Epoch 15.5 var loss 71715.828125 reconstruction mse 71709.1015625 imputation mse 1.0030226707458496\n",
      "Train Epoch 15.6 var loss 71726.75 reconstruction mse 71720.125 imputation mse 1.0031769275665283\n",
      "Train Epoch 15.7 var loss 71691.984375 reconstruction mse 71685.3984375 imputation mse 1.0026911497116089\n",
      "Train Epoch 15.8 var loss 71716.7890625 reconstruction mse 71710.2734375 imputation mse 1.0030391216278076\n",
      "Train Epoch 15.9 var loss 71711.390625 reconstruction mse 71704.9453125 imputation mse 1.0029646158218384\n",
      "Train Epoch 16.0 var loss 71764.0 reconstruction mse 71647.578125 imputation mse 1.001769781112671\n",
      "Train Epoch 16.1 var loss 71651.9296875 reconstruction mse 71645.4765625 imputation mse 1.0017404556274414\n",
      "Train Epoch 16.2 var loss 71634.1640625 reconstruction mse 71627.6484375 imputation mse 1.0014911890029907\n",
      "Train Epoch 16.3 var loss 71653.3671875 reconstruction mse 71646.828125 imputation mse 1.0017592906951904\n",
      "Train Epoch 16.4 var loss 71680.2421875 reconstruction mse 71673.765625 imputation mse 1.002135992050171\n",
      "Train Epoch 16.5 var loss 71614.953125 reconstruction mse 71608.4921875 imputation mse 1.0012233257293701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 16.6 var loss 71636.9921875 reconstruction mse 71630.59375 imputation mse 1.0015323162078857\n",
      "Train Epoch 16.7 var loss 71668.3828125 reconstruction mse 71662.1015625 imputation mse 1.0019729137420654\n",
      "Train Epoch 16.8 var loss 71670.8671875 reconstruction mse 71664.65625 imputation mse 1.0020085573196411\n",
      "Train Epoch 16.9 var loss 71644.625 reconstruction mse 71638.3984375 imputation mse 1.0016415119171143\n",
      "Train Epoch 17.0 var loss 72548.0078125 reconstruction mse 72434.4296875 imputation mse 1.010468602180481\n",
      "Train Epoch 17.1 var loss 72404.265625 reconstruction mse 72397.875 imputation mse 1.0099586248397827\n",
      "Train Epoch 17.2 var loss 72439.0 reconstruction mse 72432.53125 imputation mse 1.0104421377182007\n",
      "Train Epoch 17.3 var loss 72341.625 reconstruction mse 72335.109375 imputation mse 1.0090830326080322\n",
      "Train Epoch 17.4 var loss 72374.171875 reconstruction mse 72367.609375 imputation mse 1.0095363855361938\n",
      "Train Epoch 17.5 var loss 72428.6796875 reconstruction mse 72422.1484375 imputation mse 1.0102972984313965\n",
      "Train Epoch 17.6 var loss 72390.1171875 reconstruction mse 72383.6953125 imputation mse 1.009760856628418\n",
      "Train Epoch 17.7 var loss 72364.84375 reconstruction mse 72358.453125 imputation mse 1.009408712387085\n",
      "Train Epoch 17.8 var loss 72346.9453125 reconstruction mse 72340.6484375 imputation mse 1.0091602802276611\n",
      "Train Epoch 17.9 var loss 72381.5859375 reconstruction mse 72375.328125 imputation mse 1.0096441507339478\n",
      "Train Epoch 18.0 var loss 71746.578125 reconstruction mse 71635.59375 imputation mse 0.9993526339530945\n",
      "Train Epoch 18.1 var loss 71708.4140625 reconstruction mse 71702.0546875 imputation mse 1.0002797842025757\n",
      "Train Epoch 18.2 var loss 71673.25 reconstruction mse 71666.859375 imputation mse 0.999788761138916\n",
      "Train Epoch 18.3 var loss 71697.890625 reconstruction mse 71691.5 imputation mse 1.0001325607299805\n",
      "Train Epoch 18.4 var loss 71653.8046875 reconstruction mse 71647.390625 imputation mse 0.9995172023773193\n",
      "Train Epoch 18.5 var loss 71686.78125 reconstruction mse 71680.3515625 imputation mse 0.9999769926071167\n",
      "Train Epoch 18.6 var loss 71722.515625 reconstruction mse 71716.171875 imputation mse 1.0004767179489136\n",
      "Train Epoch 18.7 var loss 71665.5859375 reconstruction mse 71659.3203125 imputation mse 0.9996836185455322\n",
      "Train Epoch 18.8 var loss 71659.25 reconstruction mse 71653.0234375 imputation mse 0.9995957612991333\n",
      "Train Epoch 18.9 var loss 71633.4140625 reconstruction mse 71627.21875 imputation mse 0.9992357492446899\n",
      "Train Epoch 19.0 var loss 72168.953125 reconstruction mse 72059.2890625 imputation mse 1.0119123458862305\n",
      "Train Epoch 19.1 var loss 72140.546875 reconstruction mse 72134.296875 imputation mse 1.0129656791687012\n",
      "Train Epoch 19.2 var loss 72077.84375 reconstruction mse 72071.546875 imputation mse 1.0120844841003418\n",
      "Train Epoch 19.3 var loss 72060.828125 reconstruction mse 72054.4453125 imputation mse 1.011844277381897\n",
      "Train Epoch 19.4 var loss 72112.0546875 reconstruction mse 72105.7265625 imputation mse 1.0125644207000732\n",
      "Train Epoch 19.5 var loss 72020.890625 reconstruction mse 72014.5390625 imputation mse 1.0112838745117188\n",
      "Train Epoch 19.6 var loss 72053.4453125 reconstruction mse 72047.1328125 imputation mse 1.0117416381835938\n",
      "Train Epoch 19.7 var loss 72039.5703125 reconstruction mse 72033.3359375 imputation mse 1.0115479230880737\n",
      "Train Epoch 19.8 var loss 72055.1640625 reconstruction mse 72048.9609375 imputation mse 1.0117672681808472\n",
      "Train Epoch 19.9 var loss 72096.2578125 reconstruction mse 72090.1171875 imputation mse 1.0123451948165894\n",
      "Train Epoch 20.0 var loss 71823.5703125 reconstruction mse 71715.8359375 imputation mse 0.9995238184928894\n",
      "Train Epoch 20.1 var loss 71648.53125 reconstruction mse 71642.2421875 imputation mse 0.9984981417655945\n",
      "Train Epoch 20.2 var loss 71678.4140625 reconstruction mse 71672.0 imputation mse 0.9989128708839417\n",
      "Train Epoch 20.3 var loss 71670.8046875 reconstruction mse 71664.3125 imputation mse 0.9988057613372803\n",
      "Train Epoch 20.4 var loss 71656.21875 reconstruction mse 71649.6953125 imputation mse 0.998602032661438\n",
      "Train Epoch 20.5 var loss 71618.71875 reconstruction mse 71612.25 imputation mse 0.9980801343917847\n",
      "Train Epoch 20.6 var loss 71672.2890625 reconstruction mse 71665.859375 imputation mse 0.9988272786140442\n",
      "Train Epoch 20.7 var loss 71689.7265625 reconstruction mse 71683.3203125 imputation mse 0.9990706443786621\n",
      "Train Epoch 20.8 var loss 71716.65625 reconstruction mse 71710.4296875 imputation mse 0.9994484782218933\n",
      "Train Epoch 20.9 var loss 71678.8046875 reconstruction mse 71672.71875 imputation mse 0.9989228844642639\n",
      "====> Test imputation mse: 0.99863279\n",
      "====> Test imputation mse: 1.00371337\n",
      "====> Test imputation mse: 1.01540005\n",
      "Train Epoch 21.0 var loss 71512.671875 reconstruction mse 71406.8984375 imputation mse 1.0015976428985596\n",
      "Train Epoch 21.1 var loss 71440.2734375 reconstruction mse 71434.1015625 imputation mse 1.0019792318344116\n",
      "Train Epoch 21.2 var loss 71479.609375 reconstruction mse 71473.3515625 imputation mse 1.0025297403335571\n",
      "Train Epoch 21.3 var loss 71421.28125 reconstruction mse 71414.9765625 imputation mse 1.0017108917236328\n",
      "Train Epoch 21.4 var loss 71371.84375 reconstruction mse 71365.5390625 imputation mse 1.001017451286316\n",
      "Train Epoch 21.5 var loss 71438.8203125 reconstruction mse 71432.546875 imputation mse 1.0019574165344238\n",
      "Train Epoch 21.6 var loss 71411.7578125 reconstruction mse 71405.5703125 imputation mse 1.0015789270401\n",
      "Train Epoch 21.7 var loss 71454.1328125 reconstruction mse 71448.015625 imputation mse 1.0021743774414062\n",
      "Train Epoch 21.8 var loss 71406.8203125 reconstruction mse 71400.7421875 imputation mse 1.0015112161636353\n",
      "Train Epoch 21.9 var loss 71413.0625 reconstruction mse 71407.0546875 imputation mse 1.0015997886657715\n",
      "Train Epoch 22.0 var loss 71985.3203125 reconstruction mse 71880.90625 imputation mse 1.0044844150543213\n",
      "Train Epoch 22.1 var loss 71910.6796875 reconstruction mse 71904.6484375 imputation mse 1.0048161745071411\n",
      "Train Epoch 22.2 var loss 71891.6484375 reconstruction mse 71885.5390625 imputation mse 1.0045491456985474\n",
      "Train Epoch 22.3 var loss 71868.328125 reconstruction mse 71862.2109375 imputation mse 1.0042232275009155\n",
      "Train Epoch 22.4 var loss 71840.8125 reconstruction mse 71834.7109375 imputation mse 1.0038388967514038\n",
      "Train Epoch 22.5 var loss 71934.7421875 reconstruction mse 71928.6015625 imputation mse 1.0051509141921997\n",
      "Train Epoch 22.6 var loss 71881.421875 reconstruction mse 71875.2734375 imputation mse 1.0044057369232178\n",
      "Train Epoch 22.7 var loss 71876.2890625 reconstruction mse 71870.1953125 imputation mse 1.004334807395935\n",
      "Train Epoch 22.8 var loss 71923.546875 reconstruction mse 71917.4375 imputation mse 1.0049949884414673\n",
      "Train Epoch 22.9 var loss 71833.9375 reconstruction mse 71827.8359375 imputation mse 1.0037428140640259\n",
      "Train Epoch 23.0 var loss 72269.59375 reconstruction mse 72167.6875 imputation mse 1.0100305080413818\n",
      "Train Epoch 23.1 var loss 72138.3203125 reconstruction mse 72132.1328125 imputation mse 1.0095328092575073\n",
      "Train Epoch 23.2 var loss 72158.2734375 reconstruction mse 72152.046875 imputation mse 1.009811520576477\n",
      "Train Epoch 23.3 var loss 72155.0 reconstruction mse 72148.7578125 imputation mse 1.0097655057907104\n",
      "Train Epoch 23.4 var loss 72075.6484375 reconstruction mse 72069.40625 imputation mse 1.0086549520492554\n",
      "Train Epoch 23.5 var loss 72123.9140625 reconstruction mse 72117.7421875 imputation mse 1.009331464767456\n",
      "Train Epoch 23.6 var loss 72143.8046875 reconstruction mse 72137.6796875 imputation mse 1.0096105337142944\n",
      "Train Epoch 23.7 var loss 72136.6640625 reconstruction mse 72130.6328125 imputation mse 1.0095118284225464\n",
      "Train Epoch 23.8 var loss 72086.0625 reconstruction mse 72080.09375 imputation mse 1.0088045597076416\n",
      "Train Epoch 23.9 var loss 72117.28125 reconstruction mse 72111.3359375 imputation mse 1.0092418193817139\n",
      "Train Epoch 24.0 var loss 70819.8828125 reconstruction mse 70719.8984375 imputation mse 0.992922306060791\n",
      "Train Epoch 24.1 var loss 70745.3984375 reconstruction mse 70739.3203125 imputation mse 0.9931949973106384\n",
      "Train Epoch 24.2 var loss 70676.3125 reconstruction mse 70670.1171875 imputation mse 0.9922233819961548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 24.3 var loss 70747.140625 reconstruction mse 70740.9140625 imputation mse 0.9932173490524292\n",
      "Train Epoch 24.4 var loss 70665.390625 reconstruction mse 70659.1640625 imputation mse 0.9920696020126343\n",
      "Train Epoch 24.5 var loss 70729.3203125 reconstruction mse 70723.0703125 imputation mse 0.9929668307304382\n",
      "Train Epoch 24.6 var loss 70731.234375 reconstruction mse 70724.9765625 imputation mse 0.9929935932159424\n",
      "Train Epoch 24.7 var loss 70745.4453125 reconstruction mse 70739.2421875 imputation mse 0.9931939244270325\n",
      "Train Epoch 24.8 var loss 70708.78125 reconstruction mse 70702.65625 imputation mse 0.9926802515983582\n",
      "Train Epoch 24.9 var loss 70713.171875 reconstruction mse 70707.0703125 imputation mse 0.9927421808242798\n",
      "Train Epoch 25.0 var loss 70788.046875 reconstruction mse 70689.90625 imputation mse 0.9922504425048828\n",
      "Train Epoch 25.1 var loss 70669.3359375 reconstruction mse 70663.234375 imputation mse 0.9918760657310486\n",
      "Train Epoch 25.2 var loss 70666.78125 reconstruction mse 70660.6171875 imputation mse 0.9918393492698669\n",
      "Train Epoch 25.3 var loss 70679.6015625 reconstruction mse 70673.4453125 imputation mse 0.9920194149017334\n",
      "Train Epoch 25.4 var loss 70687.359375 reconstruction mse 70681.1640625 imputation mse 0.9921277165412903\n",
      "Train Epoch 25.5 var loss 70685.84375 reconstruction mse 70679.703125 imputation mse 0.9921072125434875\n",
      "Train Epoch 25.6 var loss 70707.015625 reconstruction mse 70700.9453125 imputation mse 0.9924054145812988\n",
      "Train Epoch 25.7 var loss 70679.828125 reconstruction mse 70673.7578125 imputation mse 0.992023766040802\n",
      "Train Epoch 25.8 var loss 70722.9140625 reconstruction mse 70716.8828125 imputation mse 0.9926291108131409\n",
      "Train Epoch 25.9 var loss 70729.1015625 reconstruction mse 70723.1171875 imputation mse 0.9927166104316711\n",
      "Train Epoch 26.0 var loss 71835.9453125 reconstruction mse 71739.421875 imputation mse 1.0002708435058594\n",
      "Train Epoch 26.1 var loss 71748.28125 reconstruction mse 71742.203125 imputation mse 1.0003095865249634\n",
      "Train Epoch 26.2 var loss 71777.53125 reconstruction mse 71771.40625 imputation mse 1.0007168054580688\n",
      "Train Epoch 26.3 var loss 71705.1796875 reconstruction mse 71699.0546875 imputation mse 0.9997079372406006\n",
      "Train Epoch 26.4 var loss 71745.265625 reconstruction mse 71739.171875 imputation mse 1.0002672672271729\n",
      "Train Epoch 26.5 var loss 71750.34375 reconstruction mse 71744.296875 imputation mse 1.0003387928009033\n",
      "Train Epoch 26.6 var loss 71733.6015625 reconstruction mse 71727.625 imputation mse 1.0001063346862793\n",
      "Train Epoch 26.7 var loss 71759.1953125 reconstruction mse 71753.3125 imputation mse 1.0004644393920898\n",
      "Train Epoch 26.8 var loss 71746.140625 reconstruction mse 71740.265625 imputation mse 1.0002825260162354\n",
      "Train Epoch 26.9 var loss 71693.8359375 reconstruction mse 71688.0234375 imputation mse 0.9995541572570801\n",
      "Train Epoch 27.0 var loss 72100.25 reconstruction mse 72006.3984375 imputation mse 1.0057181119918823\n",
      "Train Epoch 27.1 var loss 72018.0078125 reconstruction mse 72012.125 imputation mse 1.005798101425171\n",
      "Train Epoch 27.2 var loss 72000.8203125 reconstruction mse 71994.8359375 imputation mse 1.005556583404541\n",
      "Train Epoch 27.3 var loss 72022.703125 reconstruction mse 72016.6875 imputation mse 1.005861759185791\n",
      "Train Epoch 27.4 var loss 72010.8203125 reconstruction mse 72004.78125 imputation mse 1.0056954622268677\n",
      "Train Epoch 27.5 var loss 72013.96875 reconstruction mse 72007.96875 imputation mse 1.0057400465011597\n",
      "Train Epoch 27.6 var loss 72033.296875 reconstruction mse 72027.3046875 imputation mse 1.0060100555419922\n",
      "Train Epoch 27.7 var loss 72033.7578125 reconstruction mse 72027.78125 imputation mse 1.006016731262207\n",
      "Train Epoch 27.8 var loss 72027.7109375 reconstruction mse 72021.78125 imputation mse 1.0059329271316528\n",
      "Train Epoch 27.9 var loss 71961.921875 reconstruction mse 71955.984375 imputation mse 1.0050139427185059\n",
      "Train Epoch 28.0 var loss 71511.9765625 reconstruction mse 71419.1328125 imputation mse 0.998324453830719\n",
      "Train Epoch 28.1 var loss 71425.796875 reconstruction mse 71419.71875 imputation mse 0.9983326196670532\n",
      "Train Epoch 28.2 var loss 71412.7109375 reconstruction mse 71406.53125 imputation mse 0.9981483221054077\n",
      "Train Epoch 28.3 var loss 71427.09375 reconstruction mse 71420.890625 imputation mse 0.9983490109443665\n",
      "Train Epoch 28.4 var loss 71417.0625 reconstruction mse 71410.921875 imputation mse 0.9982096552848816\n",
      "Train Epoch 28.5 var loss 71395.765625 reconstruction mse 71389.640625 imputation mse 0.9979121685028076\n",
      "Train Epoch 28.6 var loss 71404.2421875 reconstruction mse 71398.21875 imputation mse 0.9980320930480957\n",
      "Train Epoch 28.7 var loss 71436.90625 reconstruction mse 71430.890625 imputation mse 0.9984887838363647\n",
      "Train Epoch 28.8 var loss 71395.8515625 reconstruction mse 71389.90625 imputation mse 0.9979159235954285\n",
      "Train Epoch 28.9 var loss 71464.859375 reconstruction mse 71458.9375 imputation mse 0.9988808631896973\n",
      "Train Epoch 29.0 var loss 71440.3125 reconstruction mse 71349.2109375 imputation mse 1.0017439126968384\n",
      "Train Epoch 29.1 var loss 71349.078125 reconstruction mse 71343.03125 imputation mse 1.0016571283340454\n",
      "Train Epoch 29.2 var loss 71344.40625 reconstruction mse 71338.3046875 imputation mse 1.0015908479690552\n",
      "Train Epoch 29.3 var loss 71323.9453125 reconstruction mse 71317.8046875 imputation mse 1.00130295753479\n",
      "Train Epoch 29.4 var loss 71394.1171875 reconstruction mse 71387.9921875 imputation mse 1.0022884607315063\n",
      "Train Epoch 29.5 var loss 71391.6484375 reconstruction mse 71385.5 imputation mse 1.0022534132003784\n",
      "Train Epoch 29.6 var loss 71389.34375 reconstruction mse 71383.3046875 imputation mse 1.0022226572036743\n",
      "Train Epoch 29.7 var loss 71335.8125 reconstruction mse 71329.7890625 imputation mse 1.0014712810516357\n",
      "Train Epoch 29.8 var loss 71388.21875 reconstruction mse 71382.28125 imputation mse 1.0022082328796387\n",
      "Train Epoch 29.9 var loss 71371.7578125 reconstruction mse 71365.859375 imputation mse 1.0019776821136475\n",
      "Train Epoch 30.0 var loss 71594.5390625 reconstruction mse 71504.703125 imputation mse 1.0002896785736084\n",
      "Train Epoch 30.1 var loss 71550.0 reconstruction mse 71544.078125 imputation mse 1.000840425491333\n",
      "Train Epoch 30.2 var loss 71504.7109375 reconstruction mse 71498.7421875 imputation mse 1.0002062320709229\n",
      "Train Epoch 30.3 var loss 71535.421875 reconstruction mse 71529.453125 imputation mse 1.0006358623504639\n",
      "Train Epoch 30.4 var loss 71500.3046875 reconstruction mse 71494.328125 imputation mse 1.0001444816589355\n",
      "Train Epoch 30.5 var loss 71527.0625 reconstruction mse 71521.109375 imputation mse 1.0005191564559937\n",
      "Train Epoch 30.6 var loss 71541.59375 reconstruction mse 71535.703125 imputation mse 1.0007232427597046\n",
      "Train Epoch 30.7 var loss 71523.5703125 reconstruction mse 71517.6796875 imputation mse 1.0004711151123047\n",
      "Train Epoch 30.8 var loss 71455.6015625 reconstruction mse 71449.7421875 imputation mse 0.9995207786560059\n",
      "Train Epoch 30.9 var loss 71492.84375 reconstruction mse 71486.984375 imputation mse 1.0000417232513428\n",
      "====> Test imputation mse: 0.99019921\n",
      "====> Test imputation mse: 0.99127275\n",
      "====> Test imputation mse: 1.01636112\n",
      "Train Epoch 31.0 var loss 72470.6875 reconstruction mse 72382.390625 imputation mse 1.0171637535095215\n",
      "Train Epoch 31.1 var loss 72420.5546875 reconstruction mse 72414.5546875 imputation mse 1.017615795135498\n",
      "Train Epoch 31.2 var loss 72385.703125 reconstruction mse 72379.6328125 imputation mse 1.0171250104904175\n",
      "Train Epoch 31.3 var loss 72388.7109375 reconstruction mse 72382.5625 imputation mse 1.0171661376953125\n",
      "Train Epoch 31.4 var loss 72376.1796875 reconstruction mse 72370.109375 imputation mse 1.016991138458252\n",
      "Train Epoch 31.5 var loss 72381.2890625 reconstruction mse 72375.3359375 imputation mse 1.0170645713806152\n",
      "Train Epoch 31.6 var loss 72402.3203125 reconstruction mse 72396.421875 imputation mse 1.0173609256744385\n",
      "Train Epoch 31.7 var loss 72359.1796875 reconstruction mse 72353.3828125 imputation mse 1.0167561769485474\n",
      "Train Epoch 31.8 var loss 72431.9609375 reconstruction mse 72426.1953125 imputation mse 1.0177793502807617\n",
      "Train Epoch 31.9 var loss 72372.3125 reconstruction mse 72366.609375 imputation mse 1.016942024230957\n",
      "Train Epoch 32.0 var loss 71814.46875 reconstruction mse 71728.125 imputation mse 1.004736304283142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 32.1 var loss 71749.3359375 reconstruction mse 71743.4296875 imputation mse 1.0049506425857544\n",
      "Train Epoch 32.2 var loss 71716.4765625 reconstruction mse 71710.421875 imputation mse 1.0044883489608765\n",
      "Train Epoch 32.3 var loss 71741.921875 reconstruction mse 71735.8359375 imputation mse 1.004844307899475\n",
      "Train Epoch 32.4 var loss 71727.4140625 reconstruction mse 71721.296875 imputation mse 1.0046406984329224\n",
      "Train Epoch 32.5 var loss 71756.6875 reconstruction mse 71750.5703125 imputation mse 1.0050506591796875\n",
      "Train Epoch 32.6 var loss 71717.2265625 reconstruction mse 71711.15625 imputation mse 1.0044986009597778\n",
      "Train Epoch 32.7 var loss 71767.640625 reconstruction mse 71761.65625 imputation mse 1.0052059888839722\n",
      "Train Epoch 32.8 var loss 71757.125 reconstruction mse 71751.2421875 imputation mse 1.005060076713562\n",
      "Train Epoch 32.9 var loss 71809.2421875 reconstruction mse 71803.4609375 imputation mse 1.0057915449142456\n",
      "Train Epoch 33.0 var loss 72088.1640625 reconstruction mse 72003.3515625 imputation mse 1.008238434791565\n",
      "Train Epoch 33.1 var loss 72036.421875 reconstruction mse 72030.515625 imputation mse 1.0086188316345215\n",
      "Train Epoch 33.2 var loss 71920.4140625 reconstruction mse 71914.4140625 imputation mse 1.0069931745529175\n",
      "Train Epoch 33.3 var loss 71999.3984375 reconstruction mse 71993.296875 imputation mse 1.0080976486206055\n",
      "Train Epoch 33.4 var loss 72002.671875 reconstruction mse 71996.5703125 imputation mse 1.0081435441970825\n",
      "Train Epoch 33.5 var loss 71967.6875 reconstruction mse 71961.578125 imputation mse 1.0076535940170288\n",
      "Train Epoch 33.6 var loss 71941.7890625 reconstruction mse 71935.71875 imputation mse 1.0072914361953735\n",
      "Train Epoch 33.7 var loss 71922.4765625 reconstruction mse 71916.4765625 imputation mse 1.0070220232009888\n",
      "Train Epoch 33.8 var loss 71965.2109375 reconstruction mse 71959.3046875 imputation mse 1.0076217651367188\n",
      "Train Epoch 33.9 var loss 71962.25 reconstruction mse 71956.40625 imputation mse 1.007581114768982\n",
      "Train Epoch 34.0 var loss 70844.046875 reconstruction mse 70760.578125 imputation mse 0.9979490637779236\n",
      "Train Epoch 34.1 var loss 70695.234375 reconstruction mse 70689.25 imputation mse 0.9969431161880493\n",
      "Train Epoch 34.2 var loss 70731.4140625 reconstruction mse 70725.3515625 imputation mse 0.9974522590637207\n",
      "Train Epoch 34.3 var loss 70686.875 reconstruction mse 70680.7734375 imputation mse 0.9968236088752747\n",
      "Train Epoch 34.4 var loss 70703.2578125 reconstruction mse 70697.2421875 imputation mse 0.9970558285713196\n",
      "Train Epoch 34.5 var loss 70723.90625 reconstruction mse 70717.90625 imputation mse 0.9973472952842712\n",
      "Train Epoch 34.6 var loss 70681.3984375 reconstruction mse 70675.5 imputation mse 0.996749222278595\n",
      "Train Epoch 34.7 var loss 70700.21875 reconstruction mse 70694.359375 imputation mse 0.9970151782035828\n",
      "Train Epoch 34.8 var loss 70720.2109375 reconstruction mse 70714.484375 imputation mse 0.9972990155220032\n",
      "Train Epoch 34.9 var loss 70746.2578125 reconstruction mse 70740.625 imputation mse 0.997667670249939\n",
      "Train Epoch 35.0 var loss 71398.6328125 reconstruction mse 71316.4453125 imputation mse 1.0047683715820312\n",
      "Train Epoch 35.1 var loss 71307.5 reconstruction mse 71301.7734375 imputation mse 1.0045615434646606\n",
      "Train Epoch 35.2 var loss 71311.9921875 reconstruction mse 71306.15625 imputation mse 1.004623293876648\n",
      "Train Epoch 35.3 var loss 71336.9921875 reconstruction mse 71331.1640625 imputation mse 1.00497567653656\n",
      "Train Epoch 35.4 var loss 71281.5859375 reconstruction mse 71275.7109375 imputation mse 1.0041943788528442\n",
      "Train Epoch 35.5 var loss 71309.4765625 reconstruction mse 71303.6796875 imputation mse 1.0045884847640991\n",
      "Train Epoch 35.6 var loss 71271.390625 reconstruction mse 71265.6484375 imputation mse 1.0040526390075684\n",
      "Train Epoch 35.7 var loss 71278.65625 reconstruction mse 71272.953125 imputation mse 1.0041555166244507\n",
      "Train Epoch 35.8 var loss 71343.4609375 reconstruction mse 71337.7890625 imputation mse 1.0050690174102783\n",
      "Train Epoch 35.9 var loss 71308.8828125 reconstruction mse 71303.2421875 imputation mse 1.0045822858810425\n",
      "Train Epoch 36.0 var loss 70706.703125 reconstruction mse 70626.1640625 imputation mse 0.9950149655342102\n",
      "Train Epoch 36.1 var loss 70672.7421875 reconstruction mse 70666.90625 imputation mse 0.9955889582633972\n",
      "Train Epoch 36.2 var loss 70633.21875 reconstruction mse 70627.21875 imputation mse 0.995029866695404\n",
      "Train Epoch 36.3 var loss 70640.4453125 reconstruction mse 70634.40625 imputation mse 0.9951311349868774\n",
      "Train Epoch 36.4 var loss 70602.5546875 reconstruction mse 70596.53125 imputation mse 0.9945974946022034\n",
      "Train Epoch 36.5 var loss 70643.4921875 reconstruction mse 70637.515625 imputation mse 0.9951749444007874\n",
      "Train Epoch 36.6 var loss 70617.2265625 reconstruction mse 70611.328125 imputation mse 0.9948059916496277\n",
      "Train Epoch 36.7 var loss 70612.8046875 reconstruction mse 70607.0234375 imputation mse 0.9947453141212463\n",
      "Train Epoch 36.8 var loss 70654.8203125 reconstruction mse 70649.1171875 imputation mse 0.9953383803367615\n",
      "Train Epoch 36.9 var loss 70663.5078125 reconstruction mse 70657.8828125 imputation mse 0.9954618811607361\n",
      "Train Epoch 37.0 var loss 72128.6796875 reconstruction mse 72049.6015625 imputation mse 1.0045676231384277\n",
      "Train Epoch 37.1 var loss 72093.59375 reconstruction mse 72087.859375 imputation mse 1.0051010847091675\n",
      "Train Epoch 37.2 var loss 72080.34375 reconstruction mse 72074.53125 imputation mse 1.0049152374267578\n",
      "Train Epoch 37.3 var loss 72048.578125 reconstruction mse 72042.6640625 imputation mse 1.004470944404602\n",
      "Train Epoch 37.4 var loss 72111.8359375 reconstruction mse 72105.9296875 imputation mse 1.0053529739379883\n",
      "Train Epoch 37.5 var loss 72082.078125 reconstruction mse 72076.1640625 imputation mse 1.004938006401062\n",
      "Train Epoch 37.6 var loss 72094.90625 reconstruction mse 72089.0546875 imputation mse 1.0051177740097046\n",
      "Train Epoch 37.7 var loss 72114.0234375 reconstruction mse 72108.171875 imputation mse 1.0053843259811401\n",
      "Train Epoch 37.8 var loss 72144.7421875 reconstruction mse 72138.953125 imputation mse 1.005813479423523\n",
      "Train Epoch 37.9 var loss 72083.8125 reconstruction mse 72078.0703125 imputation mse 1.0049645900726318\n",
      "Train Epoch 38.0 var loss 71409.1796875 reconstruction mse 71331.5859375 imputation mse 0.997672438621521\n",
      "Train Epoch 38.1 var loss 71334.1015625 reconstruction mse 71328.265625 imputation mse 0.997626006603241\n",
      "Train Epoch 38.2 var loss 71310.6640625 reconstruction mse 71304.734375 imputation mse 0.997296929359436\n",
      "Train Epoch 38.3 var loss 71348.4921875 reconstruction mse 71342.5703125 imputation mse 0.997826099395752\n",
      "Train Epoch 38.4 var loss 71330.078125 reconstruction mse 71324.203125 imputation mse 0.99756920337677\n",
      "Train Epoch 38.5 var loss 71331.0 reconstruction mse 71325.15625 imputation mse 0.9975825548171997\n",
      "Train Epoch 38.6 var loss 71347.8203125 reconstruction mse 71342.0390625 imputation mse 0.997818648815155\n",
      "Train Epoch 38.7 var loss 71334.6484375 reconstruction mse 71328.9453125 imputation mse 0.997635543346405\n",
      "Train Epoch 38.8 var loss 71311.375 reconstruction mse 71305.6796875 imputation mse 0.9973101019859314\n",
      "Train Epoch 38.9 var loss 71341.453125 reconstruction mse 71335.8125 imputation mse 0.9977315664291382\n",
      "Train Epoch 39.0 var loss 71990.515625 reconstruction mse 71914.125 imputation mse 1.001394271850586\n",
      "Train Epoch 39.1 var loss 71896.03125 reconstruction mse 71890.1875 imputation mse 1.0010608434677124\n",
      "Train Epoch 39.2 var loss 71892.78125 reconstruction mse 71886.859375 imputation mse 1.0010145902633667\n",
      "Train Epoch 39.3 var loss 71910.703125 reconstruction mse 71904.7578125 imputation mse 1.0012637376785278\n",
      "Train Epoch 39.4 var loss 71888.015625 reconstruction mse 71882.09375 imputation mse 1.000948190689087\n",
      "Train Epoch 39.5 var loss 71921.4296875 reconstruction mse 71915.5703125 imputation mse 1.0014142990112305\n",
      "Train Epoch 39.6 var loss 71951.71875 reconstruction mse 71945.9140625 imputation mse 1.001836895942688\n",
      "Train Epoch 39.7 var loss 71888.546875 reconstruction mse 71882.8125 imputation mse 1.0009582042694092\n",
      "Train Epoch 39.8 var loss 71898.6875 reconstruction mse 71892.96875 imputation mse 1.0010995864868164\n",
      "Train Epoch 39.9 var loss 71931.1484375 reconstruction mse 71925.40625 imputation mse 1.0015512704849243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 40.0 var loss 71663.890625 reconstruction mse 71589.359375 imputation mse 0.9990699887275696\n",
      "Train Epoch 40.1 var loss 71643.78125 reconstruction mse 71637.875 imputation mse 0.9997470378875732\n",
      "Train Epoch 40.2 var loss 71596.7421875 reconstruction mse 71590.7578125 imputation mse 0.9990894794464111\n",
      "Train Epoch 40.3 var loss 71594.765625 reconstruction mse 71588.765625 imputation mse 0.9990617036819458\n",
      "Train Epoch 40.4 var loss 71607.546875 reconstruction mse 71601.5546875 imputation mse 0.9992401599884033\n",
      "Train Epoch 40.5 var loss 71619.859375 reconstruction mse 71613.9609375 imputation mse 0.9994133114814758\n",
      "Train Epoch 40.6 var loss 71598.234375 reconstruction mse 71592.4140625 imputation mse 0.999112606048584\n",
      "Train Epoch 40.7 var loss 71611.046875 reconstruction mse 71605.34375 imputation mse 0.9992930889129639\n",
      "Train Epoch 40.8 var loss 71596.171875 reconstruction mse 71590.5625 imputation mse 0.9990867972373962\n",
      "Train Epoch 40.9 var loss 71612.1796875 reconstruction mse 71606.515625 imputation mse 0.9993094205856323\n",
      "====> Test imputation mse: 1.02174711\n",
      "====> Test imputation mse: 0.99230623\n",
      "====> Test imputation mse: 0.99646860\n",
      "Train Epoch 41.0 var loss 71874.8359375 reconstruction mse 71801.34375 imputation mse 1.0085450410842896\n",
      "Train Epoch 41.1 var loss 71801.3046875 reconstruction mse 71795.515625 imputation mse 1.0084631443023682\n",
      "Train Epoch 41.2 var loss 71836.9765625 reconstruction mse 71831.09375 imputation mse 1.008962869644165\n",
      "Train Epoch 41.3 var loss 71854.8125 reconstruction mse 71848.875 imputation mse 1.009212613105774\n",
      "Train Epoch 41.4 var loss 71839.4453125 reconstruction mse 71833.5234375 imputation mse 1.0089969635009766\n",
      "Train Epoch 41.5 var loss 71807.125 reconstruction mse 71801.203125 imputation mse 1.0085430145263672\n",
      "Train Epoch 41.6 var loss 71844.9921875 reconstruction mse 71839.1328125 imputation mse 1.0090757608413696\n",
      "Train Epoch 41.7 var loss 71859.7265625 reconstruction mse 71853.9453125 imputation mse 1.0092839002609253\n",
      "Train Epoch 41.8 var loss 71802.0703125 reconstruction mse 71796.3515625 imputation mse 1.0084748268127441\n",
      "Train Epoch 41.9 var loss 71870.515625 reconstruction mse 71864.875 imputation mse 1.0094373226165771\n",
      "Train Epoch 42.0 var loss 71531.3203125 reconstruction mse 71458.8046875 imputation mse 1.0009217262268066\n",
      "Train Epoch 42.1 var loss 71550.859375 reconstruction mse 71545.0859375 imputation mse 1.0021302700042725\n",
      "Train Epoch 42.2 var loss 71509.046875 reconstruction mse 71503.1875 imputation mse 1.001543402671814\n",
      "Train Epoch 42.3 var loss 71486.0703125 reconstruction mse 71480.1953125 imputation mse 1.0012212991714478\n",
      "Train Epoch 42.4 var loss 71455.78125 reconstruction mse 71449.921875 imputation mse 1.0007972717285156\n",
      "Train Epoch 42.5 var loss 71520.75 reconstruction mse 71514.9140625 imputation mse 1.001707673072815\n",
      "Train Epoch 42.6 var loss 71498.3125 reconstruction mse 71492.546875 imputation mse 1.0013943910598755\n",
      "Train Epoch 42.7 var loss 71482.1484375 reconstruction mse 71476.453125 imputation mse 1.001168966293335\n",
      "Train Epoch 42.8 var loss 71485.4296875 reconstruction mse 71479.828125 imputation mse 1.001216173171997\n",
      "Train Epoch 42.9 var loss 71447.8359375 reconstruction mse 71442.2578125 imputation mse 1.00068998336792\n",
      "Train Epoch 43.0 var loss 71420.765625 reconstruction mse 71349.3359375 imputation mse 1.00050950050354\n",
      "Train Epoch 43.1 var loss 71369.3828125 reconstruction mse 71363.6796875 imputation mse 1.0007106065750122\n",
      "Train Epoch 43.2 var loss 71345.734375 reconstruction mse 71339.9453125 imputation mse 1.000377893447876\n",
      "Train Epoch 43.3 var loss 71372.3125 reconstruction mse 71366.421875 imputation mse 1.000749111175537\n",
      "Train Epoch 43.4 var loss 71341.6328125 reconstruction mse 71335.734375 imputation mse 1.0003187656402588\n",
      "Train Epoch 43.5 var loss 71316.7890625 reconstruction mse 71310.9609375 imputation mse 0.9999713897705078\n",
      "Train Epoch 43.6 var loss 71426.4609375 reconstruction mse 71420.7421875 imputation mse 1.0015108585357666\n",
      "Train Epoch 43.7 var loss 71372.90625 reconstruction mse 71367.2890625 imputation mse 1.0007612705230713\n",
      "Train Epoch 43.8 var loss 71369.71875 reconstruction mse 71364.1640625 imputation mse 1.0007174015045166\n",
      "Train Epoch 43.9 var loss 71353.8828125 reconstruction mse 71348.4375 imputation mse 1.0004969835281372\n",
      "Train Epoch 44.0 var loss 71143.5703125 reconstruction mse 71073.8671875 imputation mse 0.9984668493270874\n",
      "Train Epoch 44.1 var loss 70994.5703125 reconstruction mse 70989.0625 imputation mse 0.9972755312919617\n",
      "Train Epoch 44.2 var loss 71076.1796875 reconstruction mse 71070.5625 imputation mse 0.9984204173088074\n",
      "Train Epoch 44.3 var loss 71034.9296875 reconstruction mse 71029.28125 imputation mse 0.9978405237197876\n",
      "Train Epoch 44.4 var loss 71144.140625 reconstruction mse 71138.4609375 imputation mse 0.9993743300437927\n",
      "Train Epoch 44.5 var loss 71057.2890625 reconstruction mse 71051.6640625 imputation mse 0.9981549382209778\n",
      "Train Epoch 44.6 var loss 71052.9375 reconstruction mse 71047.3671875 imputation mse 0.9980946183204651\n",
      "Train Epoch 44.7 var loss 71067.40625 reconstruction mse 71061.8359375 imputation mse 0.9982978701591492\n",
      "Train Epoch 44.8 var loss 71086.2890625 reconstruction mse 71080.7890625 imputation mse 0.9985641241073608\n",
      "Train Epoch 44.9 var loss 71067.8515625 reconstruction mse 71062.3359375 imputation mse 0.9983049035072327\n",
      "Train Epoch 45.0 var loss 71321.4140625 reconstruction mse 71253.1796875 imputation mse 0.9967989325523376\n",
      "Train Epoch 45.1 var loss 71245.1875 reconstruction mse 71239.4609375 imputation mse 0.9966070055961609\n",
      "Train Epoch 45.2 var loss 71285.2734375 reconstruction mse 71279.40625 imputation mse 0.9971657991409302\n",
      "Train Epoch 45.3 var loss 71231.5546875 reconstruction mse 71225.640625 imputation mse 0.9964136481285095\n",
      "Train Epoch 45.4 var loss 71272.4921875 reconstruction mse 71266.6171875 imputation mse 0.9969868659973145\n",
      "Train Epoch 45.5 var loss 71264.1640625 reconstruction mse 71258.34375 imputation mse 0.9968711733818054\n",
      "Train Epoch 45.6 var loss 71245.3828125 reconstruction mse 71239.6640625 imputation mse 0.9966098070144653\n",
      "Train Epoch 45.7 var loss 71299.0 reconstruction mse 71293.328125 imputation mse 0.9973605871200562\n",
      "Train Epoch 45.8 var loss 71242.6953125 reconstruction mse 71237.1171875 imputation mse 0.9965742230415344\n",
      "Train Epoch 45.9 var loss 71264.5625 reconstruction mse 71259.03125 imputation mse 0.9968807697296143\n",
      "Train Epoch 46.0 var loss 72352.625 reconstruction mse 72285.203125 imputation mse 1.0078104734420776\n",
      "Train Epoch 46.1 var loss 72292.234375 reconstruction mse 72286.5625 imputation mse 1.0078294277191162\n",
      "Train Epoch 46.2 var loss 72267.2734375 reconstruction mse 72261.5546875 imputation mse 1.0074807405471802\n",
      "Train Epoch 46.3 var loss 72311.71875 reconstruction mse 72305.9609375 imputation mse 1.0080997943878174\n",
      "Train Epoch 46.4 var loss 72263.4375 reconstruction mse 72257.6875 imputation mse 1.0074268579483032\n",
      "Train Epoch 46.5 var loss 72325.734375 reconstruction mse 72320.0234375 imputation mse 1.0082958936691284\n",
      "Train Epoch 46.6 var loss 72316.8203125 reconstruction mse 72311.1640625 imputation mse 1.0081723928451538\n",
      "Train Epoch 46.7 var loss 72301.5234375 reconstruction mse 72295.96875 imputation mse 1.007960557937622\n",
      "Train Epoch 46.8 var loss 72337.8125 reconstruction mse 72332.328125 imputation mse 1.008467435836792\n",
      "Train Epoch 46.9 var loss 72353.1171875 reconstruction mse 72347.7421875 imputation mse 1.008682370185852\n",
      "Train Epoch 47.0 var loss 72178.90625 reconstruction mse 72113.15625 imputation mse 1.0069841146469116\n",
      "Train Epoch 47.1 var loss 72097.484375 reconstruction mse 72092.0234375 imputation mse 1.0066890716552734\n",
      "Train Epoch 47.2 var loss 72090.7109375 reconstruction mse 72085.1484375 imputation mse 1.006593108177185\n",
      "Train Epoch 47.3 var loss 72061.1796875 reconstruction mse 72055.578125 imputation mse 1.0061801671981812\n",
      "Train Epoch 47.4 var loss 72130.3125 reconstruction mse 72124.6875 imputation mse 1.0071451663970947\n",
      "Train Epoch 47.5 var loss 72116.9765625 reconstruction mse 72111.3671875 imputation mse 1.0069591999053955\n",
      "Train Epoch 47.6 var loss 72092.4765625 reconstruction mse 72086.8671875 imputation mse 1.0066170692443848\n",
      "Train Epoch 47.7 var loss 72073.640625 reconstruction mse 72068.0703125 imputation mse 1.006354570388794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 47.8 var loss 72102.6328125 reconstruction mse 72097.109375 imputation mse 1.0067601203918457\n",
      "Train Epoch 47.9 var loss 72093.7421875 reconstruction mse 72088.234375 imputation mse 1.006636142730713\n",
      "Train Epoch 48.0 var loss 71974.765625 reconstruction mse 71910.15625 imputation mse 1.0090388059616089\n",
      "Train Epoch 48.1 var loss 71936.6171875 reconstruction mse 71930.9375 imputation mse 1.00933039188385\n",
      "Train Epoch 48.2 var loss 71942.03125 reconstruction mse 71936.3046875 imputation mse 1.0094057321548462\n",
      "Train Epoch 48.3 var loss 71916.671875 reconstruction mse 71910.8828125 imputation mse 1.0090489387512207\n",
      "Train Epoch 48.4 var loss 71896.859375 reconstruction mse 71891.0859375 imputation mse 1.0087711811065674\n",
      "Train Epoch 48.5 var loss 71895.53125 reconstruction mse 71889.8125 imputation mse 1.0087532997131348\n",
      "Train Epoch 48.6 var loss 71945.5234375 reconstruction mse 71939.9453125 imputation mse 1.009456753730774\n",
      "Train Epoch 48.7 var loss 71858.5625 reconstruction mse 71853.0546875 imputation mse 1.0082374811172485\n",
      "Train Epoch 48.8 var loss 71876.84375 reconstruction mse 71871.40625 imputation mse 1.0084949731826782\n",
      "Train Epoch 48.9 var loss 71925.375 reconstruction mse 71919.984375 imputation mse 1.0091766119003296\n",
      "Train Epoch 49.0 var loss 71279.6875 reconstruction mse 71216.3203125 imputation mse 0.9950582981109619\n",
      "Train Epoch 49.1 var loss 71217.6328125 reconstruction mse 71212.140625 imputation mse 0.994999885559082\n",
      "Train Epoch 49.2 var loss 71226.890625 reconstruction mse 71221.2890625 imputation mse 0.9951276779174805\n",
      "Train Epoch 49.3 var loss 71248.65625 reconstruction mse 71243.0078125 imputation mse 0.9954311847686768\n",
      "Train Epoch 49.4 var loss 71230.046875 reconstruction mse 71224.4296875 imputation mse 0.9951715469360352\n",
      "Train Epoch 49.5 var loss 71212.6171875 reconstruction mse 71207.0390625 imputation mse 0.9949285984039307\n",
      "Train Epoch 49.6 var loss 71228.84375 reconstruction mse 71223.3203125 imputation mse 0.9951560497283936\n",
      "Train Epoch 49.7 var loss 71270.9296875 reconstruction mse 71265.46875 imputation mse 0.9957450032234192\n",
      "Train Epoch 49.8 var loss 71245.703125 reconstruction mse 71240.3046875 imputation mse 0.9953933954238892\n",
      "Train Epoch 49.9 var loss 71246.0390625 reconstruction mse 71240.640625 imputation mse 0.9953981041908264\n",
      "Train Epoch 50.0 var loss 71869.96875 reconstruction mse 71807.375 imputation mse 1.0091116428375244\n",
      "Train Epoch 50.1 var loss 71821.0703125 reconstruction mse 71815.4921875 imputation mse 1.0092257261276245\n",
      "Train Epoch 50.2 var loss 71783.09375 reconstruction mse 71777.4921875 imputation mse 1.008691668510437\n",
      "Train Epoch 50.3 var loss 71773.0546875 reconstruction mse 71767.3984375 imputation mse 1.0085498094558716\n",
      "Train Epoch 50.4 var loss 71837.15625 reconstruction mse 71831.53125 imputation mse 1.009451150894165\n",
      "Train Epoch 50.5 var loss 71848.515625 reconstruction mse 71842.90625 imputation mse 1.0096110105514526\n",
      "Train Epoch 50.6 var loss 71820.5625 reconstruction mse 71815.0 imputation mse 1.0092188119888306\n",
      "Train Epoch 50.7 var loss 71785.796875 reconstruction mse 71780.28125 imputation mse 1.0087308883666992\n",
      "Train Epoch 50.8 var loss 71833.5703125 reconstruction mse 71828.0546875 imputation mse 1.0094022750854492\n",
      "Train Epoch 50.9 var loss 71813.9375 reconstruction mse 71808.4765625 imputation mse 1.009127140045166\n",
      "====> Test imputation mse: 0.99487025\n",
      "====> Test imputation mse: 1.00989282\n",
      "====> Test imputation mse: 1.00522661\n",
      "Train Epoch 51.0 var loss 72179.40625 reconstruction mse 72117.875 imputation mse 1.0052952766418457\n",
      "Train Epoch 51.1 var loss 72067.0703125 reconstruction mse 72061.4921875 imputation mse 1.0045093297958374\n",
      "Train Epoch 51.2 var loss 72160.8046875 reconstruction mse 72155.1484375 imputation mse 1.0058149099349976\n",
      "Train Epoch 51.3 var loss 72112.3203125 reconstruction mse 72106.640625 imputation mse 1.0051387548446655\n",
      "Train Epoch 51.4 var loss 72136.0703125 reconstruction mse 72130.3671875 imputation mse 1.0054694414138794\n",
      "Train Epoch 51.5 var loss 72114.1640625 reconstruction mse 72108.5234375 imputation mse 1.0051649808883667\n",
      "Train Epoch 51.6 var loss 72159.484375 reconstruction mse 72153.890625 imputation mse 1.0057973861694336\n",
      "Train Epoch 51.7 var loss 72094.8671875 reconstruction mse 72089.3828125 imputation mse 1.004898190498352\n",
      "Train Epoch 51.8 var loss 72159.203125 reconstruction mse 72153.75 imputation mse 1.0057953596115112\n",
      "Train Epoch 51.9 var loss 72101.9921875 reconstruction mse 72096.59375 imputation mse 1.0049986839294434\n",
      "Train Epoch 52.0 var loss 71835.796875 reconstruction mse 71775.5703125 imputation mse 1.0049926042556763\n",
      "Train Epoch 52.1 var loss 71782.2734375 reconstruction mse 71776.8046875 imputation mse 1.0050098896026611\n",
      "Train Epoch 52.2 var loss 71815.5390625 reconstruction mse 71809.9609375 imputation mse 1.0054742097854614\n",
      "Train Epoch 52.3 var loss 71785.203125 reconstruction mse 71779.578125 imputation mse 1.0050487518310547\n",
      "Train Epoch 52.4 var loss 71828.84375 reconstruction mse 71823.1875 imputation mse 1.0056593418121338\n",
      "Train Epoch 52.5 var loss 71823.640625 reconstruction mse 71818.015625 imputation mse 1.0055869817733765\n",
      "Train Epoch 52.6 var loss 71810.78125 reconstruction mse 71805.1953125 imputation mse 1.005407452583313\n",
      "Train Epoch 52.7 var loss 71791.1875 reconstruction mse 71785.625 imputation mse 1.0051333904266357\n",
      "Train Epoch 52.8 var loss 71836.2109375 reconstruction mse 71830.7578125 imputation mse 1.005765438079834\n",
      "Train Epoch 52.9 var loss 71849.6171875 reconstruction mse 71844.1796875 imputation mse 1.005953311920166\n",
      "Train Epoch 53.0 var loss 72476.875 reconstruction mse 72418.046875 imputation mse 1.006533145904541\n",
      "Train Epoch 53.1 var loss 72418.890625 reconstruction mse 72413.34375 imputation mse 1.0064678192138672\n",
      "Train Epoch 53.2 var loss 72429.890625 reconstruction mse 72424.21875 imputation mse 1.0066189765930176\n",
      "Train Epoch 53.3 var loss 72434.890625 reconstruction mse 72429.1796875 imputation mse 1.006687879562378\n",
      "Train Epoch 53.4 var loss 72403.046875 reconstruction mse 72397.3359375 imputation mse 1.0062452554702759\n",
      "Train Epoch 53.5 var loss 72360.2265625 reconstruction mse 72354.5234375 imputation mse 1.005650281906128\n",
      "Train Epoch 53.6 var loss 72399.203125 reconstruction mse 72393.515625 imputation mse 1.0061922073364258\n",
      "Train Epoch 53.7 var loss 72393.859375 reconstruction mse 72388.28125 imputation mse 1.0061194896697998\n",
      "Train Epoch 53.8 var loss 72433.03125 reconstruction mse 72427.46875 imputation mse 1.0066641569137573\n",
      "Train Epoch 53.9 var loss 72388.96875 reconstruction mse 72383.4609375 imputation mse 1.0060524940490723\n",
      "Train Epoch 54.0 var loss 71004.0859375 reconstruction mse 70946.203125 imputation mse 0.9918938875198364\n",
      "Train Epoch 54.1 var loss 70958.015625 reconstruction mse 70952.453125 imputation mse 0.9919812679290771\n",
      "Train Epoch 54.2 var loss 70944.4140625 reconstruction mse 70938.7890625 imputation mse 0.991790235042572\n",
      "Train Epoch 54.3 var loss 70970.453125 reconstruction mse 70964.765625 imputation mse 0.9921534061431885\n",
      "Train Epoch 54.4 var loss 70945.6796875 reconstruction mse 70940.015625 imputation mse 0.9918074011802673\n",
      "Train Epoch 54.5 var loss 70982.9140625 reconstruction mse 70977.296875 imputation mse 0.9923286437988281\n",
      "Train Epoch 54.6 var loss 70973.15625 reconstruction mse 70967.6015625 imputation mse 0.9921930432319641\n",
      "Train Epoch 54.7 var loss 70964.9765625 reconstruction mse 70959.515625 imputation mse 0.99208003282547\n",
      "Train Epoch 54.8 var loss 71001.8671875 reconstruction mse 70996.4375 imputation mse 0.9925962090492249\n",
      "Train Epoch 54.9 var loss 71049.765625 reconstruction mse 71044.375 imputation mse 0.9932664632797241\n",
      "Train Epoch 55.0 var loss 71540.4921875 reconstruction mse 71483.6875 imputation mse 1.006004810333252\n",
      "Train Epoch 55.1 var loss 71417.9453125 reconstruction mse 71412.390625 imputation mse 1.0050015449523926\n",
      "Train Epoch 55.2 var loss 71483.1796875 reconstruction mse 71477.5078125 imputation mse 1.0059179067611694\n",
      "Train Epoch 55.3 var loss 71433.671875 reconstruction mse 71427.9609375 imputation mse 1.005220651626587\n",
      "Train Epoch 55.4 var loss 71453.3046875 reconstruction mse 71447.6171875 imputation mse 1.0054972171783447\n",
      "Train Epoch 55.5 var loss 71448.6484375 reconstruction mse 71443.0390625 imputation mse 1.0054328441619873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 55.6 var loss 71431.4140625 reconstruction mse 71425.890625 imputation mse 1.005191445350647\n",
      "Train Epoch 55.7 var loss 71407.796875 reconstruction mse 71402.4375 imputation mse 1.0048613548278809\n",
      "Train Epoch 55.8 var loss 71460.4765625 reconstruction mse 71455.21875 imputation mse 1.0056042671203613\n",
      "Train Epoch 55.9 var loss 71494.2109375 reconstruction mse 71489.0078125 imputation mse 1.0060797929763794\n",
      "Train Epoch 56.0 var loss 71824.7421875 reconstruction mse 71769.1953125 imputation mse 1.0065382719039917\n",
      "Train Epoch 56.1 var loss 71665.9453125 reconstruction mse 71660.5625 imputation mse 1.0050146579742432\n",
      "Train Epoch 56.2 var loss 71699.34375 reconstruction mse 71693.8046875 imputation mse 1.0054808855056763\n",
      "Train Epoch 56.3 var loss 71671.3671875 reconstruction mse 71665.796875 imputation mse 1.0050880908966064\n",
      "Train Epoch 56.4 var loss 71670.21875 reconstruction mse 71664.59375 imputation mse 1.0050712823867798\n",
      "Train Epoch 56.5 var loss 71684.1171875 reconstruction mse 71678.484375 imputation mse 1.0052660703659058\n",
      "Train Epoch 56.6 var loss 71682.4453125 reconstruction mse 71676.8515625 imputation mse 1.005243182182312\n",
      "Train Epoch 56.7 var loss 71710.6015625 reconstruction mse 71705.0390625 imputation mse 1.0056384801864624\n",
      "Train Epoch 56.8 var loss 71685.15625 reconstruction mse 71679.71875 imputation mse 1.0052833557128906\n",
      "Train Epoch 56.9 var loss 71743.4765625 reconstruction mse 71738.0546875 imputation mse 1.0061014890670776\n",
      "Train Epoch 57.0 var loss 72058.6328125 reconstruction mse 72003.7265625 imputation mse 1.004432201385498\n",
      "Train Epoch 57.1 var loss 71967.7578125 reconstruction mse 71962.1796875 imputation mse 1.0038526058197021\n",
      "Train Epoch 57.2 var loss 71991.9375 reconstruction mse 71986.28125 imputation mse 1.004188895225525\n",
      "Train Epoch 57.3 var loss 71937.6875 reconstruction mse 71932.0 imputation mse 1.0034316778182983\n",
      "Train Epoch 57.4 var loss 71976.2578125 reconstruction mse 71970.5859375 imputation mse 1.0039699077606201\n",
      "Train Epoch 57.5 var loss 71982.09375 reconstruction mse 71976.5 imputation mse 1.0040524005889893\n",
      "Train Epoch 57.6 var loss 71942.953125 reconstruction mse 71937.4296875 imputation mse 1.003507375717163\n",
      "Train Epoch 57.7 var loss 72031.890625 reconstruction mse 72026.4375 imputation mse 1.004749059677124\n",
      "Train Epoch 57.8 var loss 71986.9453125 reconstruction mse 71981.5390625 imputation mse 1.0041227340698242\n",
      "Train Epoch 57.9 var loss 71968.1640625 reconstruction mse 71962.7890625 imputation mse 1.0038611888885498\n",
      "Train Epoch 58.0 var loss 71497.2265625 reconstruction mse 71443.5625 imputation mse 1.0025337934494019\n",
      "Train Epoch 58.1 var loss 71395.5078125 reconstruction mse 71390.0078125 imputation mse 1.0017822980880737\n",
      "Train Epoch 58.2 var loss 71450.96875 reconstruction mse 71445.4140625 imputation mse 1.002559781074524\n",
      "Train Epoch 58.3 var loss 71470.8671875 reconstruction mse 71465.265625 imputation mse 1.0028382539749146\n",
      "Train Epoch 58.4 var loss 71424.7734375 reconstruction mse 71419.2421875 imputation mse 1.002192497253418\n",
      "Train Epoch 58.5 var loss 71447.8515625 reconstruction mse 71442.375 imputation mse 1.0025171041488647\n",
      "Train Epoch 58.6 var loss 71428.53125 reconstruction mse 71423.1171875 imputation mse 1.0022468566894531\n",
      "Train Epoch 58.7 var loss 71491.125 reconstruction mse 71485.8125 imputation mse 1.003126621246338\n",
      "Train Epoch 58.8 var loss 71491.9453125 reconstruction mse 71486.6875 imputation mse 1.0031388998031616\n",
      "Train Epoch 58.9 var loss 71446.21875 reconstruction mse 71441.0 imputation mse 1.0024977922439575\n",
      "Train Epoch 59.0 var loss 71537.2734375 reconstruction mse 71484.6484375 imputation mse 0.9992681741714478\n",
      "Train Epoch 59.1 var loss 71461.890625 reconstruction mse 71456.5234375 imputation mse 0.9988750219345093\n",
      "Train Epoch 59.2 var loss 71443.0703125 reconstruction mse 71437.5859375 imputation mse 0.9986103177070618\n",
      "Train Epoch 59.3 var loss 71471.3671875 reconstruction mse 71465.796875 imputation mse 0.9990046620368958\n",
      "Train Epoch 59.4 var loss 71466.0859375 reconstruction mse 71460.546875 imputation mse 0.9989312887191772\n",
      "Train Epoch 59.5 var loss 71479.40625 reconstruction mse 71473.90625 imputation mse 0.9991180300712585\n",
      "Train Epoch 59.6 var loss 71473.8359375 reconstruction mse 71468.4375 imputation mse 0.9990415573120117\n",
      "Train Epoch 59.7 var loss 71465.734375 reconstruction mse 71460.4453125 imputation mse 0.9989298582077026\n",
      "Train Epoch 59.8 var loss 71447.46875 reconstruction mse 71442.203125 imputation mse 0.9986748695373535\n",
      "Train Epoch 59.9 var loss 71496.03125 reconstruction mse 71490.828125 imputation mse 0.9993546009063721\n",
      "Train Epoch 60.0 var loss 71686.2421875 reconstruction mse 71634.625 imputation mse 0.9964753985404968\n",
      "Train Epoch 60.1 var loss 71612.546875 reconstruction mse 71607.234375 imputation mse 0.9960944056510925\n",
      "Train Epoch 60.2 var loss 71627.8125 reconstruction mse 71622.4140625 imputation mse 0.9963055849075317\n",
      "Train Epoch 60.3 var loss 71637.5390625 reconstruction mse 71632.046875 imputation mse 0.9964395761489868\n",
      "Train Epoch 60.4 var loss 71623.8828125 reconstruction mse 71618.4140625 imputation mse 0.9962499141693115\n",
      "Train Epoch 60.5 var loss 71589.2421875 reconstruction mse 71583.796875 imputation mse 0.9957683682441711\n",
      "Train Epoch 60.6 var loss 71597.25 reconstruction mse 71591.8984375 imputation mse 0.9958810806274414\n",
      "Train Epoch 60.7 var loss 71619.6640625 reconstruction mse 71614.359375 imputation mse 0.996193528175354\n",
      "Train Epoch 60.8 var loss 71572.4765625 reconstruction mse 71567.2265625 imputation mse 0.9955378770828247\n",
      "Train Epoch 60.9 var loss 71682.1484375 reconstruction mse 71676.953125 imputation mse 0.9970642328262329\n",
      "====> Test imputation mse: 0.99869227\n",
      "====> Test imputation mse: 1.01133692\n",
      "====> Test imputation mse: 0.99708092\n",
      "Train Epoch 61.0 var loss 72346.375 reconstruction mse 72295.6171875 imputation mse 1.007997751235962\n",
      "Train Epoch 61.1 var loss 72285.5078125 reconstruction mse 72280.171875 imputation mse 1.0077824592590332\n",
      "Train Epoch 61.2 var loss 72268.2421875 reconstruction mse 72262.765625 imputation mse 1.0075397491455078\n",
      "Train Epoch 61.3 var loss 72323.4765625 reconstruction mse 72317.984375 imputation mse 1.0083096027374268\n",
      "Train Epoch 61.4 var loss 72258.3515625 reconstruction mse 72252.8984375 imputation mse 1.0074021816253662\n",
      "Train Epoch 61.5 var loss 72313.421875 reconstruction mse 72307.953125 imputation mse 1.0081697702407837\n",
      "Train Epoch 61.6 var loss 72255.65625 reconstruction mse 72250.28125 imputation mse 1.0073657035827637\n",
      "Train Epoch 61.7 var loss 72271.140625 reconstruction mse 72265.7578125 imputation mse 1.0075814723968506\n",
      "Train Epoch 61.8 var loss 72251.8828125 reconstruction mse 72246.53125 imputation mse 1.0073133707046509\n",
      "Train Epoch 61.9 var loss 72302.9453125 reconstruction mse 72297.625 imputation mse 1.0080257654190063\n",
      "Train Epoch 62.0 var loss 71736.4765625 reconstruction mse 71686.40625 imputation mse 1.0039972066879272\n",
      "Train Epoch 62.1 var loss 71675.859375 reconstruction mse 71670.4375 imputation mse 1.00377357006073\n",
      "Train Epoch 62.2 var loss 71676.8671875 reconstruction mse 71671.3515625 imputation mse 1.003786325454712\n",
      "Train Epoch 62.3 var loss 71705.9765625 reconstruction mse 71700.359375 imputation mse 1.004192590713501\n",
      "Train Epoch 62.4 var loss 71645.6328125 reconstruction mse 71640.0 imputation mse 1.0033472776412964\n",
      "Train Epoch 62.5 var loss 71682.3125 reconstruction mse 71676.6796875 imputation mse 1.0038609504699707\n",
      "Train Epoch 62.6 var loss 71695.140625 reconstruction mse 71689.578125 imputation mse 1.0040416717529297\n",
      "Train Epoch 62.7 var loss 71711.1171875 reconstruction mse 71705.65625 imputation mse 1.0042668581008911\n",
      "Train Epoch 62.8 var loss 71674.90625 reconstruction mse 71669.515625 imputation mse 1.0037606954574585\n",
      "Train Epoch 62.9 var loss 71706.265625 reconstruction mse 71700.921875 imputation mse 1.0042005777359009\n",
      "Train Epoch 63.0 var loss 72106.2734375 reconstruction mse 72056.90625 imputation mse 1.0052441358566284\n",
      "Train Epoch 63.1 var loss 72071.3828125 reconstruction mse 72065.96875 imputation mse 1.0053706169128418\n",
      "Train Epoch 63.2 var loss 71997.125 reconstruction mse 71991.609375 imputation mse 1.004333257675171\n",
      "Train Epoch 63.3 var loss 72001.6875 reconstruction mse 71996.1640625 imputation mse 1.0043967962265015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 63.4 var loss 72079.0703125 reconstruction mse 72073.5546875 imputation mse 1.0054763555526733\n",
      "Train Epoch 63.5 var loss 72023.703125 reconstruction mse 72018.28125 imputation mse 1.0047053098678589\n",
      "Train Epoch 63.6 var loss 72029.453125 reconstruction mse 72024.09375 imputation mse 1.0047863721847534\n",
      "Train Epoch 63.7 var loss 72065.078125 reconstruction mse 72059.84375 imputation mse 1.0052851438522339\n",
      "Train Epoch 63.8 var loss 72075.046875 reconstruction mse 72069.8125 imputation mse 1.0054242610931396\n",
      "Train Epoch 63.9 var loss 72014.0703125 reconstruction mse 72008.875 imputation mse 1.0045740604400635\n",
      "Train Epoch 64.0 var loss 71906.265625 reconstruction mse 71857.796875 imputation mse 1.0083039999008179\n",
      "Train Epoch 64.1 var loss 71905.453125 reconstruction mse 71900.046875 imputation mse 1.0088969469070435\n",
      "Train Epoch 64.2 var loss 71921.5234375 reconstruction mse 71915.96875 imputation mse 1.0091203451156616\n",
      "Train Epoch 64.3 var loss 71857.921875 reconstruction mse 71852.34375 imputation mse 1.0082275867462158\n",
      "Train Epoch 64.4 var loss 71865.3984375 reconstruction mse 71859.8359375 imputation mse 1.00833261013031\n",
      "Train Epoch 64.5 var loss 71832.28125 reconstruction mse 71826.78125 imputation mse 1.0078688859939575\n",
      "Train Epoch 64.6 var loss 71821.2265625 reconstruction mse 71815.765625 imputation mse 1.0077142715454102\n",
      "Train Epoch 64.7 var loss 71859.7734375 reconstruction mse 71854.390625 imputation mse 1.0082563161849976\n",
      "Train Epoch 64.8 var loss 71844.2265625 reconstruction mse 71838.9140625 imputation mse 1.008039116859436\n",
      "Train Epoch 64.9 var loss 71884.984375 reconstruction mse 71879.6796875 imputation mse 1.0086110830307007\n",
      "Train Epoch 65.0 var loss 71639.59375 reconstruction mse 71592.1484375 imputation mse 1.0031267404556274\n",
      "Train Epoch 65.1 var loss 71593.3984375 reconstruction mse 71587.96875 imputation mse 1.0030680894851685\n",
      "Train Epoch 65.2 var loss 71646.9140625 reconstruction mse 71641.4296875 imputation mse 1.0038172006607056\n",
      "Train Epoch 65.3 var loss 71612.8984375 reconstruction mse 71607.375 imputation mse 1.0033400058746338\n",
      "Train Epoch 65.4 var loss 71623.8671875 reconstruction mse 71618.390625 imputation mse 1.003494381904602\n",
      "Train Epoch 65.5 var loss 71605.5859375 reconstruction mse 71600.15625 imputation mse 1.0032389163970947\n",
      "Train Epoch 65.6 var loss 71589.0 reconstruction mse 71583.65625 imputation mse 1.0030076503753662\n",
      "Train Epoch 65.7 var loss 71586.6015625 reconstruction mse 71581.3359375 imputation mse 1.0029752254486084\n",
      "Train Epoch 65.8 var loss 71616.8671875 reconstruction mse 71611.671875 imputation mse 1.003400206565857\n",
      "Train Epoch 65.9 var loss 71609.59375 reconstruction mse 71604.40625 imputation mse 1.0032984018325806\n",
      "Train Epoch 66.0 var loss 71408.765625 reconstruction mse 71362.2578125 imputation mse 1.0001578330993652\n",
      "Train Epoch 66.1 var loss 71347.890625 reconstruction mse 71342.625 imputation mse 0.9998826384544373\n",
      "Train Epoch 66.2 var loss 71372.515625 reconstruction mse 71367.2109375 imputation mse 1.0002272129058838\n",
      "Train Epoch 66.3 var loss 71323.640625 reconstruction mse 71318.34375 imputation mse 0.9995422959327698\n",
      "Train Epoch 66.4 var loss 71332.3828125 reconstruction mse 71327.09375 imputation mse 0.9996649622917175\n",
      "Train Epoch 66.5 var loss 71380.4609375 reconstruction mse 71375.2421875 imputation mse 1.0003397464752197\n",
      "Train Epoch 66.6 var loss 71353.8046875 reconstruction mse 71348.671875 imputation mse 0.9999673962593079\n",
      "Train Epoch 66.7 var loss 71340.0078125 reconstruction mse 71334.9375 imputation mse 0.9997748732566833\n",
      "Train Epoch 66.8 var loss 71324.8203125 reconstruction mse 71319.71875 imputation mse 0.999561607837677\n",
      "Train Epoch 66.9 var loss 71365.9921875 reconstruction mse 71360.9453125 imputation mse 1.0001393556594849\n",
      "Train Epoch 67.0 var loss 71654.3984375 reconstruction mse 71608.796875 imputation mse 1.0013536214828491\n",
      "Train Epoch 67.1 var loss 71657.7421875 reconstruction mse 71652.53125 imputation mse 1.0019651651382446\n",
      "Train Epoch 67.2 var loss 71633.8125 reconstruction mse 71628.421875 imputation mse 1.001628041267395\n",
      "Train Epoch 67.3 var loss 71634.9140625 reconstruction mse 71629.5 imputation mse 1.0016430616378784\n",
      "Train Epoch 67.4 var loss 71689.5390625 reconstruction mse 71684.1484375 imputation mse 1.0024073123931885\n",
      "Train Epoch 67.5 var loss 71624.984375 reconstruction mse 71619.6171875 imputation mse 1.001504898071289\n",
      "Train Epoch 67.6 var loss 71646.375 reconstruction mse 71641.109375 imputation mse 1.0018054246902466\n",
      "Train Epoch 67.7 var loss 71649.40625 reconstruction mse 71644.1953125 imputation mse 1.001848578453064\n",
      "Train Epoch 67.8 var loss 71647.7734375 reconstruction mse 71642.65625 imputation mse 1.0018270015716553\n",
      "Train Epoch 67.9 var loss 71677.4921875 reconstruction mse 71672.421875 imputation mse 1.0022432804107666\n",
      "Train Epoch 68.0 var loss 72167.3515625 reconstruction mse 72122.734375 imputation mse 1.007511854171753\n",
      "Train Epoch 68.1 var loss 72195.9453125 reconstruction mse 72190.75 imputation mse 1.0084619522094727\n",
      "Train Epoch 68.2 var loss 72135.78125 reconstruction mse 72130.484375 imputation mse 1.007620096206665\n",
      "Train Epoch 68.3 var loss 72179.203125 reconstruction mse 72173.8984375 imputation mse 1.0082265138626099\n",
      "Train Epoch 68.4 var loss 72160.9296875 reconstruction mse 72155.609375 imputation mse 1.0079710483551025\n",
      "Train Epoch 68.5 var loss 72154.234375 reconstruction mse 72149.0 imputation mse 1.0078787803649902\n",
      "Train Epoch 68.6 var loss 72150.28125 reconstruction mse 72145.078125 imputation mse 1.0078239440917969\n",
      "Train Epoch 68.7 var loss 72145.9453125 reconstruction mse 72140.8046875 imputation mse 1.007764220237732\n",
      "Train Epoch 68.8 var loss 72146.40625 reconstruction mse 72141.3125 imputation mse 1.007771372795105\n",
      "Train Epoch 68.9 var loss 72163.5390625 reconstruction mse 72158.453125 imputation mse 1.008010745048523\n",
      "Train Epoch 69.0 var loss 70748.8125 reconstruction mse 70704.984375 imputation mse 0.9994626045227051\n",
      "Train Epoch 69.1 var loss 70751.71875 reconstruction mse 70746.453125 imputation mse 1.0000487565994263\n",
      "Train Epoch 69.2 var loss 70742.3203125 reconstruction mse 70736.9375 imputation mse 0.999914288520813\n",
      "Train Epoch 69.3 var loss 70739.8515625 reconstruction mse 70734.4609375 imputation mse 0.9998793005943298\n",
      "Train Epoch 69.4 var loss 70746.8359375 reconstruction mse 70741.5078125 imputation mse 0.9999788999557495\n",
      "Train Epoch 69.5 var loss 70694.7578125 reconstruction mse 70689.4921875 imputation mse 0.9992436170578003\n",
      "Train Epoch 69.6 var loss 70770.2734375 reconstruction mse 70765.1015625 imputation mse 1.0003124475479126\n",
      "Train Epoch 69.7 var loss 70725.8828125 reconstruction mse 70720.8125 imputation mse 0.9996863603591919\n",
      "Train Epoch 69.8 var loss 70782.78125 reconstruction mse 70777.703125 imputation mse 1.0004905462265015\n",
      "Train Epoch 69.9 var loss 70754.671875 reconstruction mse 70749.6015625 imputation mse 1.0000933408737183\n",
      "Train Epoch 70.0 var loss 71463.2890625 reconstruction mse 71420.25 imputation mse 1.0048999786376953\n",
      "Train Epoch 70.1 var loss 71405.9453125 reconstruction mse 71400.6640625 imputation mse 1.004624366760254\n",
      "Train Epoch 70.2 var loss 71407.7421875 reconstruction mse 71402.296875 imputation mse 1.0046473741531372\n",
      "Train Epoch 70.3 var loss 71413.6875 reconstruction mse 71408.140625 imputation mse 1.0047296285629272\n",
      "Train Epoch 70.4 var loss 71443.53125 reconstruction mse 71437.9765625 imputation mse 1.0051493644714355\n",
      "Train Epoch 70.5 var loss 71381.59375 reconstruction mse 71376.109375 imputation mse 1.0042788982391357\n",
      "Train Epoch 70.6 var loss 71470.453125 reconstruction mse 71465.078125 imputation mse 1.0055307149887085\n",
      "Train Epoch 70.7 var loss 71409.2890625 reconstruction mse 71404.0390625 imputation mse 1.0046718120574951\n",
      "Train Epoch 70.8 var loss 71401.7578125 reconstruction mse 71396.6328125 imputation mse 1.0045676231384277\n",
      "Train Epoch 70.9 var loss 71429.5546875 reconstruction mse 71424.515625 imputation mse 1.0049599409103394\n",
      "====> Test imputation mse: 1.00089443\n",
      "====> Test imputation mse: 1.00207615\n",
      "====> Test imputation mse: 1.00954962\n",
      "Train Epoch 71.0 var loss 70888.25 reconstruction mse 70845.9765625 imputation mse 1.000847339630127\n",
      "Train Epoch 71.1 var loss 70790.4765625 reconstruction mse 70785.4296875 imputation mse 0.9999919533729553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 71.2 var loss 70776.8046875 reconstruction mse 70771.65625 imputation mse 0.9997973442077637\n",
      "Train Epoch 71.3 var loss 70823.8203125 reconstruction mse 70818.6640625 imputation mse 1.000461459159851\n",
      "Train Epoch 71.4 var loss 70786.6484375 reconstruction mse 70781.453125 imputation mse 0.9999357461929321\n",
      "Train Epoch 71.5 var loss 70759.546875 reconstruction mse 70754.3828125 imputation mse 0.9995533227920532\n",
      "Train Epoch 71.6 var loss 70829.8203125 reconstruction mse 70824.65625 imputation mse 1.0005460977554321\n",
      "Train Epoch 71.7 var loss 70787.8671875 reconstruction mse 70782.7890625 imputation mse 0.9999546408653259\n",
      "Train Epoch 71.8 var loss 70793.6328125 reconstruction mse 70788.578125 imputation mse 1.0000364780426025\n",
      "Train Epoch 71.9 var loss 70782.6328125 reconstruction mse 70777.5703125 imputation mse 0.9998809099197388\n",
      "Train Epoch 72.0 var loss 71256.7734375 reconstruction mse 71215.15625 imputation mse 1.000002145767212\n",
      "Train Epoch 72.1 var loss 71162.234375 reconstruction mse 71157.0 imputation mse 0.9991855621337891\n",
      "Train Epoch 72.2 var loss 71165.9921875 reconstruction mse 71160.6484375 imputation mse 0.9992368221282959\n",
      "Train Epoch 72.3 var loss 71175.7578125 reconstruction mse 71170.359375 imputation mse 0.9993731379508972\n",
      "Train Epoch 72.4 var loss 71213.4375 reconstruction mse 71208.0703125 imputation mse 0.9999026656150818\n",
      "Train Epoch 72.5 var loss 71182.9296875 reconstruction mse 71177.625 imputation mse 0.9994751811027527\n",
      "Train Epoch 72.6 var loss 71216.71875 reconstruction mse 71211.546875 imputation mse 0.9999514818191528\n",
      "Train Epoch 72.7 var loss 71201.8359375 reconstruction mse 71196.7109375 imputation mse 0.9997431635856628\n",
      "Train Epoch 72.8 var loss 71197.0859375 reconstruction mse 71192.0703125 imputation mse 0.9996780157089233\n",
      "Train Epoch 72.9 var loss 71194.9921875 reconstruction mse 71190.0234375 imputation mse 0.9996492862701416\n",
      "Train Epoch 73.0 var loss 71151.96875 reconstruction mse 71111.0625 imputation mse 1.0026092529296875\n",
      "Train Epoch 73.1 var loss 71088.9921875 reconstruction mse 71083.8828125 imputation mse 1.0022259950637817\n",
      "Train Epoch 73.2 var loss 71069.9921875 reconstruction mse 71064.828125 imputation mse 1.0019574165344238\n",
      "Train Epoch 73.3 var loss 71105.09375 reconstruction mse 71099.9296875 imputation mse 1.0024522542953491\n",
      "Train Epoch 73.4 var loss 71038.2734375 reconstruction mse 71033.140625 imputation mse 1.0015106201171875\n",
      "Train Epoch 73.5 var loss 71054.8046875 reconstruction mse 71049.703125 imputation mse 1.0017441511154175\n",
      "Train Epoch 73.6 var loss 71035.53125 reconstruction mse 71030.5078125 imputation mse 1.0014734268188477\n",
      "Train Epoch 73.7 var loss 71084.46875 reconstruction mse 71079.4296875 imputation mse 1.002163290977478\n",
      "Train Epoch 73.8 var loss 71023.234375 reconstruction mse 71018.2265625 imputation mse 1.00130033493042\n",
      "Train Epoch 73.9 var loss 71069.8828125 reconstruction mse 71064.8515625 imputation mse 1.001957654953003\n",
      "Train Epoch 74.0 var loss 71606.0703125 reconstruction mse 71565.6640625 imputation mse 1.0077542066574097\n",
      "Train Epoch 74.1 var loss 71621.3828125 reconstruction mse 71616.1953125 imputation mse 1.0084657669067383\n",
      "Train Epoch 74.2 var loss 71611.4453125 reconstruction mse 71606.1796875 imputation mse 1.0083247423171997\n",
      "Train Epoch 74.3 var loss 71554.90625 reconstruction mse 71549.625 imputation mse 1.007528305053711\n",
      "Train Epoch 74.4 var loss 71572.4609375 reconstruction mse 71567.234375 imputation mse 1.0077762603759766\n",
      "Train Epoch 74.5 var loss 71602.6875 reconstruction mse 71597.53125 imputation mse 1.0082029104232788\n",
      "Train Epoch 74.6 var loss 71539.9453125 reconstruction mse 71534.8828125 imputation mse 1.007320761680603\n",
      "Train Epoch 74.7 var loss 71582.1328125 reconstruction mse 71577.125 imputation mse 1.0079156160354614\n",
      "Train Epoch 74.8 var loss 71605.515625 reconstruction mse 71600.5859375 imputation mse 1.0082459449768066\n",
      "Train Epoch 74.9 var loss 71588.2421875 reconstruction mse 71583.328125 imputation mse 1.0080028772354126\n",
      "Train Epoch 75.0 var loss 71791.6640625 reconstruction mse 71751.96875 imputation mse 1.0057464838027954\n",
      "Train Epoch 75.1 var loss 71751.09375 reconstruction mse 71745.9921875 imputation mse 1.0056627988815308\n",
      "Train Epoch 75.2 var loss 71738.0859375 reconstruction mse 71732.9375 imputation mse 1.0054798126220703\n",
      "Train Epoch 75.3 var loss 71783.0625 reconstruction mse 71777.859375 imputation mse 1.0061094760894775\n",
      "Train Epoch 75.4 var loss 71788.375 reconstruction mse 71783.2265625 imputation mse 1.006184697151184\n",
      "Train Epoch 75.5 var loss 71790.3203125 reconstruction mse 71785.25 imputation mse 1.0062130689620972\n",
      "Train Epoch 75.6 var loss 71734.546875 reconstruction mse 71729.59375 imputation mse 1.0054328441619873\n",
      "Train Epoch 75.7 var loss 71817.390625 reconstruction mse 71812.53125 imputation mse 1.0065953731536865\n",
      "Train Epoch 75.8 var loss 71741.1796875 reconstruction mse 71736.3828125 imputation mse 1.0055280923843384\n",
      "Train Epoch 75.9 var loss 71740.3515625 reconstruction mse 71735.578125 imputation mse 1.005516767501831\n",
      "Train Epoch 76.0 var loss 71586.5859375 reconstruction mse 71547.8359375 imputation mse 1.001075029373169\n",
      "Train Epoch 76.1 var loss 71567.59375 reconstruction mse 71562.6171875 imputation mse 1.0012818574905396\n",
      "Train Epoch 76.2 var loss 71535.0078125 reconstruction mse 71529.859375 imputation mse 1.0008234977722168\n",
      "Train Epoch 76.3 var loss 71548.5859375 reconstruction mse 71543.3515625 imputation mse 1.0010123252868652\n",
      "Train Epoch 76.4 var loss 71519.34375 reconstruction mse 71514.0859375 imputation mse 1.0006028413772583\n",
      "Train Epoch 76.5 var loss 71573.078125 reconstruction mse 71567.8203125 imputation mse 1.001354694366455\n",
      "Train Epoch 76.6 var loss 71578.53125 reconstruction mse 71573.390625 imputation mse 1.0014326572418213\n",
      "Train Epoch 76.7 var loss 71574.4140625 reconstruction mse 71569.3515625 imputation mse 1.0013761520385742\n",
      "Train Epoch 76.8 var loss 71541.3984375 reconstruction mse 71536.4609375 imputation mse 1.0009158849716187\n",
      "Train Epoch 76.9 var loss 71546.5390625 reconstruction mse 71541.7109375 imputation mse 1.000989317893982\n",
      "Train Epoch 77.0 var loss 72072.984375 reconstruction mse 72034.6484375 imputation mse 1.0070128440856934\n",
      "Train Epoch 77.1 var loss 72118.9375 reconstruction mse 72114.0625 imputation mse 1.0081230401992798\n",
      "Train Epoch 77.2 var loss 72131.2890625 reconstruction mse 72126.3359375 imputation mse 1.0082945823669434\n",
      "Train Epoch 77.3 var loss 72078.9296875 reconstruction mse 72073.921875 imputation mse 1.0075618028640747\n",
      "Train Epoch 77.4 var loss 72083.6875 reconstruction mse 72078.6796875 imputation mse 1.007628321647644\n",
      "Train Epoch 77.5 var loss 72098.5078125 reconstruction mse 72093.5390625 imputation mse 1.007836103439331\n",
      "Train Epoch 77.6 var loss 72101.3359375 reconstruction mse 72096.46875 imputation mse 1.007876992225647\n",
      "Train Epoch 77.7 var loss 72073.390625 reconstruction mse 72068.5625 imputation mse 1.0074869394302368\n",
      "Train Epoch 77.8 var loss 72127.2890625 reconstruction mse 72122.484375 imputation mse 1.0082406997680664\n",
      "Train Epoch 77.9 var loss 72107.921875 reconstruction mse 72103.140625 imputation mse 1.0079703330993652\n",
      "Train Epoch 78.0 var loss 72797.28125 reconstruction mse 72759.46875 imputation mse 1.0088527202606201\n",
      "Train Epoch 78.1 var loss 72774.75 reconstruction mse 72769.8046875 imputation mse 1.0089960098266602\n",
      "Train Epoch 78.2 var loss 72728.1875 reconstruction mse 72723.1328125 imputation mse 1.0083489418029785\n",
      "Train Epoch 78.3 var loss 72732.0078125 reconstruction mse 72726.8984375 imputation mse 1.0084011554718018\n",
      "Train Epoch 78.4 var loss 72701.5703125 reconstruction mse 72696.5 imputation mse 1.0079796314239502\n",
      "Train Epoch 78.5 var loss 72747.0390625 reconstruction mse 72742.03125 imputation mse 1.0086109638214111\n",
      "Train Epoch 78.6 var loss 72753.6640625 reconstruction mse 72748.71875 imputation mse 1.0087037086486816\n",
      "Train Epoch 78.7 var loss 72728.4921875 reconstruction mse 72723.6171875 imputation mse 1.0083556175231934\n",
      "Train Epoch 78.8 var loss 72743.46875 reconstruction mse 72738.6640625 imputation mse 1.0085642337799072\n",
      "Train Epoch 78.9 var loss 72781.1640625 reconstruction mse 72776.375 imputation mse 1.0090872049331665\n",
      "Train Epoch 79.0 var loss 72048.3203125 reconstruction mse 72011.109375 imputation mse 1.0067682266235352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 79.1 var loss 71926.0390625 reconstruction mse 71921.1015625 imputation mse 1.005509853363037\n",
      "Train Epoch 79.2 var loss 71964.296875 reconstruction mse 71959.2578125 imputation mse 1.0060433149337769\n",
      "Train Epoch 79.3 var loss 71952.53125 reconstruction mse 71947.4375 imputation mse 1.00587797164917\n",
      "Train Epoch 79.4 var loss 71944.8515625 reconstruction mse 71939.6953125 imputation mse 1.0057697296142578\n",
      "Train Epoch 79.5 var loss 71915.0234375 reconstruction mse 71909.9140625 imputation mse 1.0053534507751465\n",
      "Train Epoch 79.6 var loss 71990.265625 reconstruction mse 71985.1796875 imputation mse 1.0064057111740112\n",
      "Train Epoch 79.7 var loss 71957.9375 reconstruction mse 71952.921875 imputation mse 1.0059547424316406\n",
      "Train Epoch 79.8 var loss 71993.4296875 reconstruction mse 71988.53125 imputation mse 1.0064525604248047\n",
      "Train Epoch 79.9 var loss 72012.9453125 reconstruction mse 72008.0546875 imputation mse 1.006725549697876\n",
      "Train Epoch 80.0 var loss 72134.40625 reconstruction mse 72097.8515625 imputation mse 1.0018877983093262\n",
      "Train Epoch 80.1 var loss 72138.09375 reconstruction mse 72133.09375 imputation mse 1.0023775100708008\n",
      "Train Epoch 80.2 var loss 72112.0546875 reconstruction mse 72106.9765625 imputation mse 1.0020146369934082\n",
      "Train Epoch 80.3 var loss 72127.2890625 reconstruction mse 72122.1328125 imputation mse 1.0022252798080444\n",
      "Train Epoch 80.4 var loss 72160.9375 reconstruction mse 72155.78125 imputation mse 1.0026928186416626\n",
      "Train Epoch 80.5 var loss 72160.6328125 reconstruction mse 72155.5390625 imputation mse 1.0026894807815552\n",
      "Train Epoch 80.6 var loss 72146.0390625 reconstruction mse 72141.0 imputation mse 1.0024874210357666\n",
      "Train Epoch 80.7 var loss 72152.53125 reconstruction mse 72147.578125 imputation mse 1.002578854560852\n",
      "Train Epoch 80.8 var loss 72155.09375 reconstruction mse 72150.1875 imputation mse 1.0026150941848755\n",
      "Train Epoch 80.9 var loss 72164.46875 reconstruction mse 72159.5859375 imputation mse 1.0027457475662231\n",
      "====> Test imputation mse: 1.00935531\n",
      "====> Test imputation mse: 1.01592612\n",
      "====> Test imputation mse: 1.00406373\n",
      "Train Epoch 81.0 var loss 71722.59375 reconstruction mse 71686.84375 imputation mse 1.0026973485946655\n",
      "Train Epoch 81.1 var loss 71644.59375 reconstruction mse 71639.609375 imputation mse 1.002036690711975\n",
      "Train Epoch 81.2 var loss 71602.9296875 reconstruction mse 71597.8359375 imputation mse 1.0014523267745972\n",
      "Train Epoch 81.3 var loss 71660.625 reconstruction mse 71655.4921875 imputation mse 1.0022587776184082\n",
      "Train Epoch 81.4 var loss 71653.9765625 reconstruction mse 71648.828125 imputation mse 1.0021655559539795\n",
      "Train Epoch 81.5 var loss 71659.125 reconstruction mse 71654.046875 imputation mse 1.0022386312484741\n",
      "Train Epoch 81.6 var loss 71665.1875 reconstruction mse 71660.2265625 imputation mse 1.0023250579833984\n",
      "Train Epoch 81.7 var loss 71681.8046875 reconstruction mse 71676.9453125 imputation mse 1.002558946609497\n",
      "Train Epoch 81.8 var loss 71664.546875 reconstruction mse 71659.7890625 imputation mse 1.0023189783096313\n",
      "Train Epoch 81.9 var loss 71689.125 reconstruction mse 71684.3984375 imputation mse 1.0026631355285645\n",
      "Train Epoch 82.0 var loss 72008.59375 reconstruction mse 71973.484375 imputation mse 1.0030169486999512\n",
      "Train Epoch 82.1 var loss 71936.65625 reconstruction mse 71931.859375 imputation mse 1.002436876296997\n",
      "Train Epoch 82.2 var loss 71962.6328125 reconstruction mse 71957.75 imputation mse 1.0027976036071777\n",
      "Train Epoch 82.3 var loss 71970.7890625 reconstruction mse 71965.8359375 imputation mse 1.0029103755950928\n",
      "Train Epoch 82.4 var loss 71915.7734375 reconstruction mse 71910.7890625 imputation mse 1.002143144607544\n",
      "Train Epoch 82.5 var loss 71966.3359375 reconstruction mse 71961.359375 imputation mse 1.0028479099273682\n",
      "Train Epoch 82.6 var loss 71972.0234375 reconstruction mse 71967.078125 imputation mse 1.0029276609420776\n",
      "Train Epoch 82.7 var loss 71961.484375 reconstruction mse 71956.6171875 imputation mse 1.002781867980957\n",
      "Train Epoch 82.8 var loss 71927.515625 reconstruction mse 71922.71875 imputation mse 1.0023094415664673\n",
      "Train Epoch 82.9 var loss 71941.109375 reconstruction mse 71936.3671875 imputation mse 1.0024996995925903\n",
      "Train Epoch 83.0 var loss 71676.53125 reconstruction mse 71642.109375 imputation mse 1.0024222135543823\n",
      "Train Epoch 83.1 var loss 71589.5234375 reconstruction mse 71584.734375 imputation mse 1.0016193389892578\n",
      "Train Epoch 83.2 var loss 71605.4921875 reconstruction mse 71600.671875 imputation mse 1.0018423795700073\n",
      "Train Epoch 83.3 var loss 71596.4921875 reconstruction mse 71591.6484375 imputation mse 1.001716136932373\n",
      "Train Epoch 83.4 var loss 71648.2265625 reconstruction mse 71643.40625 imputation mse 1.002440333366394\n",
      "Train Epoch 83.5 var loss 71625.4140625 reconstruction mse 71620.625 imputation mse 1.0021215677261353\n",
      "Train Epoch 83.6 var loss 71621.1640625 reconstruction mse 71616.4453125 imputation mse 1.0020630359649658\n",
      "Train Epoch 83.7 var loss 71659.046875 reconstruction mse 71654.4140625 imputation mse 1.0025943517684937\n",
      "Train Epoch 83.8 var loss 71621.0859375 reconstruction mse 71616.46875 imputation mse 1.0020633935928345\n",
      "Train Epoch 83.9 var loss 71647.828125 reconstruction mse 71643.21875 imputation mse 1.002437710762024\n",
      "Train Epoch 84.0 var loss 71723.25 reconstruction mse 71689.4375 imputation mse 1.0070720911026\n",
      "Train Epoch 84.1 var loss 71715.6328125 reconstruction mse 71710.859375 imputation mse 1.0073730945587158\n",
      "Train Epoch 84.2 var loss 71717.3203125 reconstruction mse 71712.421875 imputation mse 1.0073950290679932\n",
      "Train Epoch 84.3 var loss 71717.6015625 reconstruction mse 71712.6796875 imputation mse 1.0073986053466797\n",
      "Train Epoch 84.4 var loss 71657.984375 reconstruction mse 71653.078125 imputation mse 1.0065613985061646\n",
      "Train Epoch 84.5 var loss 71664.3671875 reconstruction mse 71659.5 imputation mse 1.0066516399383545\n",
      "Train Epoch 84.6 var loss 71639.796875 reconstruction mse 71635.03125 imputation mse 1.00630784034729\n",
      "Train Epoch 84.7 var loss 71725.2734375 reconstruction mse 71720.59375 imputation mse 1.0075098276138306\n",
      "Train Epoch 84.8 var loss 71689.75 reconstruction mse 71685.1171875 imputation mse 1.0070114135742188\n",
      "Train Epoch 84.9 var loss 71693.5 reconstruction mse 71688.8984375 imputation mse 1.0070645809173584\n",
      "Train Epoch 85.0 var loss 71806.7109375 reconstruction mse 71773.53125 imputation mse 1.0043312311172485\n",
      "Train Epoch 85.1 var loss 71742.8984375 reconstruction mse 71738.1640625 imputation mse 1.0038363933563232\n",
      "Train Epoch 85.2 var loss 71718.390625 reconstruction mse 71713.5625 imputation mse 1.0034921169281006\n",
      "Train Epoch 85.3 var loss 71746.3046875 reconstruction mse 71741.421875 imputation mse 1.0038819313049316\n",
      "Train Epoch 85.4 var loss 71689.6953125 reconstruction mse 71684.796875 imputation mse 1.0030896663665771\n",
      "Train Epoch 85.5 var loss 71711.390625 reconstruction mse 71706.5390625 imputation mse 1.0033938884735107\n",
      "Train Epoch 85.6 var loss 71760.1015625 reconstruction mse 71755.3125 imputation mse 1.004076361656189\n",
      "Train Epoch 85.7 var loss 71717.1015625 reconstruction mse 71712.3828125 imputation mse 1.0034756660461426\n",
      "Train Epoch 85.8 var loss 71655.9609375 reconstruction mse 71651.2421875 imputation mse 1.0026201009750366\n",
      "Train Epoch 85.9 var loss 71725.5390625 reconstruction mse 71720.84375 imputation mse 1.0035940408706665\n",
      "Train Epoch 86.0 var loss 71249.359375 reconstruction mse 71216.609375 imputation mse 0.9970265626907349\n",
      "Train Epoch 86.1 var loss 71194.140625 reconstruction mse 71189.2578125 imputation mse 0.996643602848053\n",
      "Train Epoch 86.2 var loss 71282.765625 reconstruction mse 71277.7578125 imputation mse 0.997882604598999\n",
      "Train Epoch 86.3 var loss 71206.25 reconstruction mse 71201.2109375 imputation mse 0.9968109726905823\n",
      "Train Epoch 86.4 var loss 71258.0703125 reconstruction mse 71253.0390625 imputation mse 0.9975365400314331\n",
      "Train Epoch 86.5 var loss 71225.1171875 reconstruction mse 71220.140625 imputation mse 0.9970759749412537\n",
      "Train Epoch 86.6 var loss 71224.0546875 reconstruction mse 71219.1484375 imputation mse 0.997062087059021\n",
      "Train Epoch 86.7 var loss 71236.4140625 reconstruction mse 71231.640625 imputation mse 0.997236967086792\n",
      "Train Epoch 86.8 var loss 71211.03125 reconstruction mse 71206.3671875 imputation mse 0.9968831539154053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 86.9 var loss 71260.0703125 reconstruction mse 71255.421875 imputation mse 0.9975699186325073\n",
      "Train Epoch 87.0 var loss 71869.6875 reconstruction mse 71837.6328125 imputation mse 1.0104598999023438\n",
      "Train Epoch 87.1 var loss 71783.6875 reconstruction mse 71778.875 imputation mse 1.0096334218978882\n",
      "Train Epoch 87.2 var loss 71821.7578125 reconstruction mse 71816.8515625 imputation mse 1.0101675987243652\n",
      "Train Epoch 87.3 var loss 71841.0625 reconstruction mse 71836.0625 imputation mse 1.0104377269744873\n",
      "Train Epoch 87.4 var loss 71829.6796875 reconstruction mse 71824.7265625 imputation mse 1.010278344154358\n",
      "Train Epoch 87.5 var loss 71828.5546875 reconstruction mse 71823.6484375 imputation mse 1.010263204574585\n",
      "Train Epoch 87.6 var loss 71839.4921875 reconstruction mse 71834.6875 imputation mse 1.01041841506958\n",
      "Train Epoch 87.7 var loss 71856.2578125 reconstruction mse 71851.5234375 imputation mse 1.0106552839279175\n",
      "Train Epoch 87.8 var loss 71846.90625 reconstruction mse 71842.21875 imputation mse 1.0105243921279907\n",
      "Train Epoch 87.9 var loss 71829.4296875 reconstruction mse 71824.7578125 imputation mse 1.0102787017822266\n",
      "Train Epoch 88.0 var loss 72028.828125 reconstruction mse 71997.421875 imputation mse 1.0053679943084717\n",
      "Train Epoch 88.1 var loss 71944.3671875 reconstruction mse 71939.5703125 imputation mse 1.0045602321624756\n",
      "Train Epoch 88.2 var loss 71999.609375 reconstruction mse 71994.6796875 imputation mse 1.0053297281265259\n",
      "Train Epoch 88.3 var loss 71950.828125 reconstruction mse 71945.8359375 imputation mse 1.0046477317810059\n",
      "Train Epoch 88.4 var loss 71940.2109375 reconstruction mse 71935.2265625 imputation mse 1.0044995546340942\n",
      "Train Epoch 88.5 var loss 71996.328125 reconstruction mse 71991.40625 imputation mse 1.005284070968628\n",
      "Train Epoch 88.6 var loss 71947.9375 reconstruction mse 71943.0625 imputation mse 1.0046089887619019\n",
      "Train Epoch 88.7 var loss 71996.1015625 reconstruction mse 71991.28125 imputation mse 1.0052822828292847\n",
      "Train Epoch 88.8 var loss 71972.78125 reconstruction mse 71968.0546875 imputation mse 1.004957914352417\n",
      "Train Epoch 88.9 var loss 71926.1640625 reconstruction mse 71921.5078125 imputation mse 1.0043079853057861\n",
      "Train Epoch 89.0 var loss 71831.6171875 reconstruction mse 71800.546875 imputation mse 1.0033894777297974\n",
      "Train Epoch 89.1 var loss 71812.640625 reconstruction mse 71807.875 imputation mse 1.0034918785095215\n",
      "Train Epoch 89.2 var loss 71821.7109375 reconstruction mse 71816.890625 imputation mse 1.0036178827285767\n",
      "Train Epoch 89.3 var loss 71802.203125 reconstruction mse 71797.375 imputation mse 1.0033451318740845\n",
      "Train Epoch 89.4 var loss 71844.1875 reconstruction mse 71839.390625 imputation mse 1.0039323568344116\n",
      "Train Epoch 89.5 var loss 71838.109375 reconstruction mse 71833.34375 imputation mse 1.0038478374481201\n",
      "Train Epoch 89.6 var loss 71848.578125 reconstruction mse 71843.90625 imputation mse 1.003995418548584\n",
      "Train Epoch 89.7 var loss 71788.96875 reconstruction mse 71784.2890625 imputation mse 1.0031622648239136\n",
      "Train Epoch 89.8 var loss 71843.296875 reconstruction mse 71838.640625 imputation mse 1.0039218664169312\n",
      "Train Epoch 89.9 var loss 71807.59375 reconstruction mse 71802.90625 imputation mse 1.003422498703003\n",
      "Train Epoch 90.0 var loss 71912.6328125 reconstruction mse 71882.0390625 imputation mse 1.0023571252822876\n",
      "Train Epoch 90.1 var loss 71942.671875 reconstruction mse 71937.8828125 imputation mse 1.0031359195709229\n",
      "Train Epoch 90.2 var loss 71968.5078125 reconstruction mse 71963.640625 imputation mse 1.0034950971603394\n",
      "Train Epoch 90.3 var loss 71891.0390625 reconstruction mse 71886.1796875 imputation mse 1.0024149417877197\n",
      "Train Epoch 90.4 var loss 71930.6484375 reconstruction mse 71925.828125 imputation mse 1.0029678344726562\n",
      "Train Epoch 90.5 var loss 71891.1796875 reconstruction mse 71886.4609375 imputation mse 1.002418875694275\n",
      "Train Epoch 90.6 var loss 71936.1953125 reconstruction mse 71931.515625 imputation mse 1.0030471086502075\n",
      "Train Epoch 90.7 var loss 71893.28125 reconstruction mse 71888.6328125 imputation mse 1.0024491548538208\n",
      "Train Epoch 90.8 var loss 71894.671875 reconstruction mse 71890.046875 imputation mse 1.0024688243865967\n",
      "Train Epoch 90.9 var loss 71924.0546875 reconstruction mse 71919.4296875 imputation mse 1.0028785467147827\n",
      "====> Test imputation mse: 1.00959468\n",
      "====> Test imputation mse: 0.98652720\n",
      "====> Test imputation mse: 1.01375687\n",
      "Train Epoch 91.0 var loss 71411.125 reconstruction mse 71381.1953125 imputation mse 0.9964708685874939\n",
      "Train Epoch 91.1 var loss 71411.6171875 reconstruction mse 71406.828125 imputation mse 0.9968287348747253\n",
      "Train Epoch 91.2 var loss 71416.3359375 reconstruction mse 71411.4296875 imputation mse 0.9968929290771484\n",
      "Train Epoch 91.3 var loss 71403.0546875 reconstruction mse 71398.1640625 imputation mse 0.9967077374458313\n",
      "Train Epoch 91.4 var loss 71360.28125 reconstruction mse 71355.4453125 imputation mse 0.9961113929748535\n",
      "Train Epoch 91.5 var loss 71464.5859375 reconstruction mse 71459.8046875 imputation mse 0.9975682497024536\n",
      "Train Epoch 91.6 var loss 71432.0703125 reconstruction mse 71427.375 imputation mse 0.9971155524253845\n",
      "Train Epoch 91.7 var loss 71385.0078125 reconstruction mse 71380.390625 imputation mse 0.9964596629142761\n",
      "Train Epoch 91.8 var loss 71365.984375 reconstruction mse 71361.4140625 imputation mse 0.9961947202682495\n",
      "Train Epoch 91.9 var loss 71381.078125 reconstruction mse 71376.546875 imputation mse 0.9964060187339783\n",
      "Train Epoch 92.0 var loss 71979.515625 reconstruction mse 71950.1875 imputation mse 1.0113744735717773\n",
      "Train Epoch 92.1 var loss 71952.3515625 reconstruction mse 71947.7109375 imputation mse 1.0113396644592285\n",
      "Train Epoch 92.2 var loss 71910.6640625 reconstruction mse 71905.8984375 imputation mse 1.0107518434524536\n",
      "Train Epoch 92.3 var loss 71900.40625 reconstruction mse 71895.609375 imputation mse 1.0106072425842285\n",
      "Train Epoch 92.4 var loss 71949.1953125 reconstruction mse 71944.4296875 imputation mse 1.0112935304641724\n",
      "Train Epoch 92.5 var loss 71929.96875 reconstruction mse 71925.2734375 imputation mse 1.0110242366790771\n",
      "Train Epoch 92.6 var loss 71965.8359375 reconstruction mse 71961.1796875 imputation mse 1.0115289688110352\n",
      "Train Epoch 92.7 var loss 71877.375 reconstruction mse 71872.7890625 imputation mse 1.0102864503860474\n",
      "Train Epoch 92.8 var loss 71886.09375 reconstruction mse 71881.484375 imputation mse 1.010408639907837\n",
      "Train Epoch 92.9 var loss 71937.3828125 reconstruction mse 71932.7421875 imputation mse 1.0111291408538818\n",
      "Train Epoch 93.0 var loss 71752.8203125 reconstruction mse 71723.5859375 imputation mse 1.0037587881088257\n",
      "Train Epoch 93.1 var loss 71732.703125 reconstruction mse 71727.828125 imputation mse 1.003818154335022\n",
      "Train Epoch 93.2 var loss 71771.3984375 reconstruction mse 71766.4296875 imputation mse 1.0043584108352661\n",
      "Train Epoch 93.3 var loss 71780.046875 reconstruction mse 71775.0078125 imputation mse 1.0044784545898438\n",
      "Train Epoch 93.4 var loss 71682.7734375 reconstruction mse 71677.6953125 imputation mse 1.0031166076660156\n",
      "Train Epoch 93.5 var loss 71761.5859375 reconstruction mse 71756.625 imputation mse 1.0042212009429932\n",
      "Train Epoch 93.6 var loss 71732.4609375 reconstruction mse 71727.6171875 imputation mse 1.0038151741027832\n",
      "Train Epoch 93.7 var loss 71704.9140625 reconstruction mse 71700.2109375 imputation mse 1.0034316778182983\n",
      "Train Epoch 93.8 var loss 71726.6484375 reconstruction mse 71722.0390625 imputation mse 1.003737211227417\n",
      "Train Epoch 93.9 var loss 71715.8203125 reconstruction mse 71711.2578125 imputation mse 1.0035862922668457\n",
      "Train Epoch 94.0 var loss 72116.9375 reconstruction mse 72088.4609375 imputation mse 1.0033328533172607\n",
      "Train Epoch 94.1 var loss 72096.25 reconstruction mse 72091.625 imputation mse 1.003376841545105\n",
      "Train Epoch 94.2 var loss 72090.40625 reconstruction mse 72085.7109375 imputation mse 1.003294587135315\n",
      "Train Epoch 94.3 var loss 72089.203125 reconstruction mse 72084.4609375 imputation mse 1.0032771825790405\n",
      "Train Epoch 94.4 var loss 72058.78125 reconstruction mse 72054.0234375 imputation mse 1.002853512763977\n",
      "Train Epoch 94.5 var loss 72101.453125 reconstruction mse 72096.734375 imputation mse 1.0034480094909668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 94.6 var loss 72121.8515625 reconstruction mse 72117.1328125 imputation mse 1.0037318468093872\n",
      "Train Epoch 94.7 var loss 72106.375 reconstruction mse 72101.671875 imputation mse 1.003516674041748\n",
      "Train Epoch 94.8 var loss 72085.9921875 reconstruction mse 72081.3515625 imputation mse 1.0032339096069336\n",
      "Train Epoch 94.9 var loss 72086.984375 reconstruction mse 72082.328125 imputation mse 1.0032474994659424\n",
      "Train Epoch 95.0 var loss 71960.4375 reconstruction mse 71932.34375 imputation mse 1.0108109712600708\n",
      "Train Epoch 95.1 var loss 71911.390625 reconstruction mse 71906.6171875 imputation mse 1.0104495286941528\n",
      "Train Epoch 95.2 var loss 71907.6484375 reconstruction mse 71902.8046875 imputation mse 1.010395884513855\n",
      "Train Epoch 95.3 var loss 71932.0390625 reconstruction mse 71927.1875 imputation mse 1.010738492012024\n",
      "Train Epoch 95.4 var loss 71875.7734375 reconstruction mse 71870.953125 imputation mse 1.0099483728408813\n",
      "Train Epoch 95.5 var loss 71927.171875 reconstruction mse 71922.421875 imputation mse 1.010671615600586\n",
      "Train Epoch 95.6 var loss 71907.546875 reconstruction mse 71902.921875 imputation mse 1.0103975534439087\n",
      "Train Epoch 95.7 var loss 71931.0859375 reconstruction mse 71926.5 imputation mse 1.0107288360595703\n",
      "Train Epoch 95.8 var loss 71877.3828125 reconstruction mse 71872.8515625 imputation mse 1.0099749565124512\n",
      "Train Epoch 95.9 var loss 71913.5078125 reconstruction mse 71909.0078125 imputation mse 1.0104830265045166\n",
      "Train Epoch 96.0 var loss 72572.7734375 reconstruction mse 72545.4453125 imputation mse 1.0104104280471802\n",
      "Train Epoch 96.1 var loss 72577.3828125 reconstruction mse 72572.78125 imputation mse 1.0107911825180054\n",
      "Train Epoch 96.2 var loss 72544.0625 reconstruction mse 72539.34375 imputation mse 1.0103254318237305\n",
      "Train Epoch 96.3 var loss 72547.9296875 reconstruction mse 72543.15625 imputation mse 1.0103784799575806\n",
      "Train Epoch 96.4 var loss 72544.609375 reconstruction mse 72539.828125 imputation mse 1.0103321075439453\n",
      "Train Epoch 96.5 var loss 72533.2734375 reconstruction mse 72528.5390625 imputation mse 1.0101748704910278\n",
      "Train Epoch 96.6 var loss 72575.0546875 reconstruction mse 72570.3671875 imputation mse 1.0107574462890625\n",
      "Train Epoch 96.7 var loss 72535.6015625 reconstruction mse 72530.9609375 imputation mse 1.0102086067199707\n",
      "Train Epoch 96.8 var loss 72542.3515625 reconstruction mse 72537.71875 imputation mse 1.0103027820587158\n",
      "Train Epoch 96.9 var loss 72582.7890625 reconstruction mse 72578.15625 imputation mse 1.0108660459518433\n",
      "Train Epoch 97.0 var loss 71931.5 reconstruction mse 71904.3984375 imputation mse 1.0042513608932495\n",
      "Train Epoch 97.1 var loss 71917.2890625 reconstruction mse 71912.4921875 imputation mse 1.0043643712997437\n",
      "Train Epoch 97.2 var loss 71902.6171875 reconstruction mse 71897.71875 imputation mse 1.0041581392288208\n",
      "Train Epoch 97.3 var loss 71865.1171875 reconstruction mse 71860.1875 imputation mse 1.0036338567733765\n",
      "Train Epoch 97.4 var loss 71861.1484375 reconstruction mse 71856.265625 imputation mse 1.0035791397094727\n",
      "Train Epoch 97.5 var loss 71913.4609375 reconstruction mse 71908.6328125 imputation mse 1.0043104887008667\n",
      "Train Epoch 97.6 var loss 71914.4609375 reconstruction mse 71909.71875 imputation mse 1.0043256282806396\n",
      "Train Epoch 97.7 var loss 71920.296875 reconstruction mse 71915.671875 imputation mse 1.004408836364746\n",
      "Train Epoch 97.8 var loss 71890.1484375 reconstruction mse 71885.546875 imputation mse 1.0039880275726318\n",
      "Train Epoch 97.9 var loss 71898.796875 reconstruction mse 71894.203125 imputation mse 1.0041090250015259\n",
      "Train Epoch 98.0 var loss 72002.25 reconstruction mse 71975.640625 imputation mse 1.0064693689346313\n",
      "Train Epoch 98.1 var loss 72015.3671875 reconstruction mse 72010.6015625 imputation mse 1.006958246231079\n",
      "Train Epoch 98.2 var loss 72047.6640625 reconstruction mse 72042.7734375 imputation mse 1.0074080228805542\n",
      "Train Epoch 98.3 var loss 71908.828125 reconstruction mse 71903.921875 imputation mse 1.0054664611816406\n",
      "Train Epoch 98.4 var loss 71966.359375 reconstruction mse 71961.484375 imputation mse 1.0062713623046875\n",
      "Train Epoch 98.5 var loss 72008.4453125 reconstruction mse 72003.6796875 imputation mse 1.0068614482879639\n",
      "Train Epoch 98.6 var loss 71970.640625 reconstruction mse 71965.984375 imputation mse 1.0063343048095703\n",
      "Train Epoch 98.7 var loss 71998.9609375 reconstruction mse 71994.390625 imputation mse 1.0067315101623535\n",
      "Train Epoch 98.8 var loss 72000.6953125 reconstruction mse 71996.1953125 imputation mse 1.0067567825317383\n",
      "Train Epoch 98.9 var loss 72022.203125 reconstruction mse 72017.6953125 imputation mse 1.0070574283599854\n",
      "Train Epoch 99.0 var loss 72016.9140625 reconstruction mse 71990.828125 imputation mse 1.0043083429336548\n",
      "Train Epoch 99.1 var loss 71944.34375 reconstruction mse 71939.6484375 imputation mse 1.0035942792892456\n",
      "Train Epoch 99.2 var loss 72020.4375 reconstruction mse 72015.6328125 imputation mse 1.0046542882919312\n",
      "Train Epoch 99.3 var loss 72004.1875 reconstruction mse 71999.3515625 imputation mse 1.004427194595337\n",
      "Train Epoch 99.4 var loss 71979.8203125 reconstruction mse 71975.0 imputation mse 1.0040874481201172\n",
      "Train Epoch 99.5 var loss 71952.5234375 reconstruction mse 71947.7890625 imputation mse 1.0037078857421875\n",
      "Train Epoch 99.6 var loss 71987.640625 reconstruction mse 71982.9921875 imputation mse 1.0041990280151367\n",
      "Train Epoch 99.7 var loss 71981.7109375 reconstruction mse 71977.1328125 imputation mse 1.0041172504425049\n",
      "Train Epoch 99.8 var loss 72003.1328125 reconstruction mse 71998.59375 imputation mse 1.004416584968567\n",
      "Train Epoch 99.9 var loss 71972.6484375 reconstruction mse 71968.109375 imputation mse 1.0039913654327393\n",
      "Train Epoch 100.0 var loss 71750.71875 reconstruction mse 71724.9140625 imputation mse 0.9999569654464722\n",
      "Train Epoch 100.1 var loss 71704.0859375 reconstruction mse 71699.390625 imputation mse 0.9996011257171631\n",
      "Train Epoch 100.2 var loss 71732.875 reconstruction mse 71728.109375 imputation mse 1.0000015497207642\n",
      "Train Epoch 100.3 var loss 71755.8671875 reconstruction mse 71751.09375 imputation mse 1.0003219842910767\n",
      "Train Epoch 100.4 var loss 71753.953125 reconstruction mse 71749.1484375 imputation mse 1.000294804573059\n",
      "Train Epoch 100.5 var loss 71736.453125 reconstruction mse 71731.7265625 imputation mse 1.0000519752502441\n",
      "Train Epoch 100.6 var loss 71750.28125 reconstruction mse 71745.625 imputation mse 1.0002456903457642\n",
      "Train Epoch 100.7 var loss 71765.359375 reconstruction mse 71760.828125 imputation mse 1.0004576444625854\n",
      "Train Epoch 100.8 var loss 71752.5546875 reconstruction mse 71748.0546875 imputation mse 1.0002795457839966\n",
      "Train Epoch 100.9 var loss 71728.296875 reconstruction mse 71723.8515625 imputation mse 0.9999421834945679\n",
      "====> Test imputation mse: 1.00292814\n",
      "====> Test imputation mse: 0.99426544\n",
      "====> Test imputation mse: 1.00601411\n",
      "Train Epoch 101.0 var loss 71868.6171875 reconstruction mse 71843.2734375 imputation mse 1.0039725303649902\n",
      "Train Epoch 101.1 var loss 71840.8203125 reconstruction mse 71836.234375 imputation mse 1.0038741827011108\n",
      "Train Epoch 101.2 var loss 71867.4609375 reconstruction mse 71862.7734375 imputation mse 1.0042450428009033\n",
      "Train Epoch 101.3 var loss 71838.9375 reconstruction mse 71834.1875 imputation mse 1.0038455724716187\n",
      "Train Epoch 101.4 var loss 71856.578125 reconstruction mse 71851.8671875 imputation mse 1.0040926933288574\n",
      "Train Epoch 101.5 var loss 71824.9140625 reconstruction mse 71820.2734375 imputation mse 1.0036511421203613\n",
      "Train Epoch 101.6 var loss 71824.6171875 reconstruction mse 71820.1015625 imputation mse 1.0036487579345703\n",
      "Train Epoch 101.7 var loss 71814.28125 reconstruction mse 71809.8046875 imputation mse 1.0035048723220825\n",
      "Train Epoch 101.8 var loss 71848.359375 reconstruction mse 71843.953125 imputation mse 1.0039820671081543\n",
      "Train Epoch 101.9 var loss 71832.3125 reconstruction mse 71827.953125 imputation mse 1.003758430480957\n",
      "Train Epoch 102.0 var loss 71653.9765625 reconstruction mse 71629.1875 imputation mse 1.0022133588790894\n",
      "Train Epoch 102.1 var loss 71583.8359375 reconstruction mse 71579.3359375 imputation mse 1.0015157461166382\n",
      "Train Epoch 102.2 var loss 71648.1171875 reconstruction mse 71643.5078125 imputation mse 1.0024136304855347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 102.3 var loss 71600.5859375 reconstruction mse 71595.9375 imputation mse 1.0017480850219727\n",
      "Train Epoch 102.4 var loss 71622.515625 reconstruction mse 71617.8984375 imputation mse 1.0020554065704346\n",
      "Train Epoch 102.5 var loss 71577.8046875 reconstruction mse 71573.25 imputation mse 1.001430630683899\n",
      "Train Epoch 102.6 var loss 71608.171875 reconstruction mse 71603.6875 imputation mse 1.0018565654754639\n",
      "Train Epoch 102.7 var loss 71642.7421875 reconstruction mse 71638.3515625 imputation mse 1.0023415088653564\n",
      "Train Epoch 102.8 var loss 71609.9453125 reconstruction mse 71605.59375 imputation mse 1.0018831491470337\n",
      "Train Epoch 102.9 var loss 71607.3046875 reconstruction mse 71602.9765625 imputation mse 1.0018465518951416\n",
      "Train Epoch 103.0 var loss 71706.53125 reconstruction mse 71682.1953125 imputation mse 1.0076357126235962\n",
      "Train Epoch 103.1 var loss 71724.21875 reconstruction mse 71719.78125 imputation mse 1.0081640481948853\n",
      "Train Epoch 103.2 var loss 71652.046875 reconstruction mse 71647.5 imputation mse 1.007148027420044\n",
      "Train Epoch 103.3 var loss 71698.8984375 reconstruction mse 71694.2890625 imputation mse 1.0078057050704956\n",
      "Train Epoch 103.4 var loss 71684.5390625 reconstruction mse 71679.9609375 imputation mse 1.0076042413711548\n",
      "Train Epoch 103.5 var loss 71675.8515625 reconstruction mse 71671.3125 imputation mse 1.0074827671051025\n",
      "Train Epoch 103.6 var loss 71654.765625 reconstruction mse 71650.28125 imputation mse 1.0071871280670166\n",
      "Train Epoch 103.7 var loss 71680.203125 reconstruction mse 71675.828125 imputation mse 1.0075461864471436\n",
      "Train Epoch 103.8 var loss 71697.703125 reconstruction mse 71693.359375 imputation mse 1.007792592048645\n",
      "Train Epoch 103.9 var loss 71665.5859375 reconstruction mse 71661.2421875 imputation mse 1.0073411464691162\n",
      "Train Epoch 104.0 var loss 72082.3203125 reconstruction mse 72058.390625 imputation mse 1.0004774332046509\n",
      "Train Epoch 104.1 var loss 72039.0703125 reconstruction mse 72034.578125 imputation mse 1.0001468658447266\n",
      "Train Epoch 104.2 var loss 72006.703125 reconstruction mse 72002.1484375 imputation mse 0.9996966123580933\n",
      "Train Epoch 104.3 var loss 72067.9765625 reconstruction mse 72063.375 imputation mse 1.0005466938018799\n",
      "Train Epoch 104.4 var loss 72073.90625 reconstruction mse 72069.3046875 imputation mse 1.0006290674209595\n",
      "Train Epoch 104.5 var loss 72070.7421875 reconstruction mse 72066.1640625 imputation mse 1.0005854368209839\n",
      "Train Epoch 104.6 var loss 72041.78125 reconstruction mse 72037.2578125 imputation mse 1.0001840591430664\n",
      "Train Epoch 104.7 var loss 72078.0078125 reconstruction mse 72073.4921875 imputation mse 1.0006871223449707\n",
      "Train Epoch 104.8 var loss 72076.328125 reconstruction mse 72071.8359375 imputation mse 1.0006641149520874\n",
      "Train Epoch 104.9 var loss 72057.9609375 reconstruction mse 72053.5078125 imputation mse 1.000409722328186\n",
      "Train Epoch 105.0 var loss 70812.1328125 reconstruction mse 70788.5390625 imputation mse 0.9952974319458008\n",
      "Train Epoch 105.1 var loss 70826.9375 reconstruction mse 70822.359375 imputation mse 0.9957729578018188\n",
      "Train Epoch 105.2 var loss 70789.3828125 reconstruction mse 70784.7421875 imputation mse 0.995244026184082\n",
      "Train Epoch 105.3 var loss 70748.6875 reconstruction mse 70743.9921875 imputation mse 0.994671106338501\n",
      "Train Epoch 105.4 var loss 70830.953125 reconstruction mse 70826.2421875 imputation mse 0.9958275556564331\n",
      "Train Epoch 105.5 var loss 70791.8359375 reconstruction mse 70787.203125 imputation mse 0.9952786564826965\n",
      "Train Epoch 105.6 var loss 70829.1015625 reconstruction mse 70824.515625 imputation mse 0.9958032369613647\n",
      "Train Epoch 105.7 var loss 70803.9140625 reconstruction mse 70799.390625 imputation mse 0.9954500198364258\n",
      "Train Epoch 105.8 var loss 70757.25 reconstruction mse 70752.796875 imputation mse 0.9947949051856995\n",
      "Train Epoch 105.9 var loss 70767.390625 reconstruction mse 70762.9765625 imputation mse 0.9949380159378052\n",
      "Train Epoch 106.0 var loss 71861.8125 reconstruction mse 71838.6640625 imputation mse 1.0041186809539795\n",
      "Train Epoch 106.1 var loss 71820.21875 reconstruction mse 71815.6796875 imputation mse 1.0037974119186401\n",
      "Train Epoch 106.2 var loss 71832.90625 reconstruction mse 71828.2890625 imputation mse 1.0039736032485962\n",
      "Train Epoch 106.3 var loss 71805.8984375 reconstruction mse 71801.2890625 imputation mse 1.0035961866378784\n",
      "Train Epoch 106.4 var loss 71812.46875 reconstruction mse 71807.8984375 imputation mse 1.0036885738372803\n",
      "Train Epoch 106.5 var loss 71813.6796875 reconstruction mse 71809.1796875 imputation mse 1.0037065744400024\n",
      "Train Epoch 106.6 var loss 71803.0625 reconstruction mse 71798.640625 imputation mse 1.0035592317581177\n",
      "Train Epoch 106.7 var loss 71784.0546875 reconstruction mse 71779.703125 imputation mse 1.0032944679260254\n",
      "Train Epoch 106.8 var loss 71844.453125 reconstruction mse 71840.140625 imputation mse 1.0041393041610718\n",
      "Train Epoch 106.9 var loss 71829.4375 reconstruction mse 71825.15625 imputation mse 1.003929853439331\n",
      "Train Epoch 107.0 var loss 71815.59375 reconstruction mse 71792.859375 imputation mse 1.000471830368042\n",
      "Train Epoch 107.1 var loss 71799.796875 reconstruction mse 71795.3671875 imputation mse 1.0005067586898804\n",
      "Train Epoch 107.2 var loss 71777.9921875 reconstruction mse 71773.484375 imputation mse 1.0002018213272095\n",
      "Train Epoch 107.3 var loss 71798.3515625 reconstruction mse 71793.828125 imputation mse 1.0004853010177612\n",
      "Train Epoch 107.4 var loss 71834.078125 reconstruction mse 71829.5859375 imputation mse 1.0009835958480835\n",
      "Train Epoch 107.5 var loss 71876.1875 reconstruction mse 71871.734375 imputation mse 1.0015710592269897\n",
      "Train Epoch 107.6 var loss 71806.625 reconstruction mse 71802.2421875 imputation mse 1.0006026029586792\n",
      "Train Epoch 107.7 var loss 71800.171875 reconstruction mse 71795.8671875 imputation mse 1.0005137920379639\n",
      "Train Epoch 107.8 var loss 71795.8671875 reconstruction mse 71791.6015625 imputation mse 1.000454306602478\n",
      "Train Epoch 107.9 var loss 71835.4140625 reconstruction mse 71831.1328125 imputation mse 1.0010051727294922\n",
      "Train Epoch 108.0 var loss 71532.1796875 reconstruction mse 71509.8046875 imputation mse 1.0007109642028809\n",
      "Train Epoch 108.1 var loss 71541.5234375 reconstruction mse 71537.0859375 imputation mse 1.001092791557312\n",
      "Train Epoch 108.2 var loss 71557.015625 reconstruction mse 71552.5 imputation mse 1.0013084411621094\n",
      "Train Epoch 108.3 var loss 71480.9609375 reconstruction mse 71476.4375 imputation mse 1.0002440214157104\n",
      "Train Epoch 108.4 var loss 71479.4453125 reconstruction mse 71474.953125 imputation mse 1.0002232789993286\n",
      "Train Epoch 108.5 var loss 71535.828125 reconstruction mse 71531.4140625 imputation mse 1.0010133981704712\n",
      "Train Epoch 108.6 var loss 71535.8515625 reconstruction mse 71531.5078125 imputation mse 1.0010147094726562\n",
      "Train Epoch 108.7 var loss 71515.8046875 reconstruction mse 71511.5390625 imputation mse 1.0007352828979492\n",
      "Train Epoch 108.8 var loss 71499.8203125 reconstruction mse 71495.640625 imputation mse 1.000512719154358\n",
      "Train Epoch 108.9 var loss 71505.2890625 reconstruction mse 71501.1015625 imputation mse 1.00058913230896\n",
      "Train Epoch 109.0 var loss 72420.125 reconstruction mse 72398.125 imputation mse 1.0112882852554321\n",
      "Train Epoch 109.1 var loss 72417.2265625 reconstruction mse 72412.8359375 imputation mse 1.0114936828613281\n",
      "Train Epoch 109.2 var loss 72401.1015625 reconstruction mse 72396.578125 imputation mse 1.0112665891647339\n",
      "Train Epoch 109.3 var loss 72423.671875 reconstruction mse 72419.109375 imputation mse 1.011581301689148\n",
      "Train Epoch 109.4 var loss 72400.5703125 reconstruction mse 72395.9921875 imputation mse 1.0112584829330444\n",
      "Train Epoch 109.5 var loss 72393.953125 reconstruction mse 72389.421875 imputation mse 1.0111666917800903\n",
      "Train Epoch 109.6 var loss 72357.484375 reconstruction mse 72353.015625 imputation mse 1.0106581449508667\n",
      "Train Epoch 109.7 var loss 72384.640625 reconstruction mse 72380.2578125 imputation mse 1.0110386610031128\n",
      "Train Epoch 109.8 var loss 72407.96875 reconstruction mse 72403.6640625 imputation mse 1.0113656520843506\n",
      "Train Epoch 109.9 var loss 72400.140625 reconstruction mse 72395.84375 imputation mse 1.0112563371658325\n",
      "Train Epoch 110.0 var loss 71559.5 reconstruction mse 71537.78125 imputation mse 1.0007243156433105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 110.1 var loss 71484.0390625 reconstruction mse 71479.625 imputation mse 0.999910831451416\n",
      "Train Epoch 110.2 var loss 71527.0546875 reconstruction mse 71522.546875 imputation mse 1.0005112886428833\n",
      "Train Epoch 110.3 var loss 71525.25 reconstruction mse 71520.7265625 imputation mse 1.0004857778549194\n",
      "Train Epoch 110.4 var loss 71559.859375 reconstruction mse 71555.3828125 imputation mse 1.0009706020355225\n",
      "Train Epoch 110.5 var loss 71524.9453125 reconstruction mse 71520.4921875 imputation mse 1.0004825592041016\n",
      "Train Epoch 110.6 var loss 71574.8515625 reconstruction mse 71570.4765625 imputation mse 1.001181721687317\n",
      "Train Epoch 110.7 var loss 71513.9609375 reconstruction mse 71509.6328125 imputation mse 1.0003305673599243\n",
      "Train Epoch 110.8 var loss 71608.234375 reconstruction mse 71603.921875 imputation mse 1.0016496181488037\n",
      "Train Epoch 110.9 var loss 71582.6171875 reconstruction mse 71578.3125 imputation mse 1.0012913942337036\n",
      "====> Test imputation mse: 1.01350749\n",
      "====> Test imputation mse: 0.98287004\n",
      "====> Test imputation mse: 0.99880809\n",
      "Train Epoch 111.0 var loss 71649.5546875 reconstruction mse 71628.0859375 imputation mse 0.9986906051635742\n",
      "Train Epoch 111.1 var loss 71592.5859375 reconstruction mse 71588.1328125 imputation mse 0.9981335401535034\n",
      "Train Epoch 111.2 var loss 71640.1328125 reconstruction mse 71635.6171875 imputation mse 0.9987955689430237\n",
      "Train Epoch 111.3 var loss 71583.328125 reconstruction mse 71578.796875 imputation mse 0.998003363609314\n",
      "Train Epoch 111.4 var loss 71613.3671875 reconstruction mse 71608.8671875 imputation mse 0.9984226226806641\n",
      "Train Epoch 111.5 var loss 71624.1640625 reconstruction mse 71619.75 imputation mse 0.9985743761062622\n",
      "Train Epoch 111.6 var loss 71591.4140625 reconstruction mse 71587.0703125 imputation mse 0.9981186985969543\n",
      "Train Epoch 111.7 var loss 71615.59375 reconstruction mse 71611.34375 imputation mse 0.998457133769989\n",
      "Train Epoch 111.8 var loss 71615.4296875 reconstruction mse 71611.2109375 imputation mse 0.998455286026001\n",
      "Train Epoch 111.9 var loss 71616.7265625 reconstruction mse 71612.53125 imputation mse 0.9984737038612366\n",
      "Train Epoch 112.0 var loss 71481.15625 reconstruction mse 71460.1953125 imputation mse 1.004133939743042\n",
      "Train Epoch 112.1 var loss 71438.953125 reconstruction mse 71434.6640625 imputation mse 1.0037751197814941\n",
      "Train Epoch 112.2 var loss 71462.1484375 reconstruction mse 71457.7578125 imputation mse 1.004099726676941\n",
      "Train Epoch 112.3 var loss 71497.0390625 reconstruction mse 71492.640625 imputation mse 1.0045897960662842\n",
      "Train Epoch 112.4 var loss 71458.171875 reconstruction mse 71453.7734375 imputation mse 1.004043698310852\n",
      "Train Epoch 112.5 var loss 71503.2109375 reconstruction mse 71498.875 imputation mse 1.004677414894104\n",
      "Train Epoch 112.6 var loss 71529.7265625 reconstruction mse 71525.40625 imputation mse 1.0050503015518188\n",
      "Train Epoch 112.7 var loss 71473.375 reconstruction mse 71469.0703125 imputation mse 1.004258632659912\n",
      "Train Epoch 112.8 var loss 71465.7890625 reconstruction mse 71461.515625 imputation mse 1.004152536392212\n",
      "Train Epoch 112.9 var loss 71446.7421875 reconstruction mse 71442.453125 imputation mse 1.0038846731185913\n",
      "Train Epoch 113.0 var loss 71794.8671875 reconstruction mse 71774.2421875 imputation mse 1.0069055557250977\n",
      "Train Epoch 113.1 var loss 71776.46875 reconstruction mse 71772.078125 imputation mse 1.0068751573562622\n",
      "Train Epoch 113.2 var loss 71786.0703125 reconstruction mse 71781.59375 imputation mse 1.007008671760559\n",
      "Train Epoch 113.3 var loss 71808.046875 reconstruction mse 71803.5390625 imputation mse 1.0073165893554688\n",
      "Train Epoch 113.4 var loss 71785.984375 reconstruction mse 71781.4296875 imputation mse 1.0070064067840576\n",
      "Train Epoch 113.5 var loss 71789.609375 reconstruction mse 71785.078125 imputation mse 1.007057547569275\n",
      "Train Epoch 113.6 var loss 71784.75 reconstruction mse 71780.21875 imputation mse 1.0069893598556519\n",
      "Train Epoch 113.7 var loss 71738.9609375 reconstruction mse 71734.5 imputation mse 1.0063480138778687\n",
      "Train Epoch 113.8 var loss 71783.59375 reconstruction mse 71779.21875 imputation mse 1.0069754123687744\n",
      "Train Epoch 113.9 var loss 71730.640625 reconstruction mse 71726.3046875 imputation mse 1.0062330961227417\n",
      "Train Epoch 114.0 var loss 71927.6484375 reconstruction mse 71907.2109375 imputation mse 1.0050626993179321\n",
      "Train Epoch 114.1 var loss 71915.6953125 reconstruction mse 71911.296875 imputation mse 1.005119800567627\n",
      "Train Epoch 114.2 var loss 71862.6875 reconstruction mse 71858.25 imputation mse 1.004378318786621\n",
      "Train Epoch 114.3 var loss 71892.015625 reconstruction mse 71887.5546875 imputation mse 1.0047879219055176\n",
      "Train Epoch 114.4 var loss 71889.4609375 reconstruction mse 71885.0234375 imputation mse 1.0047526359558105\n",
      "Train Epoch 114.5 var loss 71867.578125 reconstruction mse 71863.2109375 imputation mse 1.0044476985931396\n",
      "Train Epoch 114.6 var loss 71862.2109375 reconstruction mse 71857.8828125 imputation mse 1.0043731927871704\n",
      "Train Epoch 114.7 var loss 71945.6328125 reconstruction mse 71941.375 imputation mse 1.0055402517318726\n",
      "Train Epoch 114.8 var loss 71871.5234375 reconstruction mse 71867.296875 imputation mse 1.0045047998428345\n",
      "Train Epoch 114.9 var loss 71894.3359375 reconstruction mse 71890.09375 imputation mse 1.0048234462738037\n",
      "Train Epoch 115.0 var loss 71682.7109375 reconstruction mse 71662.65625 imputation mse 1.0034116506576538\n",
      "Train Epoch 115.1 var loss 71695.1171875 reconstruction mse 71690.6953125 imputation mse 1.0038042068481445\n",
      "Train Epoch 115.2 var loss 71670.3125 reconstruction mse 71665.765625 imputation mse 1.0034551620483398\n",
      "Train Epoch 115.3 var loss 71673.5390625 reconstruction mse 71668.9453125 imputation mse 1.0034997463226318\n",
      "Train Epoch 115.4 var loss 71672.640625 reconstruction mse 71668.109375 imputation mse 1.0034879446029663\n",
      "Train Epoch 115.5 var loss 71659.2421875 reconstruction mse 71654.7578125 imputation mse 1.0033010244369507\n",
      "Train Epoch 115.6 var loss 71682.921875 reconstruction mse 71678.53125 imputation mse 1.003633975982666\n",
      "Train Epoch 115.7 var loss 71659.8828125 reconstruction mse 71655.578125 imputation mse 1.003312587738037\n",
      "Train Epoch 115.8 var loss 71638.109375 reconstruction mse 71633.8515625 imputation mse 1.0030083656311035\n",
      "Train Epoch 115.9 var loss 71623.953125 reconstruction mse 71619.6875 imputation mse 1.002810001373291\n",
      "Train Epoch 116.0 var loss 72120.8046875 reconstruction mse 72101.0078125 imputation mse 1.0073912143707275\n",
      "Train Epoch 116.1 var loss 72068.8203125 reconstruction mse 72064.359375 imputation mse 1.006879210472107\n",
      "Train Epoch 116.2 var loss 72063.234375 reconstruction mse 72058.671875 imputation mse 1.0067996978759766\n",
      "Train Epoch 116.3 var loss 72073.4609375 reconstruction mse 72068.90625 imputation mse 1.0069427490234375\n",
      "Train Epoch 116.4 var loss 72032.421875 reconstruction mse 72027.9140625 imputation mse 1.006369948387146\n",
      "Train Epoch 116.5 var loss 72069.6484375 reconstruction mse 72065.21875 imputation mse 1.0068912506103516\n",
      "Train Epoch 116.6 var loss 72082.7421875 reconstruction mse 72078.40625 imputation mse 1.0070754289627075\n",
      "Train Epoch 116.7 var loss 72082.9921875 reconstruction mse 72078.7265625 imputation mse 1.0070799589157104\n",
      "Train Epoch 116.8 var loss 72041.9296875 reconstruction mse 72037.7109375 imputation mse 1.0065069198608398\n",
      "Train Epoch 116.9 var loss 72075.1484375 reconstruction mse 72070.96875 imputation mse 1.0069715976715088\n",
      "Train Epoch 117.0 var loss 72101.609375 reconstruction mse 72082.3515625 imputation mse 1.003694772720337\n",
      "Train Epoch 117.1 var loss 72041.921875 reconstruction mse 72037.59375 imputation mse 1.003071665763855\n",
      "Train Epoch 117.2 var loss 72061.5625 reconstruction mse 72057.1328125 imputation mse 1.0033437013626099\n",
      "Train Epoch 117.3 var loss 72063.7890625 reconstruction mse 72059.3203125 imputation mse 1.0033740997314453\n",
      "Train Epoch 117.4 var loss 72056.890625 reconstruction mse 72052.4609375 imputation mse 1.0032786130905151\n",
      "Train Epoch 117.5 var loss 72063.6953125 reconstruction mse 72059.34375 imputation mse 1.003374457359314\n",
      "Train Epoch 117.6 var loss 72082.78125 reconstruction mse 72078.53125 imputation mse 1.0036416053771973\n",
      "Train Epoch 117.7 var loss 72061.21875 reconstruction mse 72057.0390625 imputation mse 1.0033423900604248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 117.8 var loss 72048.734375 reconstruction mse 72044.6015625 imputation mse 1.0031691789627075\n",
      "Train Epoch 117.9 var loss 72073.2109375 reconstruction mse 72069.09375 imputation mse 1.0035102367401123\n",
      "Train Epoch 118.0 var loss 73197.53125 reconstruction mse 73178.515625 imputation mse 1.0159590244293213\n",
      "Train Epoch 118.1 var loss 73160.4921875 reconstruction mse 73156.203125 imputation mse 1.0156493186950684\n",
      "Train Epoch 118.2 var loss 73176.0859375 reconstruction mse 73171.6875 imputation mse 1.0158642530441284\n",
      "Train Epoch 118.3 var loss 73192.0390625 reconstruction mse 73187.5859375 imputation mse 1.0160850286483765\n",
      "Train Epoch 118.4 var loss 73174.15625 reconstruction mse 73169.703125 imputation mse 1.0158367156982422\n",
      "Train Epoch 118.5 var loss 73157.3671875 reconstruction mse 73152.9609375 imputation mse 1.0156042575836182\n",
      "Train Epoch 118.6 var loss 73173.0625 reconstruction mse 73168.71875 imputation mse 1.0158230066299438\n",
      "Train Epoch 118.7 var loss 73191.8671875 reconstruction mse 73187.5625 imputation mse 1.0160846710205078\n",
      "Train Epoch 118.8 var loss 73153.671875 reconstruction mse 73149.4453125 imputation mse 1.015555500984192\n",
      "Train Epoch 118.9 var loss 73179.34375 reconstruction mse 73175.1484375 imputation mse 1.0159122943878174\n",
      "Train Epoch 119.0 var loss 71654.6796875 reconstruction mse 71635.84375 imputation mse 0.9998024106025696\n",
      "Train Epoch 119.1 var loss 71630.0546875 reconstruction mse 71625.671875 imputation mse 0.9996604323387146\n",
      "Train Epoch 119.2 var loss 71644.5625 reconstruction mse 71640.0859375 imputation mse 0.9998616576194763\n",
      "Train Epoch 119.3 var loss 71678.421875 reconstruction mse 71673.90625 imputation mse 1.0003336668014526\n",
      "Train Epoch 119.4 var loss 71640.109375 reconstruction mse 71635.6171875 imputation mse 0.9997992515563965\n",
      "Train Epoch 119.5 var loss 71688.6484375 reconstruction mse 71684.2109375 imputation mse 1.0004774332046509\n",
      "Train Epoch 119.6 var loss 71649.75 reconstruction mse 71645.40625 imputation mse 0.9999358654022217\n",
      "Train Epoch 119.7 var loss 71633.390625 reconstruction mse 71629.1328125 imputation mse 0.9997087717056274\n",
      "Train Epoch 119.8 var loss 71619.46875 reconstruction mse 71615.2578125 imputation mse 0.9995151162147522\n",
      "Train Epoch 119.9 var loss 71663.34375 reconstruction mse 71659.1328125 imputation mse 1.0001274347305298\n",
      "Train Epoch 120.0 var loss 71436.9375 reconstruction mse 71418.34375 imputation mse 1.0001728534698486\n",
      "Train Epoch 120.1 var loss 71402.6484375 reconstruction mse 71398.296875 imputation mse 0.9998921155929565\n",
      "Train Epoch 120.2 var loss 71447.546875 reconstruction mse 71443.1015625 imputation mse 1.0005196332931519\n",
      "Train Epoch 120.3 var loss 71439.71875 reconstruction mse 71435.296875 imputation mse 1.0004103183746338\n",
      "Train Epoch 120.4 var loss 71409.203125 reconstruction mse 71404.796875 imputation mse 0.9999831318855286\n",
      "Train Epoch 120.5 var loss 71424.4375 reconstruction mse 71420.1328125 imputation mse 1.0001978874206543\n",
      "Train Epoch 120.6 var loss 71422.390625 reconstruction mse 71418.1484375 imputation mse 1.000170111656189\n",
      "Train Epoch 120.7 var loss 71401.84375 reconstruction mse 71397.65625 imputation mse 0.9998831748962402\n",
      "Train Epoch 120.8 var loss 71417.1484375 reconstruction mse 71413.015625 imputation mse 1.0000982284545898\n",
      "Train Epoch 120.9 var loss 71339.4375 reconstruction mse 71335.296875 imputation mse 0.9990098476409912\n",
      "====> Test imputation mse: 0.98297763\n",
      "====> Test imputation mse: 1.00281203\n",
      "====> Test imputation mse: 1.01719999\n",
      "Train Epoch 121.0 var loss 71158.84375 reconstruction mse 71140.5703125 imputation mse 1.001204252243042\n",
      "Train Epoch 121.1 var loss 71203.8125 reconstruction mse 71199.4921875 imputation mse 1.0020334720611572\n",
      "Train Epoch 121.2 var loss 71170.1875 reconstruction mse 71165.71875 imputation mse 1.0015581846237183\n",
      "Train Epoch 121.3 var loss 71145.6875 reconstruction mse 71141.1484375 imputation mse 1.001212477684021\n",
      "Train Epoch 121.4 var loss 71182.96875 reconstruction mse 71178.4453125 imputation mse 1.001737356185913\n",
      "Train Epoch 121.5 var loss 71210.5859375 reconstruction mse 71206.1015625 imputation mse 1.0021265745162964\n",
      "Train Epoch 121.6 var loss 71156.1328125 reconstruction mse 71151.7421875 imputation mse 1.0013614892959595\n",
      "Train Epoch 121.7 var loss 71169.046875 reconstruction mse 71164.7265625 imputation mse 1.0015442371368408\n",
      "Train Epoch 121.8 var loss 71165.734375 reconstruction mse 71161.4921875 imputation mse 1.0014986991882324\n",
      "Train Epoch 121.9 var loss 71121.078125 reconstruction mse 71116.9140625 imputation mse 1.0008713006973267\n",
      "Train Epoch 122.0 var loss 71613.609375 reconstruction mse 71595.6328125 imputation mse 1.0038506984710693\n",
      "Train Epoch 122.1 var loss 71627.5 reconstruction mse 71623.2421875 imputation mse 1.0042377710342407\n",
      "Train Epoch 122.2 var loss 71625.3203125 reconstruction mse 71620.984375 imputation mse 1.0042060613632202\n",
      "Train Epoch 122.3 var loss 71642.8125 reconstruction mse 71638.421875 imputation mse 1.0044505596160889\n",
      "Train Epoch 122.4 var loss 71664.0078125 reconstruction mse 71659.640625 imputation mse 1.0047481060028076\n",
      "Train Epoch 122.5 var loss 71617.9609375 reconstruction mse 71613.625 imputation mse 1.0041029453277588\n",
      "Train Epoch 122.6 var loss 71601.71875 reconstruction mse 71597.453125 imputation mse 1.0038762092590332\n",
      "Train Epoch 122.7 var loss 71619.078125 reconstruction mse 71614.890625 imputation mse 1.0041207075119019\n",
      "Train Epoch 122.8 var loss 71597.375 reconstruction mse 71593.265625 imputation mse 1.0038174390792847\n",
      "Train Epoch 122.9 var loss 71641.0625 reconstruction mse 71636.9921875 imputation mse 1.0044305324554443\n",
      "Train Epoch 123.0 var loss 71434.8671875 reconstruction mse 71417.265625 imputation mse 0.9989686012268066\n",
      "Train Epoch 123.1 var loss 71427.1328125 reconstruction mse 71422.8984375 imputation mse 0.9990473985671997\n",
      "Train Epoch 123.2 var loss 71433.7890625 reconstruction mse 71429.4375 imputation mse 0.9991388916969299\n",
      "Train Epoch 123.3 var loss 71421.6015625 reconstruction mse 71417.2109375 imputation mse 0.9989678263664246\n",
      "Train Epoch 123.4 var loss 71378.2421875 reconstruction mse 71373.8515625 imputation mse 0.998361349105835\n",
      "Train Epoch 123.5 var loss 71412.015625 reconstruction mse 71407.6875 imputation mse 0.9988346695899963\n",
      "Train Epoch 123.6 var loss 71394.1796875 reconstruction mse 71389.921875 imputation mse 0.998586118221283\n",
      "Train Epoch 123.7 var loss 71407.3125 reconstruction mse 71403.1328125 imputation mse 0.9987709522247314\n",
      "Train Epoch 123.8 var loss 71421.2734375 reconstruction mse 71417.140625 imputation mse 0.9989668726921082\n",
      "Train Epoch 123.9 var loss 71414.8671875 reconstruction mse 71410.7578125 imputation mse 0.9988775849342346\n",
      "Train Epoch 124.0 var loss 72658.640625 reconstruction mse 72641.21875 imputation mse 1.0088777542114258\n",
      "Train Epoch 124.1 var loss 72651.421875 reconstruction mse 72647.1015625 imputation mse 1.0089595317840576\n",
      "Train Epoch 124.2 var loss 72667.71875 reconstruction mse 72663.234375 imputation mse 1.0091835260391235\n",
      "Train Epoch 124.3 var loss 72643.1640625 reconstruction mse 72638.609375 imputation mse 1.0088415145874023\n",
      "Train Epoch 124.4 var loss 72602.4375 reconstruction mse 72597.8984375 imputation mse 1.008276104927063\n",
      "Train Epoch 124.5 var loss 72602.875 reconstruction mse 72598.34375 imputation mse 1.0082823038101196\n",
      "Train Epoch 124.6 var loss 72682.78125 reconstruction mse 72678.359375 imputation mse 1.009393572807312\n",
      "Train Epoch 124.7 var loss 72620.8046875 reconstruction mse 72616.4453125 imputation mse 1.0085337162017822\n",
      "Train Epoch 124.8 var loss 72623.453125 reconstruction mse 72619.15625 imputation mse 1.0085713863372803\n",
      "Train Epoch 124.9 var loss 72632.8515625 reconstruction mse 72628.609375 imputation mse 1.0087026357650757\n",
      "Train Epoch 125.0 var loss 71268.90625 reconstruction mse 71251.6796875 imputation mse 1.0003324747085571\n",
      "Train Epoch 125.1 var loss 71256.265625 reconstruction mse 71251.8671875 imputation mse 1.0003350973129272\n",
      "Train Epoch 125.2 var loss 71259.171875 reconstruction mse 71254.6796875 imputation mse 1.0003745555877686\n",
      "Train Epoch 125.3 var loss 71258.28125 reconstruction mse 71253.765625 imputation mse 1.000361680984497\n",
      "Train Epoch 125.4 var loss 71222.1953125 reconstruction mse 71217.6796875 imputation mse 0.999855101108551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 125.5 var loss 71289.7421875 reconstruction mse 71285.3359375 imputation mse 1.0008050203323364\n",
      "Train Epoch 125.6 var loss 71273.75 reconstruction mse 71269.4375 imputation mse 1.0005817413330078\n",
      "Train Epoch 125.7 var loss 71202.1640625 reconstruction mse 71197.8984375 imputation mse 0.9995774030685425\n",
      "Train Epoch 125.8 var loss 71266.8203125 reconstruction mse 71262.6015625 imputation mse 1.0004857778549194\n",
      "Train Epoch 125.9 var loss 71256.4921875 reconstruction mse 71252.28125 imputation mse 1.0003409385681152\n",
      "Train Epoch 126.0 var loss 71721.609375 reconstruction mse 71704.6328125 imputation mse 1.0038167238235474\n",
      "Train Epoch 126.1 var loss 71766.8984375 reconstruction mse 71762.484375 imputation mse 1.0046265125274658\n",
      "Train Epoch 126.2 var loss 71738.90625 reconstruction mse 71734.40625 imputation mse 1.004233479499817\n",
      "Train Epoch 126.3 var loss 71785.7421875 reconstruction mse 71781.2421875 imputation mse 1.0048891305923462\n",
      "Train Epoch 126.4 var loss 71719.109375 reconstruction mse 71714.7109375 imputation mse 1.003957748413086\n",
      "Train Epoch 126.5 var loss 71771.78125 reconstruction mse 71767.5 imputation mse 1.0046967267990112\n",
      "Train Epoch 126.6 var loss 71745.9296875 reconstruction mse 71741.78125 imputation mse 1.0043367147445679\n",
      "Train Epoch 126.7 var loss 71726.28125 reconstruction mse 71722.2265625 imputation mse 1.0040630102157593\n",
      "Train Epoch 126.8 var loss 71778.4453125 reconstruction mse 71774.4375 imputation mse 1.0047938823699951\n",
      "Train Epoch 126.9 var loss 71754.703125 reconstruction mse 71750.71875 imputation mse 1.0044618844985962\n",
      "Train Epoch 127.0 var loss 71602.3359375 reconstruction mse 71585.859375 imputation mse 0.9957278370857239\n",
      "Train Epoch 127.1 var loss 71580.0859375 reconstruction mse 71575.8828125 imputation mse 0.995589017868042\n",
      "Train Epoch 127.2 var loss 71559.6171875 reconstruction mse 71555.328125 imputation mse 0.9953031539916992\n",
      "Train Epoch 127.3 var loss 71629.921875 reconstruction mse 71625.6015625 imputation mse 0.9962806105613708\n",
      "Train Epoch 127.4 var loss 71595.609375 reconstruction mse 71591.3359375 imputation mse 0.9958040118217468\n",
      "Train Epoch 127.5 var loss 71602.4765625 reconstruction mse 71598.2734375 imputation mse 0.9959005117416382\n",
      "Train Epoch 127.6 var loss 71551.5546875 reconstruction mse 71547.421875 imputation mse 0.9951931834220886\n",
      "Train Epoch 127.7 var loss 71581.734375 reconstruction mse 71577.6640625 imputation mse 0.9956138134002686\n",
      "Train Epoch 127.8 var loss 71603.9609375 reconstruction mse 71599.9375 imputation mse 0.995923638343811\n",
      "Train Epoch 127.9 var loss 71618.53125 reconstruction mse 71614.5 imputation mse 0.9961261749267578\n",
      "Train Epoch 128.0 var loss 71468.2265625 reconstruction mse 71452.015625 imputation mse 0.9997203946113586\n",
      "Train Epoch 128.1 var loss 71462.6171875 reconstruction mse 71458.375 imputation mse 0.9998093843460083\n",
      "Train Epoch 128.2 var loss 71445.5078125 reconstruction mse 71441.1484375 imputation mse 0.9995683431625366\n",
      "Train Epoch 128.3 var loss 71407.328125 reconstruction mse 71402.90625 imputation mse 0.9990332722663879\n",
      "Train Epoch 128.4 var loss 71409.3828125 reconstruction mse 71404.96875 imputation mse 0.9990621209144592\n",
      "Train Epoch 128.5 var loss 71430.6484375 reconstruction mse 71426.3046875 imputation mse 0.9993606805801392\n",
      "Train Epoch 128.6 var loss 71444.7109375 reconstruction mse 71440.421875 imputation mse 0.99955815076828\n",
      "Train Epoch 128.7 var loss 71428.84375 reconstruction mse 71424.6484375 imputation mse 0.9993374943733215\n",
      "Train Epoch 128.8 var loss 71471.8046875 reconstruction mse 71467.6796875 imputation mse 0.9999395608901978\n",
      "Train Epoch 128.9 var loss 71451.8671875 reconstruction mse 71447.765625 imputation mse 0.9996609091758728\n",
      "Train Epoch 129.0 var loss 70912.3828125 reconstruction mse 70896.3359375 imputation mse 0.9939342737197876\n",
      "Train Epoch 129.1 var loss 70912.6015625 reconstruction mse 70908.4375 imputation mse 0.9941039085388184\n",
      "Train Epoch 129.2 var loss 70890.640625 reconstruction mse 70886.3828125 imputation mse 0.9937946796417236\n",
      "Train Epoch 129.3 var loss 70925.515625 reconstruction mse 70921.21875 imputation mse 0.9942830801010132\n",
      "Train Epoch 129.4 var loss 70891.1796875 reconstruction mse 70886.8984375 imputation mse 0.9938019514083862\n",
      "Train Epoch 129.5 var loss 70905.875 reconstruction mse 70901.703125 imputation mse 0.9940094947814941\n",
      "Train Epoch 129.6 var loss 70895.046875 reconstruction mse 70890.9453125 imputation mse 0.9938586950302124\n",
      "Train Epoch 129.7 var loss 70891.828125 reconstruction mse 70887.7890625 imputation mse 0.9938144087791443\n",
      "Train Epoch 129.8 var loss 70901.9921875 reconstruction mse 70897.984375 imputation mse 0.9939573407173157\n",
      "Train Epoch 129.9 var loss 70852.5390625 reconstruction mse 70848.546875 imputation mse 0.9932642579078674\n",
      "Train Epoch 130.0 var loss 72060.5625 reconstruction mse 72044.8515625 imputation mse 1.0094698667526245\n",
      "Train Epoch 130.1 var loss 72031.5625 reconstruction mse 72027.328125 imputation mse 1.00922429561615\n",
      "Train Epoch 130.2 var loss 72048.0234375 reconstruction mse 72043.6953125 imputation mse 1.0094536542892456\n",
      "Train Epoch 130.3 var loss 72031.3828125 reconstruction mse 72027.0625 imputation mse 1.0092206001281738\n",
      "Train Epoch 130.4 var loss 72044.5703125 reconstruction mse 72040.3203125 imputation mse 1.009406328201294\n",
      "Train Epoch 130.5 var loss 72001.484375 reconstruction mse 71997.3125 imputation mse 1.0088037252426147\n",
      "Train Epoch 130.6 var loss 72015.0625 reconstruction mse 72010.9609375 imputation mse 1.0089949369430542\n",
      "Train Epoch 130.7 var loss 72040.65625 reconstruction mse 72036.59375 imputation mse 1.0093541145324707\n",
      "Train Epoch 130.8 var loss 71991.3671875 reconstruction mse 71987.3359375 imputation mse 1.0086638927459717\n",
      "Train Epoch 130.9 var loss 72040.5859375 reconstruction mse 72036.5625 imputation mse 1.0093536376953125\n",
      "====> Test imputation mse: 0.99412441\n",
      "====> Test imputation mse: 1.00094640\n",
      "====> Test imputation mse: 0.99658531\n",
      "Train Epoch 131.0 var loss 72067.515625 reconstruction mse 72051.9921875 imputation mse 1.006439208984375\n",
      "Train Epoch 131.1 var loss 72012.5546875 reconstruction mse 72008.359375 imputation mse 1.0058298110961914\n",
      "Train Epoch 131.2 var loss 72018.9609375 reconstruction mse 72014.671875 imputation mse 1.0059179067611694\n",
      "Train Epoch 131.3 var loss 71988.7265625 reconstruction mse 71984.421875 imputation mse 1.0054954290390015\n",
      "Train Epoch 131.4 var loss 71997.6328125 reconstruction mse 71993.390625 imputation mse 1.0056207180023193\n",
      "Train Epoch 131.5 var loss 71990.3046875 reconstruction mse 71986.1640625 imputation mse 1.0055197477340698\n",
      "Train Epoch 131.6 var loss 71993.2734375 reconstruction mse 71989.21875 imputation mse 1.005562424659729\n",
      "Train Epoch 131.7 var loss 72008.359375 reconstruction mse 72004.3671875 imputation mse 1.0057740211486816\n",
      "Train Epoch 131.8 var loss 71980.0859375 reconstruction mse 71976.09375 imputation mse 1.0053790807724\n",
      "Train Epoch 131.9 var loss 71985.625 reconstruction mse 71981.640625 imputation mse 1.005456566810608\n",
      "Train Epoch 132.0 var loss 71743.0625 reconstruction mse 71727.8203125 imputation mse 1.000457763671875\n",
      "Train Epoch 132.1 var loss 71702.25 reconstruction mse 71698.0625 imputation mse 1.0000426769256592\n",
      "Train Epoch 132.2 var loss 71717.34375 reconstruction mse 71713.0078125 imputation mse 1.0002511739730835\n",
      "Train Epoch 132.3 var loss 71698.828125 reconstruction mse 71694.4765625 imputation mse 0.9999927282333374\n",
      "Train Epoch 132.4 var loss 71745.4296875 reconstruction mse 71741.125 imputation mse 1.0006433725357056\n",
      "Train Epoch 132.5 var loss 71693.890625 reconstruction mse 71689.6796875 imputation mse 0.9999257922172546\n",
      "Train Epoch 132.6 var loss 71732.71875 reconstruction mse 71728.640625 imputation mse 1.0004692077636719\n",
      "Train Epoch 132.7 var loss 71738.4609375 reconstruction mse 71734.484375 imputation mse 1.0005507469177246\n",
      "Train Epoch 132.8 var loss 71744.8203125 reconstruction mse 71740.8828125 imputation mse 1.0006399154663086\n",
      "Train Epoch 132.9 var loss 71706.3125 reconstruction mse 71702.375 imputation mse 1.0001028776168823\n",
      "Train Epoch 133.0 var loss 71669.546875 reconstruction mse 71654.671875 imputation mse 0.9975313544273376\n",
      "Train Epoch 133.1 var loss 71685.6640625 reconstruction mse 71681.484375 imputation mse 0.9979045987129211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 133.2 var loss 71712.4375 reconstruction mse 71708.0859375 imputation mse 0.9982749223709106\n",
      "Train Epoch 133.3 var loss 71688.4296875 reconstruction mse 71684.0234375 imputation mse 0.997939944267273\n",
      "Train Epoch 133.4 var loss 71669.921875 reconstruction mse 71665.546875 imputation mse 0.9976827502250671\n",
      "Train Epoch 133.5 var loss 71671.3984375 reconstruction mse 71667.109375 imputation mse 0.9977045059204102\n",
      "Train Epoch 133.6 var loss 71635.1171875 reconstruction mse 71630.96875 imputation mse 0.9972013831138611\n",
      "Train Epoch 133.7 var loss 71678.59375 reconstruction mse 71674.5859375 imputation mse 0.997808575630188\n",
      "Train Epoch 133.8 var loss 71692.1328125 reconstruction mse 71688.2109375 imputation mse 0.9979982376098633\n",
      "Train Epoch 133.9 var loss 71660.0546875 reconstruction mse 71656.1484375 imputation mse 0.9975519180297852\n",
      "Train Epoch 134.0 var loss 71465.28125 reconstruction mse 71450.6328125 imputation mse 0.9981508851051331\n",
      "Train Epoch 134.1 var loss 71429.4765625 reconstruction mse 71425.34375 imputation mse 0.9977975487709045\n",
      "Train Epoch 134.2 var loss 71452.8828125 reconstruction mse 71448.625 imputation mse 0.9981228113174438\n",
      "Train Epoch 134.3 var loss 71460.3515625 reconstruction mse 71456.0 imputation mse 0.9982258081436157\n",
      "Train Epoch 134.4 var loss 71464.796875 reconstruction mse 71460.4375 imputation mse 0.9982877969741821\n",
      "Train Epoch 134.5 var loss 71432.2890625 reconstruction mse 71427.9765625 imputation mse 0.997834324836731\n",
      "Train Epoch 134.6 var loss 71421.65625 reconstruction mse 71417.453125 imputation mse 0.9976873397827148\n",
      "Train Epoch 134.7 var loss 71452.1796875 reconstruction mse 71448.078125 imputation mse 0.9981151819229126\n",
      "Train Epoch 134.8 var loss 71468.6171875 reconstruction mse 71464.5859375 imputation mse 0.9983457922935486\n",
      "Train Epoch 134.9 var loss 71497.6328125 reconstruction mse 71493.6328125 imputation mse 0.9987515807151794\n",
      "Train Epoch 135.0 var loss 71609.1484375 reconstruction mse 71594.5703125 imputation mse 1.00441312789917\n",
      "Train Epoch 135.1 var loss 71652.28125 reconstruction mse 71648.1796875 imputation mse 1.0051652193069458\n",
      "Train Epoch 135.2 var loss 71658.015625 reconstruction mse 71653.8046875 imputation mse 1.0052441358566284\n",
      "Train Epoch 135.3 var loss 71655.1796875 reconstruction mse 71650.9453125 imputation mse 1.0052040815353394\n",
      "Train Epoch 135.4 var loss 71653.421875 reconstruction mse 71649.203125 imputation mse 1.0051796436309814\n",
      "Train Epoch 135.5 var loss 71644.3515625 reconstruction mse 71640.1796875 imputation mse 1.0050530433654785\n",
      "Train Epoch 135.6 var loss 71660.6640625 reconstruction mse 71656.5546875 imputation mse 1.0052827596664429\n",
      "Train Epoch 135.7 var loss 71649.3046875 reconstruction mse 71645.2578125 imputation mse 1.0051242113113403\n",
      "Train Epoch 135.8 var loss 71653.984375 reconstruction mse 71650.015625 imputation mse 1.0051909685134888\n",
      "Train Epoch 135.9 var loss 71650.0625 reconstruction mse 71646.1484375 imputation mse 1.0051367282867432\n",
      "Train Epoch 136.0 var loss 71544.8828125 reconstruction mse 71530.609375 imputation mse 0.9997988343238831\n",
      "Train Epoch 136.1 var loss 71547.28125 reconstruction mse 71543.2578125 imputation mse 0.9999756217002869\n",
      "Train Epoch 136.2 var loss 71536.703125 reconstruction mse 71532.6171875 imputation mse 0.9998269081115723\n",
      "Train Epoch 136.3 var loss 71501.953125 reconstruction mse 71497.8125 imputation mse 0.9993404746055603\n",
      "Train Epoch 136.4 var loss 71553.34375 reconstruction mse 71549.203125 imputation mse 1.0000587701797485\n",
      "Train Epoch 136.5 var loss 71548.8828125 reconstruction mse 71544.8125 imputation mse 0.9999973773956299\n",
      "Train Epoch 136.6 var loss 71497.625 reconstruction mse 71493.5859375 imputation mse 0.9992813467979431\n",
      "Train Epoch 136.7 var loss 71510.75 reconstruction mse 71506.765625 imputation mse 0.9994655847549438\n",
      "Train Epoch 136.8 var loss 71545.609375 reconstruction mse 71541.6484375 imputation mse 0.9999531507492065\n",
      "Train Epoch 136.9 var loss 71542.953125 reconstruction mse 71539.0 imputation mse 0.999916136264801\n",
      "Train Epoch 137.0 var loss 72722.0703125 reconstruction mse 72707.890625 imputation mse 1.0168509483337402\n",
      "Train Epoch 137.1 var loss 72662.015625 reconstruction mse 72657.90625 imputation mse 1.0161519050598145\n",
      "Train Epoch 137.2 var loss 72707.8515625 reconstruction mse 72703.6875 imputation mse 1.0167921781539917\n",
      "Train Epoch 137.3 var loss 72688.3125 reconstruction mse 72684.140625 imputation mse 1.0165187120437622\n",
      "Train Epoch 137.4 var loss 72620.453125 reconstruction mse 72616.296875 imputation mse 1.0155699253082275\n",
      "Train Epoch 137.5 var loss 72672.25 reconstruction mse 72668.1328125 imputation mse 1.0162948369979858\n",
      "Train Epoch 137.6 var loss 72712.2265625 reconstruction mse 72708.2109375 imputation mse 1.0168553590774536\n",
      "Train Epoch 137.7 var loss 72650.7265625 reconstruction mse 72646.6875 imputation mse 1.015994906425476\n",
      "Train Epoch 137.8 var loss 72691.984375 reconstruction mse 72687.9375 imputation mse 1.0165718793869019\n",
      "Train Epoch 137.9 var loss 72668.65625 reconstruction mse 72664.6171875 imputation mse 1.016245722770691\n",
      "Train Epoch 138.0 var loss 71111.796875 reconstruction mse 71097.7734375 imputation mse 0.9979755282402039\n",
      "Train Epoch 138.1 var loss 71075.640625 reconstruction mse 71071.5 imputation mse 0.9976067543029785\n",
      "Train Epoch 138.2 var loss 71135.6796875 reconstruction mse 71131.484375 imputation mse 0.9984487295150757\n",
      "Train Epoch 138.3 var loss 71116.6015625 reconstruction mse 71112.3984375 imputation mse 0.9981808066368103\n",
      "Train Epoch 138.4 var loss 71133.7109375 reconstruction mse 71129.578125 imputation mse 0.9984219670295715\n",
      "Train Epoch 138.5 var loss 71120.7265625 reconstruction mse 71116.640625 imputation mse 0.9982403516769409\n",
      "Train Epoch 138.6 var loss 71142.015625 reconstruction mse 71138.0234375 imputation mse 0.9985405206680298\n",
      "Train Epoch 138.7 var loss 71115.75 reconstruction mse 71111.828125 imputation mse 0.9981728196144104\n",
      "Train Epoch 138.8 var loss 71103.4375 reconstruction mse 71099.515625 imputation mse 0.9979999661445618\n",
      "Train Epoch 138.9 var loss 71096.5 reconstruction mse 71092.609375 imputation mse 0.997903048992157\n",
      "Train Epoch 139.0 var loss 71970.8359375 reconstruction mse 71957.0703125 imputation mse 1.0045380592346191\n",
      "Train Epoch 139.1 var loss 71951.5078125 reconstruction mse 71947.4296875 imputation mse 1.0044034719467163\n",
      "Train Epoch 139.2 var loss 71994.796875 reconstruction mse 71990.6171875 imputation mse 1.0050064325332642\n",
      "Train Epoch 139.3 var loss 71959.6328125 reconstruction mse 71955.4609375 imputation mse 1.0045156478881836\n",
      "Train Epoch 139.4 var loss 71964.6953125 reconstruction mse 71960.5390625 imputation mse 1.0045864582061768\n",
      "Train Epoch 139.5 var loss 71990.5546875 reconstruction mse 71986.46875 imputation mse 1.0049484968185425\n",
      "Train Epoch 139.6 var loss 71920.3046875 reconstruction mse 71916.2890625 imputation mse 1.0039687156677246\n",
      "Train Epoch 139.7 var loss 71967.078125 reconstruction mse 71963.1640625 imputation mse 1.0046231746673584\n",
      "Train Epoch 139.8 var loss 71976.21875 reconstruction mse 71972.3203125 imputation mse 1.0047509670257568\n",
      "Train Epoch 139.9 var loss 71995.671875 reconstruction mse 71991.75 imputation mse 1.0050221681594849\n",
      "Train Epoch 140.0 var loss 70929.578125 reconstruction mse 70916.0078125 imputation mse 0.994405210018158\n",
      "Train Epoch 140.1 var loss 70963.03125 reconstruction mse 70958.890625 imputation mse 0.9950065016746521\n",
      "Train Epoch 140.2 var loss 70968.9140625 reconstruction mse 70964.640625 imputation mse 0.9950871467590332\n",
      "Train Epoch 140.3 var loss 71015.5625 reconstruction mse 71011.2578125 imputation mse 0.9957408308982849\n",
      "Train Epoch 140.4 var loss 70961.203125 reconstruction mse 70956.9296875 imputation mse 0.9949790239334106\n",
      "Train Epoch 140.5 var loss 70956.234375 reconstruction mse 70952.0703125 imputation mse 0.9949108958244324\n",
      "Train Epoch 140.6 var loss 70952.6796875 reconstruction mse 70948.6328125 imputation mse 0.9948626756668091\n",
      "Train Epoch 140.7 var loss 70932.546875 reconstruction mse 70928.6328125 imputation mse 0.9945822358131409\n",
      "Train Epoch 140.8 var loss 70969.671875 reconstruction mse 70965.8203125 imputation mse 0.9951037168502808\n",
      "Train Epoch 140.9 var loss 70990.0625 reconstruction mse 70986.21875 imputation mse 0.9953897595405579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test imputation mse: 1.02670622\n",
      "====> Test imputation mse: 0.99312532\n",
      "====> Test imputation mse: 0.97072911\n",
      "Train Epoch 141.0 var loss 71476.5390625 reconstruction mse 71463.28125 imputation mse 1.0022900104522705\n",
      "Train Epoch 141.1 var loss 71498.3671875 reconstruction mse 71494.3359375 imputation mse 1.002725601196289\n",
      "Train Epoch 141.2 var loss 71449.0703125 reconstruction mse 71444.921875 imputation mse 1.0020325183868408\n",
      "Train Epoch 141.3 var loss 71445.265625 reconstruction mse 71441.078125 imputation mse 1.0019786357879639\n",
      "Train Epoch 141.4 var loss 71476.328125 reconstruction mse 71472.1640625 imputation mse 1.002414584159851\n",
      "Train Epoch 141.5 var loss 71407.921875 reconstruction mse 71403.796875 imputation mse 1.0014557838439941\n",
      "Train Epoch 141.6 var loss 71461.09375 reconstruction mse 71457.0546875 imputation mse 1.0022027492523193\n",
      "Train Epoch 141.7 var loss 71439.5703125 reconstruction mse 71435.5703125 imputation mse 1.001901388168335\n",
      "Train Epoch 141.8 var loss 71469.7890625 reconstruction mse 71465.828125 imputation mse 1.0023257732391357\n",
      "Train Epoch 141.9 var loss 71436.03125 reconstruction mse 71432.0546875 imputation mse 1.0018521547317505\n",
      "Train Epoch 142.0 var loss 72350.6953125 reconstruction mse 72337.5234375 imputation mse 1.0081182718276978\n",
      "Train Epoch 142.1 var loss 72301.5078125 reconstruction mse 72297.3515625 imputation mse 1.0075583457946777\n",
      "Train Epoch 142.2 var loss 72328.5390625 reconstruction mse 72324.2890625 imputation mse 1.0079337358474731\n",
      "Train Epoch 142.3 var loss 72301.203125 reconstruction mse 72296.9453125 imputation mse 1.0075527429580688\n",
      "Train Epoch 142.4 var loss 72288.6796875 reconstruction mse 72284.4765625 imputation mse 1.0073789358139038\n",
      "Train Epoch 142.5 var loss 72303.21875 reconstruction mse 72299.0703125 imputation mse 1.0075823068618774\n",
      "Train Epoch 142.6 var loss 72302.6328125 reconstruction mse 72298.5546875 imputation mse 1.0075751543045044\n",
      "Train Epoch 142.7 var loss 72307.3828125 reconstruction mse 72303.3203125 imputation mse 1.0076415538787842\n",
      "Train Epoch 142.8 var loss 72305.328125 reconstruction mse 72301.28125 imputation mse 1.007613182067871\n",
      "Train Epoch 142.9 var loss 72286.9140625 reconstruction mse 72282.9140625 imputation mse 1.007357120513916\n",
      "Train Epoch 143.0 var loss 71982.9140625 reconstruction mse 71969.84375 imputation mse 1.0063037872314453\n",
      "Train Epoch 143.1 var loss 71914.1328125 reconstruction mse 71910.0078125 imputation mse 1.005467176437378\n",
      "Train Epoch 143.2 var loss 71981.3046875 reconstruction mse 71977.109375 imputation mse 1.0064054727554321\n",
      "Train Epoch 143.3 var loss 71923.796875 reconstruction mse 71919.5859375 imputation mse 1.005601167678833\n",
      "Train Epoch 143.4 var loss 71939.625 reconstruction mse 71935.453125 imputation mse 1.005823016166687\n",
      "Train Epoch 143.5 var loss 71949.546875 reconstruction mse 71945.40625 imputation mse 1.0059621334075928\n",
      "Train Epoch 143.6 var loss 71955.25 reconstruction mse 71951.1796875 imputation mse 1.0060428380966187\n",
      "Train Epoch 143.7 var loss 71956.296875 reconstruction mse 71952.2734375 imputation mse 1.0060582160949707\n",
      "Train Epoch 143.8 var loss 71930.296875 reconstruction mse 71926.2890625 imputation mse 1.00569486618042\n",
      "Train Epoch 143.9 var loss 71949.6640625 reconstruction mse 71945.65625 imputation mse 1.0059655904769897\n",
      "Train Epoch 144.0 var loss 72200.15625 reconstruction mse 72187.28125 imputation mse 1.0059542655944824\n",
      "Train Epoch 144.1 var loss 72237.796875 reconstruction mse 72233.65625 imputation mse 1.0066006183624268\n",
      "Train Epoch 144.2 var loss 72196.96875 reconstruction mse 72192.703125 imputation mse 1.0060298442840576\n",
      "Train Epoch 144.3 var loss 72199.703125 reconstruction mse 72195.4375 imputation mse 1.0060679912567139\n",
      "Train Epoch 144.4 var loss 72205.265625 reconstruction mse 72201.0546875 imputation mse 1.0061461925506592\n",
      "Train Epoch 144.5 var loss 72206.875 reconstruction mse 72202.7421875 imputation mse 1.0061697959899902\n",
      "Train Epoch 144.6 var loss 72178.28125 reconstruction mse 72174.203125 imputation mse 1.0057721138000488\n",
      "Train Epoch 144.7 var loss 72164.0 reconstruction mse 72159.9921875 imputation mse 1.0055739879608154\n",
      "Train Epoch 144.8 var loss 72196.125 reconstruction mse 72192.15625 imputation mse 1.0060222148895264\n",
      "Train Epoch 144.9 var loss 72200.9453125 reconstruction mse 72196.984375 imputation mse 1.0060895681381226\n",
      "Train Epoch 145.0 var loss 71523.9375 reconstruction mse 71511.3203125 imputation mse 0.9996689558029175\n",
      "Train Epoch 145.1 var loss 71555.015625 reconstruction mse 71550.890625 imputation mse 1.000222086906433\n",
      "Train Epoch 145.2 var loss 71519.1640625 reconstruction mse 71514.9921875 imputation mse 0.9997203350067139\n",
      "Train Epoch 145.3 var loss 71527.7578125 reconstruction mse 71523.578125 imputation mse 0.9998403191566467\n",
      "Train Epoch 145.4 var loss 71466.8828125 reconstruction mse 71462.7734375 imputation mse 0.9989903569221497\n",
      "Train Epoch 145.5 var loss 71480.3671875 reconstruction mse 71476.328125 imputation mse 0.9991798400878906\n",
      "Train Epoch 145.6 var loss 71533.7890625 reconstruction mse 71529.8359375 imputation mse 0.999927818775177\n",
      "Train Epoch 145.7 var loss 71505.140625 reconstruction mse 71501.2109375 imputation mse 0.999527633190155\n",
      "Train Epoch 145.8 var loss 71501.890625 reconstruction mse 71497.9765625 imputation mse 0.9994824528694153\n",
      "Train Epoch 145.9 var loss 71477.96875 reconstruction mse 71474.03125 imputation mse 0.9991477131843567\n",
      "Train Epoch 146.0 var loss 71932.875 reconstruction mse 71920.3984375 imputation mse 1.0026683807373047\n",
      "Train Epoch 146.1 var loss 71900.4375 reconstruction mse 71896.3125 imputation mse 1.0023325681686401\n",
      "Train Epoch 146.2 var loss 71858.78125 reconstruction mse 71854.5859375 imputation mse 1.0017508268356323\n",
      "Train Epoch 146.3 var loss 71860.4921875 reconstruction mse 71856.296875 imputation mse 1.0017746686935425\n",
      "Train Epoch 146.4 var loss 71875.7578125 reconstruction mse 71871.625 imputation mse 1.001988410949707\n",
      "Train Epoch 146.5 var loss 71911.9453125 reconstruction mse 71907.90625 imputation mse 1.002494215965271\n",
      "Train Epoch 146.6 var loss 71895.8046875 reconstruction mse 71891.8671875 imputation mse 1.0022705793380737\n",
      "Train Epoch 146.7 var loss 71864.1796875 reconstruction mse 71860.328125 imputation mse 1.0018309354782104\n",
      "Train Epoch 146.8 var loss 71881.625 reconstruction mse 71877.8125 imputation mse 1.0020745992660522\n",
      "Train Epoch 146.9 var loss 71859.7421875 reconstruction mse 71855.953125 imputation mse 1.0017699003219604\n",
      "Train Epoch 147.0 var loss 71328.6015625 reconstruction mse 71316.375 imputation mse 1.000412106513977\n",
      "Train Epoch 147.1 var loss 71309.171875 reconstruction mse 71305.1875 imputation mse 1.0002551078796387\n",
      "Train Epoch 147.2 var loss 71371.1953125 reconstruction mse 71367.078125 imputation mse 1.001123309135437\n",
      "Train Epoch 147.3 var loss 71319.015625 reconstruction mse 71314.859375 imputation mse 1.0003907680511475\n",
      "Train Epoch 147.4 var loss 71342.2421875 reconstruction mse 71338.140625 imputation mse 1.0007174015045166\n",
      "Train Epoch 147.5 var loss 71368.84375 reconstruction mse 71364.8046875 imputation mse 1.001091480255127\n",
      "Train Epoch 147.6 var loss 71341.2890625 reconstruction mse 71337.3125 imputation mse 1.0007057189941406\n",
      "Train Epoch 147.7 var loss 71357.1640625 reconstruction mse 71353.234375 imputation mse 1.0009291172027588\n",
      "Train Epoch 147.8 var loss 71326.21875 reconstruction mse 71322.3515625 imputation mse 1.0004959106445312\n",
      "Train Epoch 147.9 var loss 71309.140625 reconstruction mse 71305.2890625 imputation mse 1.0002565383911133\n",
      "Train Epoch 148.0 var loss 71406.5546875 reconstruction mse 71394.5234375 imputation mse 1.003450870513916\n",
      "Train Epoch 148.1 var loss 71471.296875 reconstruction mse 71467.2890625 imputation mse 1.0044735670089722\n",
      "Train Epoch 148.2 var loss 71423.09375 reconstruction mse 71418.9609375 imputation mse 1.0037943124771118\n",
      "Train Epoch 148.3 var loss 71443.7109375 reconstruction mse 71439.5625 imputation mse 1.0040838718414307\n",
      "Train Epoch 148.4 var loss 71432.3671875 reconstruction mse 71428.2421875 imputation mse 1.0039247274398804\n",
      "Train Epoch 148.5 var loss 71424.8046875 reconstruction mse 71420.7578125 imputation mse 1.0038195848464966\n",
      "Train Epoch 148.6 var loss 71431.1171875 reconstruction mse 71427.15625 imputation mse 1.0039094686508179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 148.7 var loss 71424.90625 reconstruction mse 71421.03125 imputation mse 1.0038233995437622\n",
      "Train Epoch 148.8 var loss 71453.9375 reconstruction mse 71450.0859375 imputation mse 1.0042318105697632\n",
      "Train Epoch 148.9 var loss 71435.3046875 reconstruction mse 71431.4765625 imputation mse 1.0039702653884888\n",
      "Train Epoch 149.0 var loss 70958.5 reconstruction mse 70946.546875 imputation mse 0.9928426146507263\n",
      "Train Epoch 149.1 var loss 70945.796875 reconstruction mse 70941.796875 imputation mse 0.9927761554718018\n",
      "Train Epoch 149.2 var loss 70959.015625 reconstruction mse 70954.890625 imputation mse 0.9929593801498413\n",
      "Train Epoch 149.3 var loss 70904.28125 reconstruction mse 70900.09375 imputation mse 0.9921925067901611\n",
      "Train Epoch 149.4 var loss 70949.390625 reconstruction mse 70945.234375 imputation mse 0.9928242564201355\n",
      "Train Epoch 149.5 var loss 70956.0625 reconstruction mse 70951.9765625 imputation mse 0.9929186105728149\n",
      "Train Epoch 149.6 var loss 70897.8359375 reconstruction mse 70893.8203125 imputation mse 0.992104709148407\n",
      "Train Epoch 149.7 var loss 70946.25 reconstruction mse 70942.328125 imputation mse 0.9927835464477539\n",
      "Train Epoch 149.8 var loss 70909.953125 reconstruction mse 70906.09375 imputation mse 0.9922764897346497\n",
      "Train Epoch 149.9 var loss 70886.75 reconstruction mse 70882.9453125 imputation mse 0.9919525384902954\n",
      "Train Epoch 150.0 var loss 71691.3671875 reconstruction mse 71679.5859375 imputation mse 1.0032694339752197\n",
      "Train Epoch 150.1 var loss 71681.8828125 reconstruction mse 71677.9140625 imputation mse 1.0032459497451782\n",
      "Train Epoch 150.2 var loss 71662.1953125 reconstruction mse 71658.109375 imputation mse 1.0029687881469727\n",
      "Train Epoch 150.3 var loss 71688.453125 reconstruction mse 71684.3046875 imputation mse 1.0033354759216309\n",
      "Train Epoch 150.4 var loss 71673.5234375 reconstruction mse 71669.4296875 imputation mse 1.0031272172927856\n",
      "Train Epoch 150.5 var loss 71694.0078125 reconstruction mse 71690.0234375 imputation mse 1.0034154653549194\n",
      "Train Epoch 150.6 var loss 71704.421875 reconstruction mse 71700.5078125 imputation mse 1.0035622119903564\n",
      "Train Epoch 150.7 var loss 71652.875 reconstruction mse 71649.0390625 imputation mse 1.002841830253601\n",
      "Train Epoch 150.8 var loss 71705.7734375 reconstruction mse 71701.9375 imputation mse 1.003582239151001\n",
      "Train Epoch 150.9 var loss 71699.7421875 reconstruction mse 71695.890625 imputation mse 1.00349760055542\n",
      "====> Test imputation mse: 0.98388422\n",
      "====> Test imputation mse: 1.00239670\n",
      "====> Test imputation mse: 0.99998426\n",
      "Train Epoch 151.0 var loss 70682.5703125 reconstruction mse 70670.9609375 imputation mse 0.9937001466751099\n",
      "Train Epoch 151.1 var loss 70689.1484375 reconstruction mse 70685.0390625 imputation mse 0.9938980937004089\n",
      "Train Epoch 151.2 var loss 70684.6171875 reconstruction mse 70680.3984375 imputation mse 0.9938328266143799\n",
      "Train Epoch 151.3 var loss 70700.2734375 reconstruction mse 70696.0234375 imputation mse 0.994052529335022\n",
      "Train Epoch 151.4 var loss 70650.6953125 reconstruction mse 70646.53125 imputation mse 0.9933566451072693\n",
      "Train Epoch 151.5 var loss 70697.3828125 reconstruction mse 70693.328125 imputation mse 0.9940146803855896\n",
      "Train Epoch 151.6 var loss 70708.1171875 reconstruction mse 70704.203125 imputation mse 0.9941675662994385\n",
      "Train Epoch 151.7 var loss 70703.65625 reconstruction mse 70699.8828125 imputation mse 0.9941068291664124\n",
      "Train Epoch 151.8 var loss 70709.3046875 reconstruction mse 70705.546875 imputation mse 0.9941864609718323\n",
      "Train Epoch 151.9 var loss 70684.2109375 reconstruction mse 70680.484375 imputation mse 0.9938340783119202\n",
      "Train Epoch 152.0 var loss 72712.203125 reconstruction mse 72700.8203125 imputation mse 1.0114896297454834\n",
      "Train Epoch 152.1 var loss 72725.453125 reconstruction mse 72721.5390625 imputation mse 1.0117778778076172\n",
      "Train Epoch 152.2 var loss 72708.6171875 reconstruction mse 72704.6015625 imputation mse 1.0115423202514648\n",
      "Train Epoch 152.3 var loss 72728.0 reconstruction mse 72723.9921875 imputation mse 1.0118120908737183\n",
      "Train Epoch 152.4 var loss 72703.203125 reconstruction mse 72699.2421875 imputation mse 1.011467695236206\n",
      "Train Epoch 152.5 var loss 72700.8203125 reconstruction mse 72696.9453125 imputation mse 1.0114357471466064\n",
      "Train Epoch 152.6 var loss 72747.953125 reconstruction mse 72744.1640625 imputation mse 1.0120927095413208\n",
      "Train Epoch 152.7 var loss 72689.0546875 reconstruction mse 72685.3125 imputation mse 1.0112738609313965\n",
      "Train Epoch 152.8 var loss 72750.8203125 reconstruction mse 72747.1015625 imputation mse 1.0121335983276367\n",
      "Train Epoch 152.9 var loss 72742.9140625 reconstruction mse 72739.1875 imputation mse 1.0120234489440918\n",
      "Train Epoch 153.0 var loss 71930.0546875 reconstruction mse 71918.8046875 imputation mse 1.0096133947372437\n",
      "Train Epoch 153.1 var loss 71981.515625 reconstruction mse 71977.5078125 imputation mse 1.0104374885559082\n",
      "Train Epoch 153.2 var loss 71920.6171875 reconstruction mse 71916.453125 imputation mse 1.0095804929733276\n",
      "Train Epoch 153.3 var loss 71949.5859375 reconstruction mse 71945.359375 imputation mse 1.0099862813949585\n",
      "Train Epoch 153.4 var loss 71906.4296875 reconstruction mse 71902.265625 imputation mse 1.0093812942504883\n",
      "Train Epoch 153.5 var loss 71948.2734375 reconstruction mse 71944.1953125 imputation mse 1.00996994972229\n",
      "Train Epoch 153.6 var loss 71922.2734375 reconstruction mse 71918.34375 imputation mse 1.009606957435608\n",
      "Train Epoch 153.7 var loss 71929.578125 reconstruction mse 71925.75 imputation mse 1.0097109079360962\n",
      "Train Epoch 153.8 var loss 71927.7578125 reconstruction mse 71924.0 imputation mse 1.0096863508224487\n",
      "Train Epoch 153.9 var loss 71930.1484375 reconstruction mse 71926.3671875 imputation mse 1.0097196102142334\n",
      "Train Epoch 154.0 var loss 71228.4296875 reconstruction mse 71217.296875 imputation mse 0.9970641136169434\n",
      "Train Epoch 154.1 var loss 71238.1328125 reconstruction mse 71234.125 imputation mse 0.9972996711730957\n",
      "Train Epoch 154.2 var loss 71251.8359375 reconstruction mse 71247.6796875 imputation mse 0.9974894523620605\n",
      "Train Epoch 154.3 var loss 71195.09375 reconstruction mse 71190.8984375 imputation mse 0.9966945052146912\n",
      "Train Epoch 154.4 var loss 71189.2734375 reconstruction mse 71185.0859375 imputation mse 0.9966131448745728\n",
      "Train Epoch 154.5 var loss 71207.8046875 reconstruction mse 71203.7265625 imputation mse 0.9968740940093994\n",
      "Train Epoch 154.6 var loss 71235.0 reconstruction mse 71231.0078125 imputation mse 0.9972560405731201\n",
      "Train Epoch 154.7 var loss 71233.203125 reconstruction mse 71229.328125 imputation mse 0.9972325563430786\n",
      "Train Epoch 154.8 var loss 71156.4609375 reconstruction mse 71152.640625 imputation mse 0.9961588978767395\n",
      "Train Epoch 154.9 var loss 71176.4921875 reconstruction mse 71172.6953125 imputation mse 0.9964396357536316\n",
      "Train Epoch 155.0 var loss 71307.421875 reconstruction mse 71296.4765625 imputation mse 0.9966099262237549\n",
      "Train Epoch 155.1 var loss 71316.96875 reconstruction mse 71312.9921875 imputation mse 0.99684077501297\n",
      "Train Epoch 155.2 var loss 71296.7890625 reconstruction mse 71292.7109375 imputation mse 0.9965572953224182\n",
      "Train Epoch 155.3 var loss 71311.625 reconstruction mse 71307.484375 imputation mse 0.9967637658119202\n",
      "Train Epoch 155.4 var loss 71288.484375 reconstruction mse 71284.3984375 imputation mse 0.9964410662651062\n",
      "Train Epoch 155.5 var loss 71266.09375 reconstruction mse 71262.1015625 imputation mse 0.9961293935775757\n",
      "Train Epoch 155.6 var loss 71250.984375 reconstruction mse 71247.1171875 imputation mse 0.995919942855835\n",
      "Train Epoch 155.7 var loss 71323.9140625 reconstruction mse 71320.140625 imputation mse 0.9969406723976135\n",
      "Train Epoch 155.8 var loss 71296.0 reconstruction mse 71292.2890625 imputation mse 0.9965513944625854\n",
      "Train Epoch 155.9 var loss 71275.1328125 reconstruction mse 71271.421875 imputation mse 0.9962596893310547\n",
      "Train Epoch 156.0 var loss 71444.5078125 reconstruction mse 71433.6953125 imputation mse 1.0019735097885132\n",
      "Train Epoch 156.1 var loss 71418.1796875 reconstruction mse 71414.3203125 imputation mse 1.0017017126083374\n",
      "Train Epoch 156.2 var loss 71418.4375 reconstruction mse 71414.453125 imputation mse 1.0017036199569702\n",
      "Train Epoch 156.3 var loss 71455.3984375 reconstruction mse 71451.3671875 imputation mse 1.0022213459014893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 156.4 var loss 71455.328125 reconstruction mse 71451.34375 imputation mse 1.0022209882736206\n",
      "Train Epoch 156.5 var loss 71454.2421875 reconstruction mse 71450.296875 imputation mse 1.0022063255310059\n",
      "Train Epoch 156.6 var loss 71417.7578125 reconstruction mse 71413.90625 imputation mse 1.0016958713531494\n",
      "Train Epoch 156.7 var loss 71404.9609375 reconstruction mse 71401.1875 imputation mse 1.0015175342559814\n",
      "Train Epoch 156.8 var loss 71429.453125 reconstruction mse 71425.7578125 imputation mse 1.0018621683120728\n",
      "Train Epoch 156.9 var loss 71410.2890625 reconstruction mse 71406.625 imputation mse 1.001593828201294\n",
      "Train Epoch 157.0 var loss 70689.4921875 reconstruction mse 70678.9453125 imputation mse 0.9958287477493286\n",
      "Train Epoch 157.1 var loss 70665.09375 reconstruction mse 70661.3359375 imputation mse 0.9955806136131287\n",
      "Train Epoch 157.2 var loss 70696.875 reconstruction mse 70693.0234375 imputation mse 0.9960271120071411\n",
      "Train Epoch 157.3 var loss 70669.03125 reconstruction mse 70665.125 imputation mse 0.9956340193748474\n",
      "Train Epoch 157.4 var loss 70662.9453125 reconstruction mse 70659.046875 imputation mse 0.9955483675003052\n",
      "Train Epoch 157.5 var loss 70653.1875 reconstruction mse 70649.328125 imputation mse 0.9954114556312561\n",
      "Train Epoch 157.6 var loss 70657.75 reconstruction mse 70653.9453125 imputation mse 0.995476484298706\n",
      "Train Epoch 157.7 var loss 70669.2265625 reconstruction mse 70665.5078125 imputation mse 0.995639443397522\n",
      "Train Epoch 157.8 var loss 70682.6484375 reconstruction mse 70678.96875 imputation mse 0.9958291053771973\n",
      "Train Epoch 157.9 var loss 70659.3046875 reconstruction mse 70655.59375 imputation mse 0.9954997301101685\n",
      "Train Epoch 158.0 var loss 71845.109375 reconstruction mse 71834.65625 imputation mse 1.0058341026306152\n",
      "Train Epoch 158.1 var loss 71818.984375 reconstruction mse 71815.109375 imputation mse 1.0055603981018066\n",
      "Train Epoch 158.2 var loss 71812.5234375 reconstruction mse 71808.546875 imputation mse 1.005468487739563\n",
      "Train Epoch 158.3 var loss 71802.8671875 reconstruction mse 71798.8828125 imputation mse 1.0053331851959229\n",
      "Train Epoch 158.4 var loss 71769.46875 reconstruction mse 71765.53125 imputation mse 1.004866123199463\n",
      "Train Epoch 158.5 var loss 71825.96875 reconstruction mse 71822.109375 imputation mse 1.0056583881378174\n",
      "Train Epoch 158.6 var loss 71849.1015625 reconstruction mse 71845.3359375 imputation mse 1.005983591079712\n",
      "Train Epoch 158.7 var loss 71790.6328125 reconstruction mse 71786.9140625 imputation mse 1.0051655769348145\n",
      "Train Epoch 158.8 var loss 71846.515625 reconstruction mse 71842.8359375 imputation mse 1.005948543548584\n",
      "Train Epoch 158.9 var loss 71783.40625 reconstruction mse 71779.734375 imputation mse 1.0050650835037231\n",
      "Train Epoch 159.0 var loss 72429.265625 reconstruction mse 72419.0 imputation mse 1.00367271900177\n",
      "Train Epoch 159.1 var loss 72435.2421875 reconstruction mse 72431.3984375 imputation mse 1.0038444995880127\n",
      "Train Epoch 159.2 var loss 72382.078125 reconstruction mse 72378.1328125 imputation mse 1.0031063556671143\n",
      "Train Epoch 159.3 var loss 72460.765625 reconstruction mse 72456.75 imputation mse 1.0041959285736084\n",
      "Train Epoch 159.4 var loss 72419.7734375 reconstruction mse 72415.7578125 imputation mse 1.0036277770996094\n",
      "Train Epoch 159.5 var loss 72434.75 reconstruction mse 72430.765625 imputation mse 1.0038357973098755\n",
      "Train Epoch 159.6 var loss 72425.5078125 reconstruction mse 72421.609375 imputation mse 1.003708839416504\n",
      "Train Epoch 159.7 var loss 72416.8828125 reconstruction mse 72413.0234375 imputation mse 1.0035898685455322\n",
      "Train Epoch 159.8 var loss 72386.390625 reconstruction mse 72382.5859375 imputation mse 1.003167986869812\n",
      "Train Epoch 159.9 var loss 72387.40625 reconstruction mse 72383.5859375 imputation mse 1.0031819343566895\n",
      "Train Epoch 160.0 var loss 71879.4609375 reconstruction mse 71869.21875 imputation mse 1.0010477304458618\n",
      "Train Epoch 160.1 var loss 71855.984375 reconstruction mse 71852.0546875 imputation mse 1.000808596611023\n",
      "Train Epoch 160.2 var loss 71861.46875 reconstruction mse 71857.4375 imputation mse 1.0008835792541504\n",
      "Train Epoch 160.3 var loss 71818.9375 reconstruction mse 71814.9140625 imputation mse 1.000291347503662\n",
      "Train Epoch 160.4 var loss 71860.40625 reconstruction mse 71856.4296875 imputation mse 1.0008695125579834\n",
      "Train Epoch 160.5 var loss 71825.4453125 reconstruction mse 71821.5703125 imputation mse 1.000383973121643\n",
      "Train Epoch 160.6 var loss 71848.25 reconstruction mse 71844.453125 imputation mse 1.0007027387619019\n",
      "Train Epoch 160.7 var loss 71840.2578125 reconstruction mse 71836.53125 imputation mse 1.0005923509597778\n",
      "Train Epoch 160.8 var loss 71925.125 reconstruction mse 71921.453125 imputation mse 1.0017752647399902\n",
      "Train Epoch 160.9 var loss 71852.5703125 reconstruction mse 71848.9296875 imputation mse 1.000765085220337\n",
      "====> Test imputation mse: 0.97611582\n",
      "====> Test imputation mse: 0.99842966\n",
      "====> Test imputation mse: 1.01666284\n",
      "Train Epoch 161.0 var loss 71247.171875 reconstruction mse 71237.1171875 imputation mse 0.9918426871299744\n",
      "Train Epoch 161.1 var loss 71251.28125 reconstruction mse 71247.4140625 imputation mse 0.9919860363006592\n",
      "Train Epoch 161.2 var loss 71248.7109375 reconstruction mse 71244.7265625 imputation mse 0.9919486045837402\n",
      "Train Epoch 161.3 var loss 71243.9453125 reconstruction mse 71239.890625 imputation mse 0.9918813109397888\n",
      "Train Epoch 161.4 var loss 71204.453125 reconstruction mse 71200.40625 imputation mse 0.9913315773010254\n",
      "Train Epoch 161.5 var loss 71242.078125 reconstruction mse 71238.0625 imputation mse 0.9918558597564697\n",
      "Train Epoch 161.6 var loss 71231.171875 reconstruction mse 71227.234375 imputation mse 0.991705060005188\n",
      "Train Epoch 161.7 var loss 71278.7421875 reconstruction mse 71274.90625 imputation mse 0.9923688173294067\n",
      "Train Epoch 161.8 var loss 71236.96875 reconstruction mse 71233.203125 imputation mse 0.9917882084846497\n",
      "Train Epoch 161.9 var loss 71263.2265625 reconstruction mse 71259.5 imputation mse 0.9921543002128601\n",
      "Train Epoch 162.0 var loss 71533.34375 reconstruction mse 71523.359375 imputation mse 0.9997813701629639\n",
      "Train Epoch 162.1 var loss 71556.8828125 reconstruction mse 71553.03125 imputation mse 1.000196099281311\n",
      "Train Epoch 162.2 var loss 71547.4765625 reconstruction mse 71543.5703125 imputation mse 1.0000638961791992\n",
      "Train Epoch 162.3 var loss 71516.59375 reconstruction mse 71512.65625 imputation mse 0.9996317625045776\n",
      "Train Epoch 162.4 var loss 71525.6171875 reconstruction mse 71521.703125 imputation mse 0.999758243560791\n",
      "Train Epoch 162.5 var loss 71570.0 reconstruction mse 71566.125 imputation mse 1.000379204750061\n",
      "Train Epoch 162.6 var loss 71537.875 reconstruction mse 71534.0546875 imputation mse 0.9999308586120605\n",
      "Train Epoch 162.7 var loss 71539.3046875 reconstruction mse 71535.53125 imputation mse 0.9999515414237976\n",
      "Train Epoch 162.8 var loss 71536.7265625 reconstruction mse 71532.96875 imputation mse 0.9999157190322876\n",
      "Train Epoch 162.9 var loss 71535.3671875 reconstruction mse 71531.609375 imputation mse 0.9998967051506042\n",
      "Train Epoch 163.0 var loss 71567.3125 reconstruction mse 71557.5546875 imputation mse 1.0061240196228027\n",
      "Train Epoch 163.1 var loss 71603.5703125 reconstruction mse 71599.703125 imputation mse 1.0067167282104492\n",
      "Train Epoch 163.2 var loss 71565.15625 reconstruction mse 71561.234375 imputation mse 1.0061757564544678\n",
      "Train Epoch 163.3 var loss 71548.5078125 reconstruction mse 71544.5859375 imputation mse 1.0059417486190796\n",
      "Train Epoch 163.4 var loss 71592.015625 reconstruction mse 71588.1171875 imputation mse 1.0065537691116333\n",
      "Train Epoch 163.5 var loss 71529.140625 reconstruction mse 71525.28125 imputation mse 1.0056703090667725\n",
      "Train Epoch 163.6 var loss 71547.5625 reconstruction mse 71543.7734375 imputation mse 1.0059303045272827\n",
      "Train Epoch 163.7 var loss 71512.5078125 reconstruction mse 71508.7890625 imputation mse 1.0054384469985962\n",
      "Train Epoch 163.8 var loss 71558.6640625 reconstruction mse 71554.953125 imputation mse 1.0060874223709106\n",
      "Train Epoch 163.9 var loss 71479.7421875 reconstruction mse 71476.03125 imputation mse 1.004977822303772\n",
      "Train Epoch 164.0 var loss 71731.421875 reconstruction mse 71721.78125 imputation mse 1.0067486763000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 164.1 var loss 71775.2109375 reconstruction mse 71771.34375 imputation mse 1.0074443817138672\n",
      "Train Epoch 164.2 var loss 71777.0546875 reconstruction mse 71773.09375 imputation mse 1.0074689388275146\n",
      "Train Epoch 164.3 var loss 71801.296875 reconstruction mse 71797.3046875 imputation mse 1.007808804512024\n",
      "Train Epoch 164.4 var loss 71793.1640625 reconstruction mse 71789.234375 imputation mse 1.0076954364776611\n",
      "Train Epoch 164.5 var loss 71775.515625 reconstruction mse 71771.671875 imputation mse 1.0074489116668701\n",
      "Train Epoch 164.6 var loss 71739.9609375 reconstruction mse 71736.2265625 imputation mse 1.0069514513015747\n",
      "Train Epoch 164.7 var loss 71780.1015625 reconstruction mse 71776.4296875 imputation mse 1.007515788078308\n",
      "Train Epoch 164.8 var loss 71755.484375 reconstruction mse 71751.8515625 imputation mse 1.0071707963943481\n",
      "Train Epoch 164.9 var loss 71747.421875 reconstruction mse 71743.78125 imputation mse 1.0070574283599854\n",
      "Train Epoch 165.0 var loss 71414.4765625 reconstruction mse 71404.953125 imputation mse 0.9973734021186829\n",
      "Train Epoch 165.1 var loss 71420.03125 reconstruction mse 71416.1953125 imputation mse 0.9975304007530212\n",
      "Train Epoch 165.2 var loss 71409.6796875 reconstruction mse 71405.765625 imputation mse 0.9973847270011902\n",
      "Train Epoch 165.3 var loss 71399.015625 reconstruction mse 71395.0703125 imputation mse 0.9972353577613831\n",
      "Train Epoch 165.4 var loss 71390.3828125 reconstruction mse 71386.46875 imputation mse 0.9971151947975159\n",
      "Train Epoch 165.5 var loss 71429.3828125 reconstruction mse 71425.546875 imputation mse 0.9976610541343689\n",
      "Train Epoch 165.6 var loss 71354.328125 reconstruction mse 71350.5703125 imputation mse 0.9966138005256653\n",
      "Train Epoch 165.7 var loss 71433.5546875 reconstruction mse 71429.84375 imputation mse 0.9977210760116577\n",
      "Train Epoch 165.8 var loss 71391.578125 reconstruction mse 71387.921875 imputation mse 0.9971355199813843\n",
      "Train Epoch 165.9 var loss 71413.3671875 reconstruction mse 71409.734375 imputation mse 0.9974401593208313\n",
      "Train Epoch 166.0 var loss 71105.3515625 reconstruction mse 71095.9921875 imputation mse 0.9954633712768555\n",
      "Train Epoch 166.1 var loss 71074.609375 reconstruction mse 71070.796875 imputation mse 0.9951105713844299\n",
      "Train Epoch 166.2 var loss 71112.921875 reconstruction mse 71108.9921875 imputation mse 0.9956453442573547\n",
      "Train Epoch 166.3 var loss 71154.15625 reconstruction mse 71150.2109375 imputation mse 0.9962224960327148\n",
      "Train Epoch 166.4 var loss 71132.125 reconstruction mse 71128.1796875 imputation mse 0.9959140419960022\n",
      "Train Epoch 166.5 var loss 71138.96875 reconstruction mse 71135.0859375 imputation mse 0.9960107207298279\n",
      "Train Epoch 166.6 var loss 71129.53125 reconstruction mse 71125.7265625 imputation mse 0.9958796501159668\n",
      "Train Epoch 166.7 var loss 71124.734375 reconstruction mse 71121.0 imputation mse 0.9958134889602661\n",
      "Train Epoch 166.8 var loss 71103.359375 reconstruction mse 71099.6875 imputation mse 0.9955151081085205\n",
      "Train Epoch 166.9 var loss 71127.6875 reconstruction mse 71124.03125 imputation mse 0.9958559274673462\n",
      "Train Epoch 167.0 var loss 71694.484375 reconstruction mse 71685.21875 imputation mse 1.0013999938964844\n",
      "Train Epoch 167.1 var loss 71685.390625 reconstruction mse 71681.609375 imputation mse 1.0013495683670044\n",
      "Train Epoch 167.2 var loss 71701.125 reconstruction mse 71697.265625 imputation mse 1.00156831741333\n",
      "Train Epoch 167.3 var loss 71673.4921875 reconstruction mse 71669.6171875 imputation mse 1.0011820793151855\n",
      "Train Epoch 167.4 var loss 71699.2421875 reconstruction mse 71695.40625 imputation mse 1.001542329788208\n",
      "Train Epoch 167.5 var loss 71636.6328125 reconstruction mse 71632.890625 imputation mse 1.000669002532959\n",
      "Train Epoch 167.6 var loss 71651.3515625 reconstruction mse 71647.6484375 imputation mse 1.0008751153945923\n",
      "Train Epoch 167.7 var loss 71680.34375 reconstruction mse 71676.6875 imputation mse 1.0012807846069336\n",
      "Train Epoch 167.8 var loss 71666.578125 reconstruction mse 71662.9375 imputation mse 1.0010887384414673\n",
      "Train Epoch 167.9 var loss 71679.2109375 reconstruction mse 71675.5625 imputation mse 1.001265048980713\n",
      "Train Epoch 168.0 var loss 71186.6796875 reconstruction mse 71177.6015625 imputation mse 0.9929080009460449\n",
      "Train Epoch 168.1 var loss 71257.8046875 reconstruction mse 71253.984375 imputation mse 0.9939734935760498\n",
      "Train Epoch 168.2 var loss 71208.3671875 reconstruction mse 71204.453125 imputation mse 0.9932825565338135\n",
      "Train Epoch 168.3 var loss 71200.4296875 reconstruction mse 71196.5078125 imputation mse 0.9931716918945312\n",
      "Train Epoch 168.4 var loss 71217.96875 reconstruction mse 71214.1484375 imputation mse 0.9934177994728088\n",
      "Train Epoch 168.5 var loss 71245.1875 reconstruction mse 71241.4296875 imputation mse 0.9937983751296997\n",
      "Train Epoch 168.6 var loss 71242.859375 reconstruction mse 71239.1953125 imputation mse 0.9937672019004822\n",
      "Train Epoch 168.7 var loss 71194.078125 reconstruction mse 71190.484375 imputation mse 0.9930877089500427\n",
      "Train Epoch 168.8 var loss 71174.203125 reconstruction mse 71170.6328125 imputation mse 0.9928107857704163\n",
      "Train Epoch 168.9 var loss 71204.0078125 reconstruction mse 71200.4765625 imputation mse 0.9932270646095276\n",
      "Train Epoch 169.0 var loss 72072.6875 reconstruction mse 72063.7421875 imputation mse 1.001358151435852\n",
      "Train Epoch 169.1 var loss 72055.75 reconstruction mse 72052.078125 imputation mse 1.0011961460113525\n",
      "Train Epoch 169.2 var loss 72071.0703125 reconstruction mse 72067.3046875 imputation mse 1.0014076232910156\n",
      "Train Epoch 169.3 var loss 72068.78125 reconstruction mse 72065.0 imputation mse 1.001375675201416\n",
      "Train Epoch 169.4 var loss 72081.703125 reconstruction mse 72077.9375 imputation mse 1.0015554428100586\n",
      "Train Epoch 169.5 var loss 72080.5703125 reconstruction mse 72076.8515625 imputation mse 1.0015403032302856\n",
      "Train Epoch 169.6 var loss 72079.28125 reconstruction mse 72075.625 imputation mse 1.0015232563018799\n",
      "Train Epoch 169.7 var loss 72058.7421875 reconstruction mse 72055.1640625 imputation mse 1.0012389421463013\n",
      "Train Epoch 169.8 var loss 72091.3515625 reconstruction mse 72087.8203125 imputation mse 1.001692771911621\n",
      "Train Epoch 169.9 var loss 72059.1953125 reconstruction mse 72055.6953125 imputation mse 1.0012463331222534\n",
      "Train Epoch 170.0 var loss 71626.171875 reconstruction mse 71617.3828125 imputation mse 1.002244472503662\n",
      "Train Epoch 170.1 var loss 71582.765625 reconstruction mse 71579.140625 imputation mse 1.0017093420028687\n",
      "Train Epoch 170.2 var loss 71588.0390625 reconstruction mse 71584.2890625 imputation mse 1.0017813444137573\n",
      "Train Epoch 170.3 var loss 71638.046875 reconstruction mse 71634.21875 imputation mse 1.0024800300598145\n",
      "Train Epoch 170.4 var loss 71591.71875 reconstruction mse 71587.8984375 imputation mse 1.0018318891525269\n",
      "Train Epoch 170.5 var loss 71616.8515625 reconstruction mse 71613.1171875 imputation mse 1.0021847486495972\n",
      "Train Epoch 170.6 var loss 71604.359375 reconstruction mse 71600.6953125 imputation mse 1.0020109415054321\n",
      "Train Epoch 170.7 var loss 71629.7734375 reconstruction mse 71626.1953125 imputation mse 1.0023677349090576\n",
      "Train Epoch 170.8 var loss 71579.4375 reconstruction mse 71575.8828125 imputation mse 1.0016636848449707\n",
      "Train Epoch 170.9 var loss 71580.7578125 reconstruction mse 71577.2109375 imputation mse 1.0016822814941406\n",
      "====> Test imputation mse: 1.02306330\n",
      "====> Test imputation mse: 1.00992751\n",
      "====> Test imputation mse: 1.00093853\n",
      "Train Epoch 171.0 var loss 71578.3359375 reconstruction mse 71569.6328125 imputation mse 0.9998551607131958\n",
      "Train Epoch 171.1 var loss 71574.4921875 reconstruction mse 71570.7578125 imputation mse 0.9998708963394165\n",
      "Train Epoch 171.2 var loss 71497.7578125 reconstruction mse 71493.8984375 imputation mse 0.9987971186637878\n",
      "Train Epoch 171.3 var loss 71523.0546875 reconstruction mse 71519.140625 imputation mse 0.9991497993469238\n",
      "Train Epoch 171.4 var loss 71547.09375 reconstruction mse 71543.203125 imputation mse 0.9994859099388123\n",
      "Train Epoch 171.5 var loss 71512.6015625 reconstruction mse 71508.8125 imputation mse 0.9990054965019226\n",
      "Train Epoch 171.6 var loss 71546.0625 reconstruction mse 71542.359375 imputation mse 0.9994741678237915\n",
      "Train Epoch 171.7 var loss 71533.3671875 reconstruction mse 71529.7734375 imputation mse 0.9992983341217041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 171.8 var loss 71538.625 reconstruction mse 71535.1328125 imputation mse 0.999373197555542\n",
      "Train Epoch 171.9 var loss 71495.609375 reconstruction mse 71492.1796875 imputation mse 0.9987730979919434\n",
      "Train Epoch 172.0 var loss 71464.5546875 reconstruction mse 71456.0234375 imputation mse 0.9983935356140137\n",
      "Train Epoch 172.1 var loss 71431.203125 reconstruction mse 71427.59375 imputation mse 0.9979963302612305\n",
      "Train Epoch 172.2 var loss 71422.6640625 reconstruction mse 71418.921875 imputation mse 0.9978751540184021\n",
      "Train Epoch 172.3 var loss 71466.8828125 reconstruction mse 71463.0859375 imputation mse 0.9984921813011169\n",
      "Train Epoch 172.4 var loss 71462.6796875 reconstruction mse 71458.8203125 imputation mse 0.9984326362609863\n",
      "Train Epoch 172.5 var loss 71460.765625 reconstruction mse 71456.9140625 imputation mse 0.9984059929847717\n",
      "Train Epoch 172.6 var loss 71437.5078125 reconstruction mse 71433.6875 imputation mse 0.9980814456939697\n",
      "Train Epoch 172.7 var loss 71450.9296875 reconstruction mse 71447.1484375 imputation mse 0.9982695579528809\n",
      "Train Epoch 172.8 var loss 71426.2890625 reconstruction mse 71422.5859375 imputation mse 0.9979263544082642\n",
      "Train Epoch 172.9 var loss 71435.5703125 reconstruction mse 71431.8984375 imputation mse 0.9980564713478088\n",
      "Train Epoch 173.0 var loss 71274.953125 reconstruction mse 71266.375 imputation mse 1.0004123449325562\n",
      "Train Epoch 173.1 var loss 71276.5 reconstruction mse 71272.6640625 imputation mse 1.0005006790161133\n",
      "Train Epoch 173.2 var loss 71258.1796875 reconstruction mse 71254.2890625 imputation mse 1.0002427101135254\n",
      "Train Epoch 173.3 var loss 71221.2265625 reconstruction mse 71217.3203125 imputation mse 0.9997237324714661\n",
      "Train Epoch 173.4 var loss 71270.0703125 reconstruction mse 71266.2109375 imputation mse 1.0004100799560547\n",
      "Train Epoch 173.5 var loss 71227.1015625 reconstruction mse 71223.375 imputation mse 0.9998087286949158\n",
      "Train Epoch 173.6 var loss 71279.984375 reconstruction mse 71276.34375 imputation mse 1.0005522966384888\n",
      "Train Epoch 173.7 var loss 71231.6640625 reconstruction mse 71228.0859375 imputation mse 0.9998748898506165\n",
      "Train Epoch 173.8 var loss 71247.0234375 reconstruction mse 71243.484375 imputation mse 1.0000910758972168\n",
      "Train Epoch 173.9 var loss 71291.9375 reconstruction mse 71288.3671875 imputation mse 1.0007210969924927\n",
      "Train Epoch 174.0 var loss 71074.5390625 reconstruction mse 71066.0546875 imputation mse 0.9963555335998535\n",
      "Train Epoch 174.1 var loss 71061.4140625 reconstruction mse 71057.5859375 imputation mse 0.9962368011474609\n",
      "Train Epoch 174.2 var loss 71042.2421875 reconstruction mse 71038.2890625 imputation mse 0.9959662556648254\n",
      "Train Epoch 174.3 var loss 71038.4609375 reconstruction mse 71034.4453125 imputation mse 0.9959123730659485\n",
      "Train Epoch 174.4 var loss 71072.2265625 reconstruction mse 71068.2734375 imputation mse 0.9963866472244263\n",
      "Train Epoch 174.5 var loss 71057.03125 reconstruction mse 71053.203125 imputation mse 0.9961753487586975\n",
      "Train Epoch 174.6 var loss 71098.1875 reconstruction mse 71094.484375 imputation mse 0.9967541098594666\n",
      "Train Epoch 174.7 var loss 71084.4140625 reconstruction mse 71080.8515625 imputation mse 0.9965629577636719\n",
      "Train Epoch 174.8 var loss 71099.1484375 reconstruction mse 71095.6484375 imputation mse 0.996770441532135\n",
      "Train Epoch 174.9 var loss 71028.9140625 reconstruction mse 71025.4140625 imputation mse 0.9957857728004456\n",
      "Train Epoch 175.0 var loss 71136.0625 reconstruction mse 71127.7265625 imputation mse 0.9985501766204834\n",
      "Train Epoch 175.1 var loss 71114.5234375 reconstruction mse 71110.7734375 imputation mse 0.9983121752738953\n",
      "Train Epoch 175.2 var loss 71141.40625 reconstruction mse 71137.5546875 imputation mse 0.9986881613731384\n",
      "Train Epoch 175.3 var loss 71136.7578125 reconstruction mse 71132.8671875 imputation mse 0.9986223578453064\n",
      "Train Epoch 175.4 var loss 71146.9609375 reconstruction mse 71143.109375 imputation mse 0.9987661242485046\n",
      "Train Epoch 175.5 var loss 71135.484375 reconstruction mse 71131.6953125 imputation mse 0.9986059069633484\n",
      "Train Epoch 175.6 var loss 71130.734375 reconstruction mse 71127.046875 imputation mse 0.9985406398773193\n",
      "Train Epoch 175.7 var loss 71124.2734375 reconstruction mse 71120.71875 imputation mse 0.9984517693519592\n",
      "Train Epoch 175.8 var loss 71111.4140625 reconstruction mse 71107.90625 imputation mse 0.9982718825340271\n",
      "Train Epoch 175.9 var loss 71165.8515625 reconstruction mse 71162.3828125 imputation mse 0.9990366697311401\n",
      "Train Epoch 176.0 var loss 72072.7421875 reconstruction mse 72064.5859375 imputation mse 1.0044264793395996\n",
      "Train Epoch 176.1 var loss 72085.6015625 reconstruction mse 72081.921875 imputation mse 1.004668116569519\n",
      "Train Epoch 176.2 var loss 72086.96875 reconstruction mse 72083.1484375 imputation mse 1.0046851634979248\n",
      "Train Epoch 176.3 var loss 72057.0 reconstruction mse 72053.078125 imputation mse 1.0042660236358643\n",
      "Train Epoch 176.4 var loss 72065.109375 reconstruction mse 72061.2109375 imputation mse 1.004379391670227\n",
      "Train Epoch 176.5 var loss 72062.2578125 reconstruction mse 72058.4375 imputation mse 1.0043407678604126\n",
      "Train Epoch 176.6 var loss 72056.875 reconstruction mse 72053.125 imputation mse 1.0042667388916016\n",
      "Train Epoch 176.7 var loss 72069.0 reconstruction mse 72065.296875 imputation mse 1.0044363737106323\n",
      "Train Epoch 176.8 var loss 72072.453125 reconstruction mse 72068.7890625 imputation mse 1.004485011100769\n",
      "Train Epoch 176.9 var loss 72066.3828125 reconstruction mse 72062.75 imputation mse 1.0044008493423462\n",
      "Train Epoch 177.0 var loss 71642.1875 reconstruction mse 71634.046875 imputation mse 1.0018047094345093\n",
      "Train Epoch 177.1 var loss 71687.5 reconstruction mse 71683.703125 imputation mse 1.0024992227554321\n",
      "Train Epoch 177.2 var loss 71658.3828125 reconstruction mse 71654.4921875 imputation mse 1.0020906925201416\n",
      "Train Epoch 177.3 var loss 71641.8203125 reconstruction mse 71637.8984375 imputation mse 1.0018585920333862\n",
      "Train Epoch 177.4 var loss 71659.3359375 reconstruction mse 71655.4765625 imputation mse 1.00210440158844\n",
      "Train Epoch 177.5 var loss 71696.78125 reconstruction mse 71693.0078125 imputation mse 1.002629280090332\n",
      "Train Epoch 177.6 var loss 71694.7265625 reconstruction mse 71691.0390625 imputation mse 1.0026017427444458\n",
      "Train Epoch 177.7 var loss 71673.1875 reconstruction mse 71669.5859375 imputation mse 1.0023016929626465\n",
      "Train Epoch 177.8 var loss 71633.46875 reconstruction mse 71629.9296875 imputation mse 1.0017471313476562\n",
      "Train Epoch 177.9 var loss 71663.1875 reconstruction mse 71659.6796875 imputation mse 1.0021631717681885\n",
      "Train Epoch 178.0 var loss 71492.34375 reconstruction mse 71484.3203125 imputation mse 1.002360224723816\n",
      "Train Epoch 178.1 var loss 71546.7265625 reconstruction mse 71543.0078125 imputation mse 1.003183126449585\n",
      "Train Epoch 178.2 var loss 71554.375 reconstruction mse 71550.5234375 imputation mse 1.0032885074615479\n",
      "Train Epoch 178.3 var loss 71528.90625 reconstruction mse 71524.984375 imputation mse 1.0029304027557373\n",
      "Train Epoch 178.4 var loss 71534.125 reconstruction mse 71530.21875 imputation mse 1.0030038356781006\n",
      "Train Epoch 178.5 var loss 71542.03125 reconstruction mse 71538.2578125 imputation mse 1.003116488456726\n",
      "Train Epoch 178.6 var loss 71517.0234375 reconstruction mse 71513.375 imputation mse 1.002767562866211\n",
      "Train Epoch 178.7 var loss 71555.9140625 reconstruction mse 71552.3515625 imputation mse 1.0033141374588013\n",
      "Train Epoch 178.8 var loss 71506.53125 reconstruction mse 71503.0390625 imputation mse 1.0026227235794067\n",
      "Train Epoch 178.9 var loss 71561.296875 reconstruction mse 71557.7890625 imputation mse 1.0033904314041138\n",
      "Train Epoch 179.0 var loss 72161.0390625 reconstruction mse 72153.078125 imputation mse 1.0029897689819336\n",
      "Train Epoch 179.1 var loss 72178.8828125 reconstruction mse 72175.1328125 imputation mse 1.0032963752746582\n",
      "Train Epoch 179.2 var loss 72172.1484375 reconstruction mse 72168.28125 imputation mse 1.0032011270523071\n",
      "Train Epoch 179.3 var loss 72245.765625 reconstruction mse 72241.890625 imputation mse 1.0042243003845215\n",
      "Train Epoch 179.4 var loss 72177.6015625 reconstruction mse 72173.7578125 imputation mse 1.0032771825790405\n",
      "Train Epoch 179.5 var loss 72141.234375 reconstruction mse 72137.4765625 imputation mse 1.0027729272842407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 179.6 var loss 72166.3671875 reconstruction mse 72162.703125 imputation mse 1.0031235218048096\n",
      "Train Epoch 179.7 var loss 72182.1953125 reconstruction mse 72178.6171875 imputation mse 1.0033447742462158\n",
      "Train Epoch 179.8 var loss 72128.7890625 reconstruction mse 72125.265625 imputation mse 1.0026031732559204\n",
      "Train Epoch 179.9 var loss 72184.28125 reconstruction mse 72180.78125 imputation mse 1.0033748149871826\n",
      "Train Epoch 180.0 var loss 71773.703125 reconstruction mse 71765.9140625 imputation mse 1.0058996677398682\n",
      "Train Epoch 180.1 var loss 71777.984375 reconstruction mse 71774.3203125 imputation mse 1.0060175657272339\n",
      "Train Epoch 180.2 var loss 71807.0703125 reconstruction mse 71803.34375 imputation mse 1.0064243078231812\n",
      "Train Epoch 180.3 var loss 71791.5546875 reconstruction mse 71787.8125 imputation mse 1.0062066316604614\n",
      "Train Epoch 180.4 var loss 71795.5625 reconstruction mse 71791.8359375 imputation mse 1.006263017654419\n",
      "Train Epoch 180.5 var loss 71779.1640625 reconstruction mse 71775.515625 imputation mse 1.006034255027771\n",
      "Train Epoch 180.6 var loss 71818.75 reconstruction mse 71815.171875 imputation mse 1.0065901279449463\n",
      "Train Epoch 180.7 var loss 71792.7890625 reconstruction mse 71789.265625 imputation mse 1.0062270164489746\n",
      "Train Epoch 180.8 var loss 71793.8984375 reconstruction mse 71790.390625 imputation mse 1.0062427520751953\n",
      "Train Epoch 180.9 var loss 71758.515625 reconstruction mse 71755.015625 imputation mse 1.0057469606399536\n",
      "====> Test imputation mse: 1.01395822\n",
      "====> Test imputation mse: 1.01100826\n",
      "====> Test imputation mse: 0.99627441\n",
      "Train Epoch 181.0 var loss 70964.96875 reconstruction mse 70957.3046875 imputation mse 0.9987656474113464\n",
      "Train Epoch 181.1 var loss 70936.7890625 reconstruction mse 70933.078125 imputation mse 0.9984246492385864\n",
      "Train Epoch 181.2 var loss 70908.1484375 reconstruction mse 70904.3359375 imputation mse 0.9980200529098511\n",
      "Train Epoch 181.3 var loss 70990.5078125 reconstruction mse 70986.6953125 imputation mse 0.9991793036460876\n",
      "Train Epoch 181.4 var loss 70890.8671875 reconstruction mse 70887.1015625 imputation mse 0.9977774620056152\n",
      "Train Epoch 181.5 var loss 70940.5234375 reconstruction mse 70936.859375 imputation mse 0.9984778761863708\n",
      "Train Epoch 181.6 var loss 70953.578125 reconstruction mse 70949.984375 imputation mse 0.9986625909805298\n",
      "Train Epoch 181.7 var loss 70961.90625 reconstruction mse 70958.390625 imputation mse 0.9987809062004089\n",
      "Train Epoch 181.8 var loss 70962.2421875 reconstruction mse 70958.7578125 imputation mse 0.9987860918045044\n",
      "Train Epoch 181.9 var loss 70959.8125 reconstruction mse 70956.28125 imputation mse 0.9987512230873108\n",
      "Train Epoch 182.0 var loss 70972.4453125 reconstruction mse 70964.7734375 imputation mse 0.9970323443412781\n",
      "Train Epoch 182.1 var loss 70926.125 reconstruction mse 70922.3828125 imputation mse 0.9964367747306824\n",
      "Train Epoch 182.2 var loss 70944.515625 reconstruction mse 70940.6640625 imputation mse 0.9966936111450195\n",
      "Train Epoch 182.3 var loss 70921.734375 reconstruction mse 70917.8828125 imputation mse 0.9963735342025757\n",
      "Train Epoch 182.4 var loss 70949.609375 reconstruction mse 70945.796875 imputation mse 0.9967657327651978\n",
      "Train Epoch 182.5 var loss 70978.46875 reconstruction mse 70974.7421875 imputation mse 0.9971724152565002\n",
      "Train Epoch 182.6 var loss 70957.453125 reconstruction mse 70953.796875 imputation mse 0.9968780875205994\n",
      "Train Epoch 182.7 var loss 70982.1015625 reconstruction mse 70978.5234375 imputation mse 0.9972255229949951\n",
      "Train Epoch 182.8 var loss 70944.3828125 reconstruction mse 70940.8359375 imputation mse 0.9966959953308105\n",
      "Train Epoch 182.9 var loss 70946.140625 reconstruction mse 70942.609375 imputation mse 0.9967209100723267\n",
      "Train Epoch 183.0 var loss 71388.9140625 reconstruction mse 71381.3671875 imputation mse 0.9941417574882507\n",
      "Train Epoch 183.1 var loss 71433.96875 reconstruction mse 71430.234375 imputation mse 0.9948223233222961\n",
      "Train Epoch 183.2 var loss 71433.1171875 reconstruction mse 71429.2890625 imputation mse 0.9948092103004456\n",
      "Train Epoch 183.3 var loss 71364.515625 reconstruction mse 71360.6640625 imputation mse 0.9938534498214722\n",
      "Train Epoch 183.4 var loss 71358.6171875 reconstruction mse 71354.8203125 imputation mse 0.993772029876709\n",
      "Train Epoch 183.5 var loss 71400.9296875 reconstruction mse 71397.21875 imputation mse 0.9943625330924988\n",
      "Train Epoch 183.6 var loss 71396.25 reconstruction mse 71392.65625 imputation mse 0.9942989945411682\n",
      "Train Epoch 183.7 var loss 71351.4609375 reconstruction mse 71347.9296875 imputation mse 0.9936760663986206\n",
      "Train Epoch 183.8 var loss 71391.078125 reconstruction mse 71387.6171875 imputation mse 0.9942288398742676\n",
      "Train Epoch 183.9 var loss 71408.6484375 reconstruction mse 71405.2265625 imputation mse 0.9944740533828735\n",
      "Train Epoch 184.0 var loss 72120.21875 reconstruction mse 72112.8125 imputation mse 1.0030853748321533\n",
      "Train Epoch 184.1 var loss 72172.078125 reconstruction mse 72168.53125 imputation mse 1.0038604736328125\n",
      "Train Epoch 184.2 var loss 72126.1796875 reconstruction mse 72122.515625 imputation mse 1.0032203197479248\n",
      "Train Epoch 184.3 var loss 72137.34375 reconstruction mse 72133.640625 imputation mse 1.0033751726150513\n",
      "Train Epoch 184.4 var loss 72133.8203125 reconstruction mse 72130.125 imputation mse 1.003326177597046\n",
      "Train Epoch 184.5 var loss 72138.1875 reconstruction mse 72134.5703125 imputation mse 1.0033880472183228\n",
      "Train Epoch 184.6 var loss 72132.4609375 reconstruction mse 72128.8984375 imputation mse 1.0033091306686401\n",
      "Train Epoch 184.7 var loss 72112.0859375 reconstruction mse 72108.5625 imputation mse 1.0030262470245361\n",
      "Train Epoch 184.8 var loss 72146.25 reconstruction mse 72142.7265625 imputation mse 1.003501534461975\n",
      "Train Epoch 184.9 var loss 72104.59375 reconstruction mse 72101.0390625 imputation mse 1.0029215812683105\n",
      "Train Epoch 185.0 var loss 71900.28125 reconstruction mse 71892.8046875 imputation mse 1.0126317739486694\n",
      "Train Epoch 185.1 var loss 71904.4375 reconstruction mse 71900.65625 imputation mse 1.0127424001693726\n",
      "Train Epoch 185.2 var loss 71914.8984375 reconstruction mse 71911.0078125 imputation mse 1.0128881931304932\n",
      "Train Epoch 185.3 var loss 71910.125 reconstruction mse 71906.25 imputation mse 1.0128211975097656\n",
      "Train Epoch 185.4 var loss 71873.453125 reconstruction mse 71869.65625 imputation mse 1.012305736541748\n",
      "Train Epoch 185.5 var loss 71926.96875 reconstruction mse 71923.28125 imputation mse 1.0130610466003418\n",
      "Train Epoch 185.6 var loss 71869.1015625 reconstruction mse 71865.5 imputation mse 1.0122472047805786\n",
      "Train Epoch 185.7 var loss 71885.7890625 reconstruction mse 71882.234375 imputation mse 1.0124828815460205\n",
      "Train Epoch 185.8 var loss 71936.6640625 reconstruction mse 71933.09375 imputation mse 1.0131992101669312\n",
      "Train Epoch 185.9 var loss 71908.03125 reconstruction mse 71904.484375 imputation mse 1.0127962827682495\n",
      "Train Epoch 186.0 var loss 72157.109375 reconstruction mse 72149.7265625 imputation mse 1.0013285875320435\n",
      "Train Epoch 186.1 var loss 72116.984375 reconstruction mse 72113.2109375 imputation mse 1.0008217096328735\n",
      "Train Epoch 186.2 var loss 72160.3203125 reconstruction mse 72156.4375 imputation mse 1.0014216899871826\n",
      "Train Epoch 186.3 var loss 72147.3046875 reconstruction mse 72143.4296875 imputation mse 1.0012412071228027\n",
      "Train Epoch 186.4 var loss 72126.53125 reconstruction mse 72122.71875 imputation mse 1.0009536743164062\n",
      "Train Epoch 186.5 var loss 72152.9453125 reconstruction mse 72149.25 imputation mse 1.0013219118118286\n",
      "Train Epoch 186.6 var loss 72119.328125 reconstruction mse 72115.7421875 imputation mse 1.000856876373291\n",
      "Train Epoch 186.7 var loss 72152.5703125 reconstruction mse 72149.015625 imputation mse 1.0013186931610107\n",
      "Train Epoch 186.8 var loss 72122.0546875 reconstruction mse 72118.4921875 imputation mse 1.0008950233459473\n",
      "Train Epoch 186.9 var loss 72148.6640625 reconstruction mse 72145.0625 imputation mse 1.0012638568878174\n",
      "Train Epoch 187.0 var loss 71413.078125 reconstruction mse 71405.796875 imputation mse 0.9967308044433594\n",
      "Train Epoch 187.1 var loss 71398.6796875 reconstruction mse 71394.875 imputation mse 0.9965783953666687\n",
      "Train Epoch 187.2 var loss 71437.7265625 reconstruction mse 71433.8046875 imputation mse 0.9971218109130859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 187.3 var loss 71413.3671875 reconstruction mse 71409.453125 imputation mse 0.9967818856239319\n",
      "Train Epoch 187.4 var loss 71437.6796875 reconstruction mse 71433.8828125 imputation mse 0.9971228837966919\n",
      "Train Epoch 187.5 var loss 71432.75 reconstruction mse 71429.0625 imputation mse 0.9970555901527405\n",
      "Train Epoch 187.6 var loss 71441.484375 reconstruction mse 71437.8984375 imputation mse 0.9971789121627808\n",
      "Train Epoch 187.7 var loss 71425.4921875 reconstruction mse 71421.9609375 imputation mse 0.996956467628479\n",
      "Train Epoch 187.8 var loss 71417.5625 reconstruction mse 71414.0234375 imputation mse 0.9968456625938416\n",
      "Train Epoch 187.9 var loss 71427.78125 reconstruction mse 71424.234375 imputation mse 0.9969881772994995\n",
      "Train Epoch 188.0 var loss 71684.328125 reconstruction mse 71677.09375 imputation mse 0.9953492879867554\n",
      "Train Epoch 188.1 var loss 71681.4140625 reconstruction mse 71677.671875 imputation mse 0.9953573346138\n",
      "Train Epoch 188.2 var loss 71629.0859375 reconstruction mse 71625.2734375 imputation mse 0.9946296811103821\n",
      "Train Epoch 188.3 var loss 71597.2578125 reconstruction mse 71593.46875 imputation mse 0.9941880106925964\n",
      "Train Epoch 188.4 var loss 71660.4453125 reconstruction mse 71656.734375 imputation mse 0.9950665831565857\n",
      "Train Epoch 188.5 var loss 71670.3046875 reconstruction mse 71666.6796875 imputation mse 0.9952046871185303\n",
      "Train Epoch 188.6 var loss 71652.0859375 reconstruction mse 71648.53125 imputation mse 0.9949526786804199\n",
      "Train Epoch 188.7 var loss 71648.84375 reconstruction mse 71645.3359375 imputation mse 0.9949082732200623\n",
      "Train Epoch 188.8 var loss 71669.6015625 reconstruction mse 71666.078125 imputation mse 0.9951963424682617\n",
      "Train Epoch 188.9 var loss 71648.2265625 reconstruction mse 71644.671875 imputation mse 0.9948990941047668\n",
      "Train Epoch 189.0 var loss 72443.546875 reconstruction mse 72436.3984375 imputation mse 1.0113425254821777\n",
      "Train Epoch 189.1 var loss 72385.375 reconstruction mse 72381.6875 imputation mse 1.0105786323547363\n",
      "Train Epoch 189.2 var loss 72405.125 reconstruction mse 72401.390625 imputation mse 1.0108537673950195\n",
      "Train Epoch 189.3 var loss 72381.7109375 reconstruction mse 72378.0 imputation mse 1.01052725315094\n",
      "Train Epoch 189.4 var loss 72373.9609375 reconstruction mse 72370.328125 imputation mse 1.0104200839996338\n",
      "Train Epoch 189.5 var loss 72375.4609375 reconstruction mse 72371.9140625 imputation mse 1.0104422569274902\n",
      "Train Epoch 189.6 var loss 72376.0234375 reconstruction mse 72372.546875 imputation mse 1.010451078414917\n",
      "Train Epoch 189.7 var loss 72419.9375 reconstruction mse 72416.484375 imputation mse 1.0110645294189453\n",
      "Train Epoch 189.8 var loss 72395.421875 reconstruction mse 72391.953125 imputation mse 1.010722041130066\n",
      "Train Epoch 189.9 var loss 72368.0703125 reconstruction mse 72364.578125 imputation mse 1.0103398561477661\n",
      "Train Epoch 190.0 var loss 71407.203125 reconstruction mse 71400.1796875 imputation mse 0.9957906007766724\n",
      "Train Epoch 190.1 var loss 71404.2890625 reconstruction mse 71400.5859375 imputation mse 0.9957963228225708\n",
      "Train Epoch 190.2 var loss 71436.359375 reconstruction mse 71432.53125 imputation mse 0.9962418079376221\n",
      "Train Epoch 190.3 var loss 71398.3828125 reconstruction mse 71394.5390625 imputation mse 0.9957119822502136\n",
      "Train Epoch 190.4 var loss 71426.71875 reconstruction mse 71422.9296875 imputation mse 0.9961079359054565\n",
      "Train Epoch 190.5 var loss 71416.9765625 reconstruction mse 71413.28125 imputation mse 0.9959733486175537\n",
      "Train Epoch 190.6 var loss 71397.1875 reconstruction mse 71393.6484375 imputation mse 0.9956995248794556\n",
      "Train Epoch 190.7 var loss 71378.09375 reconstruction mse 71374.6796875 imputation mse 0.9954349994659424\n",
      "Train Epoch 190.8 var loss 71428.2265625 reconstruction mse 71424.8515625 imputation mse 0.9961346983909607\n",
      "Train Epoch 190.9 var loss 71401.6484375 reconstruction mse 71398.296875 imputation mse 0.9957643747329712\n",
      "====> Test imputation mse: 0.98540843\n",
      "====> Test imputation mse: 1.00291193\n",
      "====> Test imputation mse: 0.99981409\n",
      "Train Epoch 191.0 var loss 71250.3125 reconstruction mse 71243.4296875 imputation mse 0.9987443089485168\n",
      "Train Epoch 191.1 var loss 71191.9609375 reconstruction mse 71188.421875 imputation mse 0.9979732036590576\n",
      "Train Epoch 191.2 var loss 71217.328125 reconstruction mse 71213.6953125 imputation mse 0.9983274936676025\n",
      "Train Epoch 191.3 var loss 71208.015625 reconstruction mse 71204.390625 imputation mse 0.998197078704834\n",
      "Train Epoch 191.4 var loss 71196.359375 reconstruction mse 71192.765625 imputation mse 0.9980340600013733\n",
      "Train Epoch 191.5 var loss 71217.0 reconstruction mse 71213.484375 imputation mse 0.9983245134353638\n",
      "Train Epoch 191.6 var loss 71238.65625 reconstruction mse 71235.234375 imputation mse 0.9986294507980347\n",
      "Train Epoch 191.7 var loss 71224.8828125 reconstruction mse 71221.4921875 imputation mse 0.9984368085861206\n",
      "Train Epoch 191.8 var loss 71225.4765625 reconstruction mse 71222.109375 imputation mse 0.998445451259613\n",
      "Train Epoch 191.9 var loss 71227.3984375 reconstruction mse 71224.015625 imputation mse 0.9984721541404724\n",
      "Train Epoch 192.0 var loss 71675.4296875 reconstruction mse 71668.625 imputation mse 1.0044516324996948\n",
      "Train Epoch 192.1 var loss 71645.6015625 reconstruction mse 71642.0234375 imputation mse 1.00407874584198\n",
      "Train Epoch 192.2 var loss 71662.6484375 reconstruction mse 71658.984375 imputation mse 1.0043164491653442\n",
      "Train Epoch 192.3 var loss 71709.921875 reconstruction mse 71706.25 imputation mse 1.004978895187378\n",
      "Train Epoch 192.4 var loss 71694.5390625 reconstruction mse 71690.921875 imputation mse 1.0047640800476074\n",
      "Train Epoch 192.5 var loss 71677.5859375 reconstruction mse 71674.03125 imputation mse 1.0045273303985596\n",
      "Train Epoch 192.6 var loss 71642.203125 reconstruction mse 71638.75 imputation mse 1.004032850265503\n",
      "Train Epoch 192.7 var loss 71682.671875 reconstruction mse 71679.2734375 imputation mse 1.0046008825302124\n",
      "Train Epoch 192.8 var loss 71670.5390625 reconstruction mse 71667.203125 imputation mse 1.0044316053390503\n",
      "Train Epoch 192.9 var loss 71684.1796875 reconstruction mse 71680.84375 imputation mse 1.0046228170394897\n",
      "Train Epoch 193.0 var loss 71100.21875 reconstruction mse 71093.53125 imputation mse 0.9944542050361633\n",
      "Train Epoch 193.1 var loss 71106.359375 reconstruction mse 71102.875 imputation mse 0.9945849180221558\n",
      "Train Epoch 193.2 var loss 71099.96875 reconstruction mse 71096.390625 imputation mse 0.9944941997528076\n",
      "Train Epoch 193.3 var loss 71082.59375 reconstruction mse 71078.9765625 imputation mse 0.9942505955696106\n",
      "Train Epoch 193.4 var loss 71098.2265625 reconstruction mse 71094.6640625 imputation mse 0.9944700598716736\n",
      "Train Epoch 193.5 var loss 71080.015625 reconstruction mse 71076.5390625 imputation mse 0.9942165017127991\n",
      "Train Epoch 193.6 var loss 71124.3671875 reconstruction mse 71120.9453125 imputation mse 0.9948377013206482\n",
      "Train Epoch 193.7 var loss 71044.4921875 reconstruction mse 71041.1484375 imputation mse 0.9937214851379395\n",
      "Train Epoch 193.8 var loss 71066.859375 reconstruction mse 71063.5546875 imputation mse 0.9940348863601685\n",
      "Train Epoch 193.9 var loss 71055.1171875 reconstruction mse 71051.8125 imputation mse 0.9938706755638123\n",
      "Train Epoch 194.0 var loss 72500.6171875 reconstruction mse 72493.984375 imputation mse 1.007672667503357\n",
      "Train Epoch 194.1 var loss 72564.0546875 reconstruction mse 72560.546875 imputation mse 1.0085978507995605\n",
      "Train Epoch 194.2 var loss 72508.6796875 reconstruction mse 72505.0703125 imputation mse 1.0078266859054565\n",
      "Train Epoch 194.3 var loss 72514.890625 reconstruction mse 72511.28125 imputation mse 1.0079131126403809\n",
      "Train Epoch 194.4 var loss 72523.890625 reconstruction mse 72520.3359375 imputation mse 1.008038878440857\n",
      "Train Epoch 194.5 var loss 72508.5859375 reconstruction mse 72505.109375 imputation mse 1.0078272819519043\n",
      "Train Epoch 194.6 var loss 72511.671875 reconstruction mse 72508.265625 imputation mse 1.007871150970459\n",
      "Train Epoch 194.7 var loss 72490.5703125 reconstruction mse 72487.1875 imputation mse 1.0075781345367432\n",
      "Train Epoch 194.8 var loss 72498.9453125 reconstruction mse 72495.5703125 imputation mse 1.0076947212219238\n",
      "Train Epoch 194.9 var loss 72539.7265625 reconstruction mse 72536.3515625 imputation mse 1.0082615613937378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 195.0 var loss 72427.3671875 reconstruction mse 72420.7734375 imputation mse 1.0117459297180176\n",
      "Train Epoch 195.1 var loss 72448.0390625 reconstruction mse 72444.5 imputation mse 1.0120774507522583\n",
      "Train Epoch 195.2 var loss 72479.3515625 reconstruction mse 72475.703125 imputation mse 1.012513279914856\n",
      "Train Epoch 195.3 var loss 72478.2578125 reconstruction mse 72474.59375 imputation mse 1.0124977827072144\n",
      "Train Epoch 195.4 var loss 72455.6953125 reconstruction mse 72452.0546875 imputation mse 1.0121829509735107\n",
      "Train Epoch 195.5 var loss 72445.5 reconstruction mse 72441.9140625 imputation mse 1.0120412111282349\n",
      "Train Epoch 195.6 var loss 72412.0 reconstruction mse 72408.4609375 imputation mse 1.0115739107131958\n",
      "Train Epoch 195.7 var loss 72457.8515625 reconstruction mse 72454.359375 imputation mse 1.0122151374816895\n",
      "Train Epoch 195.8 var loss 72436.078125 reconstruction mse 72432.6484375 imputation mse 1.0119118690490723\n",
      "Train Epoch 195.9 var loss 72460.953125 reconstruction mse 72457.5234375 imputation mse 1.0122593641281128\n",
      "Train Epoch 196.0 var loss 72001.0859375 reconstruction mse 71994.5234375 imputation mse 1.003673791885376\n",
      "Train Epoch 196.1 var loss 71999.375 reconstruction mse 71995.734375 imputation mse 1.0036906003952026\n",
      "Train Epoch 196.2 var loss 71973.46875 reconstruction mse 71969.7421875 imputation mse 1.0033283233642578\n",
      "Train Epoch 196.3 var loss 71982.2265625 reconstruction mse 71978.4921875 imputation mse 1.0034502744674683\n",
      "Train Epoch 196.4 var loss 71984.671875 reconstruction mse 71980.9453125 imputation mse 1.0034844875335693\n",
      "Train Epoch 196.5 var loss 71976.6015625 reconstruction mse 71972.9609375 imputation mse 1.003373146057129\n",
      "Train Epoch 196.6 var loss 72022.390625 reconstruction mse 72018.7890625 imputation mse 1.004012107849121\n",
      "Train Epoch 196.7 var loss 72006.21875 reconstruction mse 72002.6875 imputation mse 1.003787636756897\n",
      "Train Epoch 196.8 var loss 71991.5703125 reconstruction mse 71988.0703125 imputation mse 1.0035837888717651\n",
      "Train Epoch 196.9 var loss 71983.3203125 reconstruction mse 71979.828125 imputation mse 1.0034688711166382\n",
      "Train Epoch 197.0 var loss 71141.1171875 reconstruction mse 71134.59375 imputation mse 0.9966737031936646\n",
      "Train Epoch 197.1 var loss 71154.046875 reconstruction mse 71150.3984375 imputation mse 0.9968951344490051\n",
      "Train Epoch 197.2 var loss 71198.5625 reconstruction mse 71194.8125 imputation mse 0.9975174069404602\n",
      "Train Epoch 197.3 var loss 71185.6015625 reconstruction mse 71181.8359375 imputation mse 0.9973356127738953\n",
      "Train Epoch 197.4 var loss 71161.203125 reconstruction mse 71157.484375 imputation mse 0.9969943761825562\n",
      "Train Epoch 197.5 var loss 71149.5234375 reconstruction mse 71145.875 imputation mse 0.9968317151069641\n",
      "Train Epoch 197.6 var loss 71189.3125 reconstruction mse 71185.75 imputation mse 0.9973904490470886\n",
      "Train Epoch 197.7 var loss 71133.9296875 reconstruction mse 71130.453125 imputation mse 0.9966156482696533\n",
      "Train Epoch 197.8 var loss 71155.6015625 reconstruction mse 71152.1640625 imputation mse 0.9969198703765869\n",
      "Train Epoch 197.9 var loss 71149.0625 reconstruction mse 71145.6171875 imputation mse 0.9968281388282776\n",
      "Train Epoch 198.0 var loss 72273.2265625 reconstruction mse 72266.734375 imputation mse 1.0016456842422485\n",
      "Train Epoch 198.1 var loss 72238.0 reconstruction mse 72234.34375 imputation mse 1.0011967420578003\n",
      "Train Epoch 198.2 var loss 72259.8828125 reconstruction mse 72256.078125 imputation mse 1.0014979839324951\n",
      "Train Epoch 198.3 var loss 72205.578125 reconstruction mse 72201.8046875 imputation mse 1.0007457733154297\n",
      "Train Epoch 198.4 var loss 72278.3125 reconstruction mse 72274.5859375 imputation mse 1.0017545223236084\n",
      "Train Epoch 198.5 var loss 72228.1640625 reconstruction mse 72224.5703125 imputation mse 1.0010613203048706\n",
      "Train Epoch 198.6 var loss 72246.234375 reconstruction mse 72242.7265625 imputation mse 1.0013129711151123\n",
      "Train Epoch 198.7 var loss 72205.75 reconstruction mse 72202.328125 imputation mse 1.0007530450820923\n",
      "Train Epoch 198.8 var loss 72170.203125 reconstruction mse 72166.828125 imputation mse 1.0002609491348267\n",
      "Train Epoch 198.9 var loss 72212.6328125 reconstruction mse 72209.2265625 imputation mse 1.000848650932312\n",
      "Train Epoch 199.0 var loss 71068.5859375 reconstruction mse 71062.171875 imputation mse 0.9998476505279541\n",
      "Train Epoch 199.1 var loss 71037.578125 reconstruction mse 71033.9453125 imputation mse 0.9994505047798157\n",
      "Train Epoch 199.2 var loss 71024.9375 reconstruction mse 71021.203125 imputation mse 0.9992712140083313\n",
      "Train Epoch 199.3 var loss 71008.4140625 reconstruction mse 71004.6640625 imputation mse 0.9990385174751282\n",
      "Train Epoch 199.4 var loss 71025.828125 reconstruction mse 71022.15625 imputation mse 0.9992846250534058\n",
      "Train Epoch 199.5 var loss 71021.1796875 reconstruction mse 71017.625 imputation mse 0.9992208480834961\n",
      "Train Epoch 199.6 var loss 71001.75 reconstruction mse 70998.2890625 imputation mse 0.9989488124847412\n",
      "Train Epoch 199.7 var loss 70988.640625 reconstruction mse 70985.234375 imputation mse 0.9987651109695435\n",
      "Train Epoch 199.8 var loss 71055.9296875 reconstruction mse 71052.5546875 imputation mse 0.999712347984314\n",
      "Train Epoch 199.9 var loss 70999.8046875 reconstruction mse 70996.3984375 imputation mse 0.9989222288131714\n",
      "Train Epoch 200.0 var loss 71970.2578125 reconstruction mse 71963.921875 imputation mse 1.004101037979126\n",
      "Train Epoch 200.1 var loss 71932.4375 reconstruction mse 71928.84375 imputation mse 1.0036115646362305\n",
      "Train Epoch 200.2 var loss 71918.515625 reconstruction mse 71914.84375 imputation mse 1.0034162998199463\n",
      "Train Epoch 200.3 var loss 71994.375 reconstruction mse 71990.7109375 imputation mse 1.0044748783111572\n",
      "Train Epoch 200.4 var loss 71934.4453125 reconstruction mse 71930.859375 imputation mse 1.0036396980285645\n",
      "Train Epoch 200.5 var loss 71946.359375 reconstruction mse 71942.890625 imputation mse 1.003807544708252\n",
      "Train Epoch 200.6 var loss 71897.0625 reconstruction mse 71893.6796875 imputation mse 1.003121018409729\n",
      "Train Epoch 200.7 var loss 71954.2578125 reconstruction mse 71950.9453125 imputation mse 1.0039199590682983\n",
      "Train Epoch 200.8 var loss 71924.6953125 reconstruction mse 71921.40625 imputation mse 1.0035078525543213\n",
      "Train Epoch 200.9 var loss 71966.78125 reconstruction mse 71963.4609375 imputation mse 1.0040946006774902\n",
      "====> Test imputation mse: 0.98137802\n",
      "====> Test imputation mse: 0.99669039\n",
      "====> Test imputation mse: 0.99827796\n",
      "Train Epoch 201.0 var loss 71944.0234375 reconstruction mse 71937.7890625 imputation mse 1.0007761716842651\n",
      "Train Epoch 201.1 var loss 71971.1484375 reconstruction mse 71967.5859375 imputation mse 1.0011906623840332\n",
      "Train Epoch 201.2 var loss 71942.375 reconstruction mse 71938.6875 imputation mse 1.0007885694503784\n",
      "Train Epoch 201.3 var loss 71926.796875 reconstruction mse 71923.0703125 imputation mse 1.000571370124817\n",
      "Train Epoch 201.4 var loss 71934.234375 reconstruction mse 71930.5703125 imputation mse 1.0006756782531738\n",
      "Train Epoch 201.5 var loss 71904.140625 reconstruction mse 71900.546875 imputation mse 1.000257968902588\n",
      "Train Epoch 201.6 var loss 71976.125 reconstruction mse 71972.6328125 imputation mse 1.0012608766555786\n",
      "Train Epoch 201.7 var loss 71910.078125 reconstruction mse 71906.6640625 imputation mse 1.0003430843353271\n",
      "Train Epoch 201.8 var loss 71939.8671875 reconstruction mse 71936.484375 imputation mse 1.0007579326629639\n",
      "Train Epoch 201.9 var loss 71916.28125 reconstruction mse 71912.90625 imputation mse 1.0004299879074097\n",
      "Train Epoch 202.0 var loss 72234.9765625 reconstruction mse 72228.7578125 imputation mse 1.0076556205749512\n",
      "Train Epoch 202.1 var loss 72251.4609375 reconstruction mse 72247.875 imputation mse 1.0079224109649658\n",
      "Train Epoch 202.2 var loss 72240.859375 reconstruction mse 72237.140625 imputation mse 1.0077725648880005\n",
      "Train Epoch 202.3 var loss 72230.4375 reconstruction mse 72226.6640625 imputation mse 1.0076264142990112\n",
      "Train Epoch 202.4 var loss 72276.6171875 reconstruction mse 72272.890625 imputation mse 1.008271336555481\n",
      "Train Epoch 202.5 var loss 72258.3359375 reconstruction mse 72254.671875 imputation mse 1.0080171823501587\n",
      "Train Epoch 202.6 var loss 72283.671875 reconstruction mse 72280.09375 imputation mse 1.0083718299865723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 202.7 var loss 72232.6796875 reconstruction mse 72229.1875 imputation mse 1.0076617002487183\n",
      "Train Epoch 202.8 var loss 72208.640625 reconstruction mse 72205.1796875 imputation mse 1.0073267221450806\n",
      "Train Epoch 202.9 var loss 72224.40625 reconstruction mse 72220.9453125 imputation mse 1.0075466632843018\n",
      "Train Epoch 203.0 var loss 71211.625 reconstruction mse 71205.4375 imputation mse 0.9965492486953735\n",
      "Train Epoch 203.1 var loss 71243.640625 reconstruction mse 71240.0 imputation mse 0.9970329999923706\n",
      "Train Epoch 203.2 var loss 71184.75 reconstruction mse 71181.0390625 imputation mse 0.9962077736854553\n",
      "Train Epoch 203.3 var loss 71211.84375 reconstruction mse 71208.1171875 imputation mse 0.9965867400169373\n",
      "Train Epoch 203.4 var loss 71193.1171875 reconstruction mse 71189.4375 imputation mse 0.9963253140449524\n",
      "Train Epoch 203.5 var loss 71205.796875 reconstruction mse 71202.2265625 imputation mse 0.9965043067932129\n",
      "Train Epoch 203.6 var loss 71196.953125 reconstruction mse 71193.5234375 imputation mse 0.9963825345039368\n",
      "Train Epoch 203.7 var loss 71176.640625 reconstruction mse 71173.3125 imputation mse 0.9960996508598328\n",
      "Train Epoch 203.8 var loss 71191.6484375 reconstruction mse 71188.3828125 imputation mse 0.9963105916976929\n",
      "Train Epoch 203.9 var loss 71227.109375 reconstruction mse 71223.8671875 imputation mse 0.9968072175979614\n",
      "Train Epoch 204.0 var loss 71717.0546875 reconstruction mse 71711.0546875 imputation mse 1.0027555227279663\n",
      "Train Epoch 204.1 var loss 71729.40625 reconstruction mse 71725.9921875 imputation mse 1.0029643774032593\n",
      "Train Epoch 204.2 var loss 71736.3046875 reconstruction mse 71732.78125 imputation mse 1.0030592679977417\n",
      "Train Epoch 204.3 var loss 71720.375 reconstruction mse 71716.7890625 imputation mse 1.0028356313705444\n",
      "Train Epoch 204.4 var loss 71681.4765625 reconstruction mse 71677.8984375 imputation mse 1.0022917985916138\n",
      "Train Epoch 204.5 var loss 71688.8515625 reconstruction mse 71685.3203125 imputation mse 1.0023956298828125\n",
      "Train Epoch 204.6 var loss 71751.53125 reconstruction mse 71748.0625 imputation mse 1.0032730102539062\n",
      "Train Epoch 204.7 var loss 71722.453125 reconstruction mse 71719.046875 imputation mse 1.0028672218322754\n",
      "Train Epoch 204.8 var loss 71745.6796875 reconstruction mse 71742.34375 imputation mse 1.0031930208206177\n",
      "Train Epoch 204.9 var loss 71736.4453125 reconstruction mse 71733.140625 imputation mse 1.0030642747879028\n",
      "Train Epoch 205.0 var loss 71871.6484375 reconstruction mse 71865.75 imputation mse 1.0050450563430786\n",
      "Train Epoch 205.1 var loss 71802.3515625 reconstruction mse 71798.921875 imputation mse 1.0041104555130005\n",
      "Train Epoch 205.2 var loss 71797.90625 reconstruction mse 71794.3828125 imputation mse 1.0040470361709595\n",
      "Train Epoch 205.3 var loss 71818.4921875 reconstruction mse 71814.9140625 imputation mse 1.0043342113494873\n",
      "Train Epoch 205.4 var loss 71791.7109375 reconstruction mse 71788.171875 imputation mse 1.003960132598877\n",
      "Train Epoch 205.5 var loss 71831.0859375 reconstruction mse 71827.609375 imputation mse 1.0045117139816284\n",
      "Train Epoch 205.6 var loss 71812.6015625 reconstruction mse 71809.1953125 imputation mse 1.0042542219161987\n",
      "Train Epoch 205.7 var loss 71778.5546875 reconstruction mse 71775.2265625 imputation mse 1.0037791728973389\n",
      "Train Epoch 205.8 var loss 71816.625 reconstruction mse 71813.3359375 imputation mse 1.0043120384216309\n",
      "Train Epoch 205.9 var loss 71836.3984375 reconstruction mse 71833.1171875 imputation mse 1.0045887231826782\n",
      "Train Epoch 206.0 var loss 71382.1875 reconstruction mse 71376.2890625 imputation mse 1.0046064853668213\n",
      "Train Epoch 206.1 var loss 71360.125 reconstruction mse 71356.6484375 imputation mse 1.004330039024353\n",
      "Train Epoch 206.2 var loss 71361.5390625 reconstruction mse 71357.984375 imputation mse 1.004348874092102\n",
      "Train Epoch 206.3 var loss 71336.265625 reconstruction mse 71332.6953125 imputation mse 1.0039929151535034\n",
      "Train Epoch 206.4 var loss 71344.9921875 reconstruction mse 71341.4765625 imputation mse 1.0041165351867676\n",
      "Train Epoch 206.5 var loss 71347.5859375 reconstruction mse 71344.171875 imputation mse 1.0041544437408447\n",
      "Train Epoch 206.6 var loss 71344.5546875 reconstruction mse 71341.2109375 imputation mse 1.0041128396987915\n",
      "Train Epoch 206.7 var loss 71349.6484375 reconstruction mse 71346.359375 imputation mse 1.0041853189468384\n",
      "Train Epoch 206.8 var loss 71342.046875 reconstruction mse 71338.7578125 imputation mse 1.0040782690048218\n",
      "Train Epoch 206.9 var loss 71352.15625 reconstruction mse 71348.8125 imputation mse 1.0042197704315186\n",
      "Train Epoch 207.0 var loss 71803.9375 reconstruction mse 71798.109375 imputation mse 1.0070991516113281\n",
      "Train Epoch 207.1 var loss 71787.3046875 reconstruction mse 71783.734375 imputation mse 1.0068974494934082\n",
      "Train Epoch 207.2 var loss 71801.7890625 reconstruction mse 71798.1171875 imputation mse 1.0070992708206177\n",
      "Train Epoch 207.3 var loss 71799.7109375 reconstruction mse 71796.0546875 imputation mse 1.0070703029632568\n",
      "Train Epoch 207.4 var loss 71793.3984375 reconstruction mse 71789.8203125 imputation mse 1.0069828033447266\n",
      "Train Epoch 207.5 var loss 71781.515625 reconstruction mse 71778.0546875 imputation mse 1.0068178176879883\n",
      "Train Epoch 207.6 var loss 71775.15625 reconstruction mse 71771.7890625 imputation mse 1.0067299604415894\n",
      "Train Epoch 207.7 var loss 71807.3671875 reconstruction mse 71804.0625 imputation mse 1.0071825981140137\n",
      "Train Epoch 207.8 var loss 71777.8359375 reconstruction mse 71774.5234375 imputation mse 1.0067682266235352\n",
      "Train Epoch 207.9 var loss 71787.921875 reconstruction mse 71784.6171875 imputation mse 1.0069098472595215\n",
      "Train Epoch 208.0 var loss 72020.15625 reconstruction mse 72014.34375 imputation mse 1.0033626556396484\n",
      "Train Epoch 208.1 var loss 72021.296875 reconstruction mse 72017.7265625 imputation mse 1.003409743309021\n",
      "Train Epoch 208.2 var loss 71985.46875 reconstruction mse 71981.78125 imputation mse 1.0029089450836182\n",
      "Train Epoch 208.3 var loss 72014.8984375 reconstruction mse 72011.1328125 imputation mse 1.0033178329467773\n",
      "Train Epoch 208.4 var loss 71994.8515625 reconstruction mse 71991.140625 imputation mse 1.0030393600463867\n",
      "Train Epoch 208.5 var loss 72025.328125 reconstruction mse 72021.7109375 imputation mse 1.0034652948379517\n",
      "Train Epoch 208.6 var loss 72023.515625 reconstruction mse 72020.0390625 imputation mse 1.0034419298171997\n",
      "Train Epoch 208.7 var loss 72037.8828125 reconstruction mse 72034.484375 imputation mse 1.0036431550979614\n",
      "Train Epoch 208.8 var loss 72011.1796875 reconstruction mse 72007.8515625 imputation mse 1.0032721757888794\n",
      "Train Epoch 208.9 var loss 72059.921875 reconstruction mse 72056.640625 imputation mse 1.003951907157898\n",
      "Train Epoch 209.0 var loss 72093.609375 reconstruction mse 72087.9296875 imputation mse 1.009521722793579\n",
      "Train Epoch 209.1 var loss 72129.6484375 reconstruction mse 72126.25 imputation mse 1.0100584030151367\n",
      "Train Epoch 209.2 var loss 72089.90625 reconstruction mse 72086.4140625 imputation mse 1.009500503540039\n",
      "Train Epoch 209.3 var loss 72081.3984375 reconstruction mse 72077.8984375 imputation mse 1.0093812942504883\n",
      "Train Epoch 209.4 var loss 72073.421875 reconstruction mse 72069.96875 imputation mse 1.009270191192627\n",
      "Train Epoch 209.5 var loss 72079.8359375 reconstruction mse 72076.4453125 imputation mse 1.009360909461975\n",
      "Train Epoch 209.6 var loss 72067.375 reconstruction mse 72064.046875 imputation mse 1.0091873407363892\n",
      "Train Epoch 209.7 var loss 72104.6015625 reconstruction mse 72101.3046875 imputation mse 1.009709119796753\n",
      "Train Epoch 209.8 var loss 72098.5703125 reconstruction mse 72095.2734375 imputation mse 1.0096246004104614\n",
      "Train Epoch 209.9 var loss 72087.703125 reconstruction mse 72084.375 imputation mse 1.0094720125198364\n",
      "Train Epoch 210.0 var loss 71366.203125 reconstruction mse 71360.4921875 imputation mse 0.9991388320922852\n",
      "Train Epoch 210.1 var loss 71396.46875 reconstruction mse 71392.8828125 imputation mse 0.9995923042297363\n",
      "Train Epoch 210.2 var loss 71393.953125 reconstruction mse 71390.265625 imputation mse 0.9995557069778442\n",
      "Train Epoch 210.3 var loss 71379.09375 reconstruction mse 71375.3671875 imputation mse 0.9993470907211304\n",
      "Train Epoch 210.4 var loss 71421.0859375 reconstruction mse 71417.421875 imputation mse 0.9999359250068665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 210.5 var loss 71391.390625 reconstruction mse 71387.859375 imputation mse 0.9995219707489014\n",
      "Train Epoch 210.6 var loss 71370.84375 reconstruction mse 71367.4375 imputation mse 0.9992360472679138\n",
      "Train Epoch 210.7 var loss 71393.6484375 reconstruction mse 71390.3125 imputation mse 0.9995563626289368\n",
      "Train Epoch 210.8 var loss 71401.09375 reconstruction mse 71397.8046875 imputation mse 0.9996612071990967\n",
      "Train Epoch 210.9 var loss 71380.25 reconstruction mse 71376.9765625 imputation mse 0.9993696212768555\n",
      "====> Test imputation mse: 1.01130402\n",
      "====> Test imputation mse: 1.02796316\n",
      "====> Test imputation mse: 1.01840889\n",
      "Train Epoch 211.0 var loss 71612.46875 reconstruction mse 71606.8515625 imputation mse 1.0027426481246948\n",
      "Train Epoch 211.1 var loss 71607.03125 reconstruction mse 71603.59375 imputation mse 1.0026969909667969\n",
      "Train Epoch 211.2 var loss 71620.296875 reconstruction mse 71616.7734375 imputation mse 1.0028815269470215\n",
      "Train Epoch 211.3 var loss 71590.625 reconstruction mse 71587.0859375 imputation mse 1.002465844154358\n",
      "Train Epoch 211.4 var loss 71586.8984375 reconstruction mse 71583.3984375 imputation mse 1.0024142265319824\n",
      "Train Epoch 211.5 var loss 71601.0234375 reconstruction mse 71597.5703125 imputation mse 1.002612590789795\n",
      "Train Epoch 211.6 var loss 71607.703125 reconstruction mse 71604.3359375 imputation mse 1.0027073621749878\n",
      "Train Epoch 211.7 var loss 71648.7734375 reconstruction mse 71645.46875 imputation mse 1.0032833814620972\n",
      "Train Epoch 211.8 var loss 71617.5859375 reconstruction mse 71614.3515625 imputation mse 1.002847671508789\n",
      "Train Epoch 211.9 var loss 71644.0703125 reconstruction mse 71640.8359375 imputation mse 1.0032185316085815\n",
      "Train Epoch 212.0 var loss 71797.828125 reconstruction mse 71792.2421875 imputation mse 1.001761555671692\n",
      "Train Epoch 212.1 var loss 71775.1796875 reconstruction mse 71771.7578125 imputation mse 1.0014756917953491\n",
      "Train Epoch 212.2 var loss 71742.703125 reconstruction mse 71739.1796875 imputation mse 1.001021146774292\n",
      "Train Epoch 212.3 var loss 71771.28125 reconstruction mse 71767.7109375 imputation mse 1.001419186592102\n",
      "Train Epoch 212.4 var loss 71737.171875 reconstruction mse 71733.6796875 imputation mse 1.0009443759918213\n",
      "Train Epoch 212.5 var loss 71778.1328125 reconstruction mse 71774.7265625 imputation mse 1.0015171766281128\n",
      "Train Epoch 212.6 var loss 71783.8203125 reconstruction mse 71780.46875 imputation mse 1.001597285270691\n",
      "Train Epoch 212.7 var loss 71759.5703125 reconstruction mse 71756.2578125 imputation mse 1.001259446144104\n",
      "Train Epoch 212.8 var loss 71750.5390625 reconstruction mse 71747.265625 imputation mse 1.001133918762207\n",
      "Train Epoch 212.9 var loss 71725.3828125 reconstruction mse 71722.1328125 imputation mse 1.0007832050323486\n",
      "Train Epoch 213.0 var loss 72198.1640625 reconstruction mse 72192.6484375 imputation mse 1.0038747787475586\n",
      "Train Epoch 213.1 var loss 72179.625 reconstruction mse 72176.1796875 imputation mse 1.0036457777023315\n",
      "Train Epoch 213.2 var loss 72178.015625 reconstruction mse 72174.4609375 imputation mse 1.0036218166351318\n",
      "Train Epoch 213.3 var loss 72170.875 reconstruction mse 72167.3203125 imputation mse 1.003522515296936\n",
      "Train Epoch 213.4 var loss 72169.75 reconstruction mse 72166.2265625 imputation mse 1.003507375717163\n",
      "Train Epoch 213.5 var loss 72162.5390625 reconstruction mse 72159.109375 imputation mse 1.0034083127975464\n",
      "Train Epoch 213.6 var loss 72148.7734375 reconstruction mse 72145.453125 imputation mse 1.003218412399292\n",
      "Train Epoch 213.7 var loss 72191.2890625 reconstruction mse 72188.0234375 imputation mse 1.0038104057312012\n",
      "Train Epoch 213.8 var loss 72164.0859375 reconstruction mse 72160.8828125 imputation mse 1.0034329891204834\n",
      "Train Epoch 213.9 var loss 72177.09375 reconstruction mse 72173.90625 imputation mse 1.003614068031311\n",
      "Train Epoch 214.0 var loss 71200.875 reconstruction mse 71195.4453125 imputation mse 0.9998377561569214\n",
      "Train Epoch 214.1 var loss 71205.1953125 reconstruction mse 71201.8515625 imputation mse 0.9999276995658875\n",
      "Train Epoch 214.2 var loss 71209.5546875 reconstruction mse 71206.125 imputation mse 0.9999877214431763\n",
      "Train Epoch 214.3 var loss 71202.71875 reconstruction mse 71199.2734375 imputation mse 0.9998915195465088\n",
      "Train Epoch 214.4 var loss 71204.375 reconstruction mse 71200.9453125 imputation mse 0.9999149441719055\n",
      "Train Epoch 214.5 var loss 71196.5390625 reconstruction mse 71193.1640625 imputation mse 0.9998056888580322\n",
      "Train Epoch 214.6 var loss 71198.6015625 reconstruction mse 71195.2890625 imputation mse 0.9998355507850647\n",
      "Train Epoch 214.7 var loss 71197.96875 reconstruction mse 71194.6875 imputation mse 0.9998270869255066\n",
      "Train Epoch 214.8 var loss 71233.359375 reconstruction mse 71230.09375 imputation mse 1.0003243684768677\n",
      "Train Epoch 214.9 var loss 71215.921875 reconstruction mse 71212.640625 imputation mse 1.0000791549682617\n",
      "Train Epoch 215.0 var loss 71431.7421875 reconstruction mse 71426.2578125 imputation mse 1.0011810064315796\n",
      "Train Epoch 215.1 var loss 71386.5234375 reconstruction mse 71383.0625 imputation mse 1.0005755424499512\n",
      "Train Epoch 215.2 var loss 71399.03125 reconstruction mse 71395.4765625 imputation mse 1.0007495880126953\n",
      "Train Epoch 215.3 var loss 71397.8046875 reconstruction mse 71394.2265625 imputation mse 1.0007320642471313\n",
      "Train Epoch 215.4 var loss 71397.234375 reconstruction mse 71393.671875 imputation mse 1.0007243156433105\n",
      "Train Epoch 215.5 var loss 71423.625 reconstruction mse 71420.1484375 imputation mse 1.0010954141616821\n",
      "Train Epoch 215.6 var loss 71449.6015625 reconstruction mse 71446.2578125 imputation mse 1.001461386680603\n",
      "Train Epoch 215.7 var loss 71406.7734375 reconstruction mse 71403.5078125 imputation mse 1.0008621215820312\n",
      "Train Epoch 215.8 var loss 71397.75 reconstruction mse 71394.5078125 imputation mse 1.0007359981536865\n",
      "Train Epoch 215.9 var loss 71358.6953125 reconstruction mse 71355.4453125 imputation mse 1.0001884698867798\n",
      "Train Epoch 216.0 var loss 71502.4921875 reconstruction mse 71497.0703125 imputation mse 1.0010510683059692\n",
      "Train Epoch 216.1 var loss 71535.1171875 reconstruction mse 71531.6171875 imputation mse 1.0015348196029663\n",
      "Train Epoch 216.2 var loss 71526.8203125 reconstruction mse 71523.1953125 imputation mse 1.0014169216156006\n",
      "Train Epoch 216.3 var loss 71552.46875 reconstruction mse 71548.796875 imputation mse 1.0017752647399902\n",
      "Train Epoch 216.4 var loss 71541.7109375 reconstruction mse 71538.0859375 imputation mse 1.0016252994537354\n",
      "Train Epoch 216.5 var loss 71522.375 reconstruction mse 71518.875 imputation mse 1.0013563632965088\n",
      "Train Epoch 216.6 var loss 71559.578125 reconstruction mse 71556.15625 imputation mse 1.0018783807754517\n",
      "Train Epoch 216.7 var loss 71524.6328125 reconstruction mse 71521.296875 imputation mse 1.0013903379440308\n",
      "Train Epoch 216.8 var loss 71521.1015625 reconstruction mse 71517.796875 imputation mse 1.0013412237167358\n",
      "Train Epoch 216.9 var loss 71514.53125 reconstruction mse 71511.1953125 imputation mse 1.001248836517334\n",
      "Train Epoch 217.0 var loss 71672.265625 reconstruction mse 71666.828125 imputation mse 1.005666732788086\n",
      "Train Epoch 217.1 var loss 71645.4921875 reconstruction mse 71641.90625 imputation mse 1.005316972732544\n",
      "Train Epoch 217.2 var loss 71674.625 reconstruction mse 71670.9609375 imputation mse 1.0057246685028076\n",
      "Train Epoch 217.3 var loss 71684.015625 reconstruction mse 71680.3203125 imputation mse 1.0058560371398926\n",
      "Train Epoch 217.4 var loss 71670.7890625 reconstruction mse 71667.203125 imputation mse 1.0056719779968262\n",
      "Train Epoch 217.5 var loss 71681.15625 reconstruction mse 71677.6875 imputation mse 1.0058190822601318\n",
      "Train Epoch 217.6 var loss 71665.5 reconstruction mse 71662.1640625 imputation mse 1.0056012868881226\n",
      "Train Epoch 217.7 var loss 71690.125 reconstruction mse 71686.8671875 imputation mse 1.0059479475021362\n",
      "Train Epoch 217.8 var loss 71672.3828125 reconstruction mse 71669.1875 imputation mse 1.005699872970581\n",
      "Train Epoch 217.9 var loss 71687.1015625 reconstruction mse 71683.875 imputation mse 1.0059059858322144\n",
      "Train Epoch 218.0 var loss 71202.5546875 reconstruction mse 71197.2734375 imputation mse 0.9999757409095764\n",
      "Train Epoch 218.1 var loss 71227.4765625 reconstruction mse 71223.9453125 imputation mse 1.0003503561019897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 218.2 var loss 71244.859375 reconstruction mse 71241.203125 imputation mse 1.0005927085876465\n",
      "Train Epoch 218.3 var loss 71244.6328125 reconstruction mse 71240.953125 imputation mse 1.0005892515182495\n",
      "Train Epoch 218.4 var loss 71236.8671875 reconstruction mse 71233.265625 imputation mse 1.0004812479019165\n",
      "Train Epoch 218.5 var loss 71210.3203125 reconstruction mse 71206.8515625 imputation mse 1.0001102685928345\n",
      "Train Epoch 218.6 var loss 71197.453125 reconstruction mse 71194.1328125 imputation mse 0.9999316334724426\n",
      "Train Epoch 218.7 var loss 71183.421875 reconstruction mse 71180.1328125 imputation mse 0.9997349977493286\n",
      "Train Epoch 218.8 var loss 71207.375 reconstruction mse 71204.1171875 imputation mse 1.0000718832015991\n",
      "Train Epoch 218.9 var loss 71216.1328125 reconstruction mse 71212.8671875 imputation mse 1.000194787979126\n",
      "Train Epoch 219.0 var loss 72119.6640625 reconstruction mse 72114.40625 imputation mse 1.0075221061706543\n",
      "Train Epoch 219.1 var loss 72093.3671875 reconstruction mse 72089.9140625 imputation mse 1.0071799755096436\n",
      "Train Epoch 219.2 var loss 72053.765625 reconstruction mse 72050.2265625 imputation mse 1.0066255331039429\n",
      "Train Epoch 219.3 var loss 72099.5625 reconstruction mse 72096.0 imputation mse 1.0072649717330933\n",
      "Train Epoch 219.4 var loss 72111.328125 reconstruction mse 72107.84375 imputation mse 1.0074304342269897\n",
      "Train Epoch 219.5 var loss 72107.8125 reconstruction mse 72104.40625 imputation mse 1.0073823928833008\n",
      "Train Epoch 219.6 var loss 72067.0625 reconstruction mse 72063.71875 imputation mse 1.0068140029907227\n",
      "Train Epoch 219.7 var loss 72083.84375 reconstruction mse 72080.5703125 imputation mse 1.0070494413375854\n",
      "Train Epoch 219.8 var loss 72109.75 reconstruction mse 72106.4921875 imputation mse 1.0074115991592407\n",
      "Train Epoch 219.9 var loss 72086.21875 reconstruction mse 72082.96875 imputation mse 1.0070829391479492\n",
      "Train Epoch 220.0 var loss 71670.203125 reconstruction mse 71665.0 imputation mse 0.9963435530662537\n",
      "Train Epoch 220.1 var loss 71650.2109375 reconstruction mse 71646.7578125 imputation mse 0.9960899353027344\n",
      "Train Epoch 220.2 var loss 71668.375 reconstruction mse 71664.796875 imputation mse 0.9963407516479492\n",
      "Train Epoch 220.3 var loss 71671.28125 reconstruction mse 71667.71875 imputation mse 0.9963813424110413\n",
      "Train Epoch 220.4 var loss 71702.6640625 reconstruction mse 71699.1640625 imputation mse 0.9968185424804688\n",
      "Train Epoch 220.5 var loss 71690.2109375 reconstruction mse 71686.8046875 imputation mse 0.9966467022895813\n",
      "Train Epoch 220.6 var loss 71646.1953125 reconstruction mse 71642.90625 imputation mse 0.9960364103317261\n",
      "Train Epoch 220.7 var loss 71641.2734375 reconstruction mse 71638.0625 imputation mse 0.9959690570831299\n",
      "Train Epoch 220.8 var loss 71682.5859375 reconstruction mse 71679.40625 imputation mse 0.996543824672699\n",
      "Train Epoch 220.9 var loss 71673.125 reconstruction mse 71669.921875 imputation mse 0.9964119791984558\n",
      "====> Test imputation mse: 1.00729394\n",
      "====> Test imputation mse: 1.00406051\n",
      "====> Test imputation mse: 1.00773895\n",
      "Train Epoch 221.0 var loss 71828.5234375 reconstruction mse 71823.34375 imputation mse 1.0079479217529297\n",
      "Train Epoch 221.1 var loss 71815.0390625 reconstruction mse 71811.65625 imputation mse 1.0077838897705078\n",
      "Train Epoch 221.2 var loss 71855.3515625 reconstruction mse 71851.8828125 imputation mse 1.0083484649658203\n",
      "Train Epoch 221.3 var loss 71840.890625 reconstruction mse 71837.4375 imputation mse 1.0081456899642944\n",
      "Train Epoch 221.4 var loss 71800.265625 reconstruction mse 71796.90625 imputation mse 1.0075769424438477\n",
      "Train Epoch 221.5 var loss 71815.0625 reconstruction mse 71811.84375 imputation mse 1.007786512374878\n",
      "Train Epoch 221.6 var loss 71824.7109375 reconstruction mse 71821.609375 imputation mse 1.0079236030578613\n",
      "Train Epoch 221.7 var loss 71830.4921875 reconstruction mse 71827.421875 imputation mse 1.008005142211914\n",
      "Train Epoch 221.8 var loss 71863.078125 reconstruction mse 71860.0078125 imputation mse 1.0084624290466309\n",
      "Train Epoch 221.9 var loss 71830.5390625 reconstruction mse 71827.3984375 imputation mse 1.0080047845840454\n",
      "Train Epoch 222.0 var loss 72526.3203125 reconstruction mse 72521.234375 imputation mse 1.013829231262207\n",
      "Train Epoch 222.1 var loss 72507.828125 reconstruction mse 72504.421875 imputation mse 1.0135942697525024\n",
      "Train Epoch 222.2 var loss 72484.65625 reconstruction mse 72481.1015625 imputation mse 1.013268232345581\n",
      "Train Epoch 222.3 var loss 72501.453125 reconstruction mse 72497.90625 imputation mse 1.0135031938552856\n",
      "Train Epoch 222.4 var loss 72524.6953125 reconstruction mse 72521.1875 imputation mse 1.0138286352157593\n",
      "Train Epoch 222.5 var loss 72535.4296875 reconstruction mse 72532.015625 imputation mse 1.0139800310134888\n",
      "Train Epoch 222.6 var loss 72497.3671875 reconstruction mse 72494.0390625 imputation mse 1.0134490728378296\n",
      "Train Epoch 222.7 var loss 72522.0 reconstruction mse 72518.7421875 imputation mse 1.0137944221496582\n",
      "Train Epoch 222.8 var loss 72517.34375 reconstruction mse 72514.1015625 imputation mse 1.0137295722961426\n",
      "Train Epoch 222.9 var loss 72508.765625 reconstruction mse 72505.453125 imputation mse 1.013608694076538\n",
      "Train Epoch 223.0 var loss 71537.8359375 reconstruction mse 71532.7109375 imputation mse 0.9987114667892456\n",
      "Train Epoch 223.1 var loss 71577.984375 reconstruction mse 71574.40625 imputation mse 0.9992936253547668\n",
      "Train Epoch 223.2 var loss 71585.328125 reconstruction mse 71581.6328125 imputation mse 0.9993945360183716\n",
      "Train Epoch 223.3 var loss 71582.5625 reconstruction mse 71578.9140625 imputation mse 0.9993565678596497\n",
      "Train Epoch 223.4 var loss 71592.1328125 reconstruction mse 71588.6171875 imputation mse 0.9994920492172241\n",
      "Train Epoch 223.5 var loss 71600.53125 reconstruction mse 71597.171875 imputation mse 0.999611496925354\n",
      "Train Epoch 223.6 var loss 71577.1171875 reconstruction mse 71573.90625 imputation mse 0.9992866516113281\n",
      "Train Epoch 223.7 var loss 71566.8046875 reconstruction mse 71563.640625 imputation mse 0.9991433024406433\n",
      "Train Epoch 223.8 var loss 71578.9921875 reconstruction mse 71575.8046875 imputation mse 0.9993131756782532\n",
      "Train Epoch 223.9 var loss 71563.703125 reconstruction mse 71560.4453125 imputation mse 0.9990987181663513\n",
      "Train Epoch 224.0 var loss 71270.7421875 reconstruction mse 71265.6953125 imputation mse 0.996555745601654\n",
      "Train Epoch 224.1 var loss 71270.65625 reconstruction mse 71267.109375 imputation mse 0.9965755343437195\n",
      "Train Epoch 224.2 var loss 71286.515625 reconstruction mse 71282.8046875 imputation mse 0.9967949986457825\n",
      "Train Epoch 224.3 var loss 71271.8828125 reconstruction mse 71268.2109375 imputation mse 0.9965909123420715\n",
      "Train Epoch 224.4 var loss 71288.453125 reconstruction mse 71284.8671875 imputation mse 0.9968238472938538\n",
      "Train Epoch 224.5 var loss 71322.46875 reconstruction mse 71318.9921875 imputation mse 0.9973010420799255\n",
      "Train Epoch 224.6 var loss 71293.3984375 reconstruction mse 71290.0703125 imputation mse 0.9968966245651245\n",
      "Train Epoch 224.7 var loss 71296.3828125 reconstruction mse 71293.171875 imputation mse 0.9969399571418762\n",
      "Train Epoch 224.8 var loss 71302.84375 reconstruction mse 71299.671875 imputation mse 0.9970308542251587\n",
      "Train Epoch 224.9 var loss 71284.359375 reconstruction mse 71281.203125 imputation mse 0.9967725872993469\n",
      "Train Epoch 225.0 var loss 71741.8828125 reconstruction mse 71736.90625 imputation mse 1.0037766695022583\n",
      "Train Epoch 225.1 var loss 71726.8515625 reconstruction mse 71723.5 imputation mse 1.0035890340805054\n",
      "Train Epoch 225.2 var loss 71747.8203125 reconstruction mse 71744.3671875 imputation mse 1.0038810968399048\n",
      "Train Epoch 225.3 var loss 71713.03125 reconstruction mse 71709.59375 imputation mse 1.0033944845199585\n",
      "Train Epoch 225.4 var loss 71746.515625 reconstruction mse 71743.171875 imputation mse 1.0038642883300781\n",
      "Train Epoch 225.5 var loss 71746.5625 reconstruction mse 71743.3125 imputation mse 1.0038663148880005\n",
      "Train Epoch 225.6 var loss 71721.828125 reconstruction mse 71718.671875 imputation mse 1.0035215616226196\n",
      "Train Epoch 225.7 var loss 71702.0625 reconstruction mse 71698.9375 imputation mse 1.0032453536987305\n",
      "Train Epoch 225.8 var loss 71750.3125 reconstruction mse 71747.1875 imputation mse 1.003920555114746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 225.9 var loss 71732.0 reconstruction mse 71728.8203125 imputation mse 1.0036635398864746\n",
      "Train Epoch 226.0 var loss 71112.8671875 reconstruction mse 71107.9296875 imputation mse 0.9946138858795166\n",
      "Train Epoch 226.1 var loss 71089.4375 reconstruction mse 71086.046875 imputation mse 0.994307816028595\n",
      "Train Epoch 226.2 var loss 71101.21875 reconstruction mse 71097.734375 imputation mse 0.9944712519645691\n",
      "Train Epoch 226.3 var loss 71111.953125 reconstruction mse 71108.4375 imputation mse 0.9946209788322449\n",
      "Train Epoch 226.4 var loss 71111.6953125 reconstruction mse 71108.2421875 imputation mse 0.9946182370185852\n",
      "Train Epoch 226.5 var loss 71163.4453125 reconstruction mse 71160.0859375 imputation mse 0.9953433871269226\n",
      "Train Epoch 226.6 var loss 71116.6875 reconstruction mse 71113.4140625 imputation mse 0.9946905970573425\n",
      "Train Epoch 226.7 var loss 71093.5546875 reconstruction mse 71090.328125 imputation mse 0.9943676590919495\n",
      "Train Epoch 226.8 var loss 71121.0 reconstruction mse 71117.8359375 imputation mse 0.9947524070739746\n",
      "Train Epoch 226.9 var loss 71119.75 reconstruction mse 71116.6171875 imputation mse 0.9947353601455688\n",
      "Train Epoch 227.0 var loss 71847.984375 reconstruction mse 71843.109375 imputation mse 1.0051501989364624\n",
      "Train Epoch 227.1 var loss 71833.2265625 reconstruction mse 71829.921875 imputation mse 1.0049656629562378\n",
      "Train Epoch 227.2 var loss 71827.1640625 reconstruction mse 71823.7734375 imputation mse 1.0048797130584717\n",
      "Train Epoch 227.3 var loss 71820.4765625 reconstruction mse 71817.0390625 imputation mse 1.004785418510437\n",
      "Train Epoch 227.4 var loss 71828.8828125 reconstruction mse 71825.453125 imputation mse 1.0049031972885132\n",
      "Train Epoch 227.5 var loss 71827.296875 reconstruction mse 71823.9375 imputation mse 1.0048819780349731\n",
      "Train Epoch 227.6 var loss 71807.1171875 reconstruction mse 71803.828125 imputation mse 1.0046006441116333\n",
      "Train Epoch 227.7 var loss 71833.796875 reconstruction mse 71830.5703125 imputation mse 1.0049747228622437\n",
      "Train Epoch 227.8 var loss 71824.1640625 reconstruction mse 71820.953125 imputation mse 1.0048402547836304\n",
      "Train Epoch 227.9 var loss 71823.828125 reconstruction mse 71820.6171875 imputation mse 1.0048354864120483\n",
      "Train Epoch 228.0 var loss 71975.8515625 reconstruction mse 71971.0078125 imputation mse 1.00309419631958\n",
      "Train Epoch 228.1 var loss 71907.5078125 reconstruction mse 71904.140625 imputation mse 1.002162218093872\n",
      "Train Epoch 228.2 var loss 71939.0390625 reconstruction mse 71935.5703125 imputation mse 1.0026003122329712\n",
      "Train Epoch 228.3 var loss 71963.4921875 reconstruction mse 71960.0234375 imputation mse 1.0029411315917969\n",
      "Train Epoch 228.4 var loss 71923.6171875 reconstruction mse 71920.171875 imputation mse 1.0023857355117798\n",
      "Train Epoch 228.5 var loss 71933.0 reconstruction mse 71929.609375 imputation mse 1.0025172233581543\n",
      "Train Epoch 228.6 var loss 71924.21875 reconstruction mse 71920.8984375 imputation mse 1.0023958683013916\n",
      "Train Epoch 228.7 var loss 71960.953125 reconstruction mse 71957.71875 imputation mse 1.0029090642929077\n",
      "Train Epoch 228.8 var loss 71966.890625 reconstruction mse 71963.6953125 imputation mse 1.0029922723770142\n",
      "Train Epoch 228.9 var loss 71912.3203125 reconstruction mse 71909.125 imputation mse 1.0022317171096802\n",
      "Train Epoch 229.0 var loss 71421.859375 reconstruction mse 71417.0234375 imputation mse 1.0007569789886475\n",
      "Train Epoch 229.1 var loss 71455.125 reconstruction mse 71451.7578125 imputation mse 1.0012437105178833\n",
      "Train Epoch 229.2 var loss 71416.6015625 reconstruction mse 71413.140625 imputation mse 1.0007026195526123\n",
      "Train Epoch 229.3 var loss 71409.625 reconstruction mse 71406.1640625 imputation mse 1.0006048679351807\n",
      "Train Epoch 229.4 var loss 71420.1953125 reconstruction mse 71416.7578125 imputation mse 1.0007532835006714\n",
      "Train Epoch 229.5 var loss 71423.4453125 reconstruction mse 71420.1015625 imputation mse 1.0008001327514648\n",
      "Train Epoch 229.6 var loss 71431.578125 reconstruction mse 71428.328125 imputation mse 1.0009154081344604\n",
      "Train Epoch 229.7 var loss 71413.34375 reconstruction mse 71410.1796875 imputation mse 1.0006611347198486\n",
      "Train Epoch 229.8 var loss 71406.1328125 reconstruction mse 71403.0078125 imputation mse 1.0005606412887573\n",
      "Train Epoch 229.9 var loss 71431.6953125 reconstruction mse 71428.5546875 imputation mse 1.0009186267852783\n",
      "Train Epoch 230.0 var loss 71319.296875 reconstruction mse 71314.5078125 imputation mse 0.9929478764533997\n",
      "Train Epoch 230.1 var loss 71347.9375 reconstruction mse 71344.5546875 imputation mse 0.9933662414550781\n",
      "Train Epoch 230.2 var loss 71365.7890625 reconstruction mse 71362.296875 imputation mse 0.9936132431030273\n",
      "Train Epoch 230.3 var loss 71374.984375 reconstruction mse 71371.5 imputation mse 0.9937413930892944\n",
      "Train Epoch 230.4 var loss 71329.96875 reconstruction mse 71326.53125 imputation mse 0.993115246295929\n",
      "Train Epoch 230.5 var loss 71337.0859375 reconstruction mse 71333.78125 imputation mse 0.9932162165641785\n",
      "Train Epoch 230.6 var loss 71350.65625 reconstruction mse 71347.46875 imputation mse 0.9934067726135254\n",
      "Train Epoch 230.7 var loss 71307.484375 reconstruction mse 71304.3671875 imputation mse 0.9928066730499268\n",
      "Train Epoch 230.8 var loss 71336.3671875 reconstruction mse 71333.2734375 imputation mse 0.9932091236114502\n",
      "Train Epoch 230.9 var loss 71353.90625 reconstruction mse 71350.7890625 imputation mse 0.9934530258178711\n",
      "====> Test imputation mse: 0.98930240\n",
      "====> Test imputation mse: 1.00282562\n",
      "====> Test imputation mse: 0.99422878\n",
      "Train Epoch 231.0 var loss 71803.9296875 reconstruction mse 71799.171875 imputation mse 1.0032581090927124\n",
      "Train Epoch 231.1 var loss 71748.4296875 reconstruction mse 71745.046875 imputation mse 1.0025018453598022\n",
      "Train Epoch 231.2 var loss 71752.140625 reconstruction mse 71748.6484375 imputation mse 1.0025521516799927\n",
      "Train Epoch 231.3 var loss 71836.1328125 reconstruction mse 71832.640625 imputation mse 1.0037257671356201\n",
      "Train Epoch 231.4 var loss 71801.6328125 reconstruction mse 71798.234375 imputation mse 1.0032449960708618\n",
      "Train Epoch 231.5 var loss 71805.4453125 reconstruction mse 71802.15625 imputation mse 1.0032998323440552\n",
      "Train Epoch 231.6 var loss 71760.6015625 reconstruction mse 71757.421875 imputation mse 1.0026748180389404\n",
      "Train Epoch 231.7 var loss 71748.25 reconstruction mse 71745.1640625 imputation mse 1.002503514289856\n",
      "Train Epoch 231.8 var loss 71795.5703125 reconstruction mse 71792.5078125 imputation mse 1.0031650066375732\n",
      "Train Epoch 231.9 var loss 71767.4765625 reconstruction mse 71764.4296875 imputation mse 1.0027726888656616\n",
      "Train Epoch 232.0 var loss 70886.9609375 reconstruction mse 70882.3046875 imputation mse 0.9939465522766113\n",
      "Train Epoch 232.1 var loss 70922.046875 reconstruction mse 70918.7421875 imputation mse 0.994457483291626\n",
      "Train Epoch 232.2 var loss 70891.234375 reconstruction mse 70887.8125 imputation mse 0.9940237998962402\n",
      "Train Epoch 232.3 var loss 70876.734375 reconstruction mse 70873.296875 imputation mse 0.9938202500343323\n",
      "Train Epoch 232.4 var loss 70914.9921875 reconstruction mse 70911.6015625 imputation mse 0.9943573474884033\n",
      "Train Epoch 232.5 var loss 70925.3046875 reconstruction mse 70922.0 imputation mse 0.9945032000541687\n",
      "Train Epoch 232.6 var loss 70921.71875 reconstruction mse 70918.546875 imputation mse 0.9944547414779663\n",
      "Train Epoch 232.7 var loss 70887.1484375 reconstruction mse 70884.078125 imputation mse 0.9939714074134827\n",
      "Train Epoch 232.8 var loss 70916.2734375 reconstruction mse 70913.234375 imputation mse 0.9943802952766418\n",
      "Train Epoch 232.9 var loss 70916.5234375 reconstruction mse 70913.4609375 imputation mse 0.9943834543228149\n",
      "Train Epoch 233.0 var loss 71552.25 reconstruction mse 71547.5859375 imputation mse 0.9991562962532043\n",
      "Train Epoch 233.1 var loss 71513.921875 reconstruction mse 71510.59375 imputation mse 0.998639702796936\n",
      "Train Epoch 233.2 var loss 71532.015625 reconstruction mse 71528.5546875 imputation mse 0.9988905787467957\n",
      "Train Epoch 233.3 var loss 71591.4921875 reconstruction mse 71588.0234375 imputation mse 0.9997210502624512\n",
      "Train Epoch 233.4 var loss 71497.4453125 reconstruction mse 71494.0234375 imputation mse 0.998408317565918\n",
      "Train Epoch 233.5 var loss 71512.765625 reconstruction mse 71509.4609375 imputation mse 0.9986239075660706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 233.6 var loss 71565.7890625 reconstruction mse 71562.578125 imputation mse 0.9993656873703003\n",
      "Train Epoch 233.7 var loss 71533.5078125 reconstruction mse 71530.3671875 imputation mse 0.9989158511161804\n",
      "Train Epoch 233.8 var loss 71549.0390625 reconstruction mse 71545.9296875 imputation mse 0.9991331696510315\n",
      "Train Epoch 233.9 var loss 71519.625 reconstruction mse 71516.5078125 imputation mse 0.9987223148345947\n",
      "Train Epoch 234.0 var loss 71532.3984375 reconstruction mse 71527.7734375 imputation mse 1.0032649040222168\n",
      "Train Epoch 234.1 var loss 71553.046875 reconstruction mse 71549.75 imputation mse 1.0035731792449951\n",
      "Train Epoch 234.2 var loss 71572.0703125 reconstruction mse 71568.671875 imputation mse 1.0038385391235352\n",
      "Train Epoch 234.3 var loss 71591.90625 reconstruction mse 71588.5234375 imputation mse 1.0041170120239258\n",
      "Train Epoch 234.4 var loss 71555.53125 reconstruction mse 71552.171875 imputation mse 1.003607153892517\n",
      "Train Epoch 234.5 var loss 71559.421875 reconstruction mse 71556.1484375 imputation mse 1.0036629438400269\n",
      "Train Epoch 234.6 var loss 71566.1953125 reconstruction mse 71563.0 imputation mse 1.0037590265274048\n",
      "Train Epoch 234.7 var loss 71504.4375 reconstruction mse 71501.2890625 imputation mse 1.0028934478759766\n",
      "Train Epoch 234.8 var loss 71550.2109375 reconstruction mse 71547.125 imputation mse 1.003536343574524\n",
      "Train Epoch 234.9 var loss 71540.90625 reconstruction mse 71537.859375 imputation mse 1.0034064054489136\n",
      "Train Epoch 235.0 var loss 71750.4609375 reconstruction mse 71745.921875 imputation mse 1.0047041177749634\n",
      "Train Epoch 235.1 var loss 71717.875 reconstruction mse 71714.703125 imputation mse 1.0042669773101807\n",
      "Train Epoch 235.2 var loss 71754.375 reconstruction mse 71751.109375 imputation mse 1.0047767162322998\n",
      "Train Epoch 235.3 var loss 71706.65625 reconstruction mse 71703.375 imputation mse 1.0041083097457886\n",
      "Train Epoch 235.4 var loss 71752.9609375 reconstruction mse 71749.75 imputation mse 1.0047577619552612\n",
      "Train Epoch 235.5 var loss 71695.671875 reconstruction mse 71692.53125 imputation mse 1.0039564371109009\n",
      "Train Epoch 235.6 var loss 71714.1015625 reconstruction mse 71711.03125 imputation mse 1.0042154788970947\n",
      "Train Epoch 235.7 var loss 71710.96875 reconstruction mse 71707.9140625 imputation mse 1.0041718482971191\n",
      "Train Epoch 235.8 var loss 71725.3671875 reconstruction mse 71722.3046875 imputation mse 1.0043734312057495\n",
      "Train Epoch 235.9 var loss 71690.4921875 reconstruction mse 71687.3984375 imputation mse 1.0038845539093018\n",
      "Train Epoch 236.0 var loss 71691.0859375 reconstruction mse 71686.546875 imputation mse 1.0019644498825073\n",
      "Train Epoch 236.1 var loss 71671.9140625 reconstruction mse 71668.625 imputation mse 1.0017139911651611\n",
      "Train Epoch 236.2 var loss 71673.09375 reconstruction mse 71669.7578125 imputation mse 1.0017297267913818\n",
      "Train Epoch 236.3 var loss 71637.5234375 reconstruction mse 71634.21875 imputation mse 1.0012329816818237\n",
      "Train Epoch 236.4 var loss 71668.125 reconstruction mse 71664.890625 imputation mse 1.001661777496338\n",
      "Train Epoch 236.5 var loss 71703.6484375 reconstruction mse 71700.4921875 imputation mse 1.0021593570709229\n",
      "Train Epoch 236.6 var loss 71669.9296875 reconstruction mse 71666.84375 imputation mse 1.001689076423645\n",
      "Train Epoch 236.7 var loss 71676.4140625 reconstruction mse 71673.3671875 imputation mse 1.0017802715301514\n",
      "Train Epoch 236.8 var loss 71652.125 reconstruction mse 71649.0546875 imputation mse 1.001440405845642\n",
      "Train Epoch 236.9 var loss 71686.5625 reconstruction mse 71683.4609375 imputation mse 1.00192129611969\n",
      "Train Epoch 237.0 var loss 71566.4296875 reconstruction mse 71561.9140625 imputation mse 0.999859094619751\n",
      "Train Epoch 237.1 var loss 71584.75 reconstruction mse 71581.4453125 imputation mse 1.0001319646835327\n",
      "Train Epoch 237.2 var loss 71581.0859375 reconstruction mse 71577.671875 imputation mse 1.0000792741775513\n",
      "Train Epoch 237.3 var loss 71593.671875 reconstruction mse 71590.234375 imputation mse 1.00025475025177\n",
      "Train Epoch 237.4 var loss 71592.4921875 reconstruction mse 71589.0859375 imputation mse 1.0002387762069702\n",
      "Train Epoch 237.5 var loss 71610.4140625 reconstruction mse 71607.0859375 imputation mse 1.0004901885986328\n",
      "Train Epoch 237.6 var loss 71540.5 reconstruction mse 71537.2890625 imputation mse 0.9995149970054626\n",
      "Train Epoch 237.7 var loss 71536.453125 reconstruction mse 71533.3046875 imputation mse 0.9994593262672424\n",
      "Train Epoch 237.8 var loss 71652.53125 reconstruction mse 71649.4296875 imputation mse 1.0010818243026733\n",
      "Train Epoch 237.9 var loss 71553.3125 reconstruction mse 71550.1953125 imputation mse 0.999695360660553\n",
      "Train Epoch 238.0 var loss 72035.6796875 reconstruction mse 72031.1953125 imputation mse 1.0052921772003174\n",
      "Train Epoch 238.1 var loss 72041.140625 reconstruction mse 72037.84375 imputation mse 1.005384922027588\n",
      "Train Epoch 238.2 var loss 72015.9921875 reconstruction mse 72012.6171875 imputation mse 1.0050328969955444\n",
      "Train Epoch 238.3 var loss 72043.171875 reconstruction mse 72039.7890625 imputation mse 1.0054121017456055\n",
      "Train Epoch 238.4 var loss 72040.1328125 reconstruction mse 72036.828125 imputation mse 1.0053707361221313\n",
      "Train Epoch 238.5 var loss 72046.0234375 reconstruction mse 72042.8359375 imputation mse 1.005454659461975\n",
      "Train Epoch 238.6 var loss 72002.875 reconstruction mse 71999.8046875 imputation mse 1.0048540830612183\n",
      "Train Epoch 238.7 var loss 72042.9140625 reconstruction mse 72039.890625 imputation mse 1.00541353225708\n",
      "Train Epoch 238.8 var loss 72021.34375 reconstruction mse 72018.3203125 imputation mse 1.0051125288009644\n",
      "Train Epoch 238.9 var loss 72040.8984375 reconstruction mse 72037.796875 imputation mse 1.0053843259811401\n",
      "Train Epoch 239.0 var loss 71361.7109375 reconstruction mse 71357.2421875 imputation mse 0.9997512102127075\n",
      "Train Epoch 239.1 var loss 71313.1015625 reconstruction mse 71309.703125 imputation mse 0.9990851283073425\n",
      "Train Epoch 239.2 var loss 71316.8671875 reconstruction mse 71313.3125 imputation mse 0.9991357326507568\n",
      "Train Epoch 239.3 var loss 71289.8125 reconstruction mse 71286.234375 imputation mse 0.9987563490867615\n",
      "Train Epoch 239.4 var loss 71340.015625 reconstruction mse 71336.5234375 imputation mse 0.9994609355926514\n",
      "Train Epoch 239.5 var loss 71337.578125 reconstruction mse 71334.21875 imputation mse 0.9994286298751831\n",
      "Train Epoch 239.6 var loss 71341.296875 reconstruction mse 71338.09375 imputation mse 0.9994829297065735\n",
      "Train Epoch 239.7 var loss 71349.9765625 reconstruction mse 71346.875 imputation mse 0.9996059536933899\n",
      "Train Epoch 239.8 var loss 71308.0 reconstruction mse 71304.9609375 imputation mse 0.9990187287330627\n",
      "Train Epoch 239.9 var loss 71369.28125 reconstruction mse 71366.2109375 imputation mse 0.999876856803894\n",
      "Train Epoch 240.0 var loss 71572.0234375 reconstruction mse 71567.5625 imputation mse 1.0035696029663086\n",
      "Train Epoch 240.1 var loss 71561.640625 reconstruction mse 71558.3046875 imputation mse 1.0034397840499878\n",
      "Train Epoch 240.2 var loss 71611.328125 reconstruction mse 71607.8515625 imputation mse 1.0041346549987793\n",
      "Train Epoch 240.3 var loss 71596.3359375 reconstruction mse 71592.8671875 imputation mse 1.0039244890213013\n",
      "Train Epoch 240.4 var loss 71567.4921875 reconstruction mse 71564.09375 imputation mse 1.0035209655761719\n",
      "Train Epoch 240.5 var loss 71570.6953125 reconstruction mse 71567.4296875 imputation mse 1.0035678148269653\n",
      "Train Epoch 240.6 var loss 71558.59375 reconstruction mse 71555.46875 imputation mse 1.0034000873565674\n",
      "Train Epoch 240.7 var loss 71550.6015625 reconstruction mse 71547.578125 imputation mse 1.0032894611358643\n",
      "Train Epoch 240.8 var loss 71545.875 reconstruction mse 71542.90625 imputation mse 1.0032238960266113\n",
      "Train Epoch 240.9 var loss 71580.7421875 reconstruction mse 71577.7578125 imputation mse 1.0037126541137695\n",
      "====> Test imputation mse: 1.01399672\n",
      "====> Test imputation mse: 0.98956507\n",
      "====> Test imputation mse: 1.01014566\n",
      "Train Epoch 241.0 var loss 71691.3984375 reconstruction mse 71687.0546875 imputation mse 1.0018315315246582\n",
      "Train Epoch 241.1 var loss 71663.2265625 reconstruction mse 71659.9453125 imputation mse 1.0014526844024658\n",
      "Train Epoch 241.2 var loss 71710.3125 reconstruction mse 71706.890625 imputation mse 1.0021086931228638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 241.3 var loss 71654.8203125 reconstruction mse 71651.34375 imputation mse 1.001332402229309\n",
      "Train Epoch 241.4 var loss 71676.8046875 reconstruction mse 71673.359375 imputation mse 1.0016400814056396\n",
      "Train Epoch 241.5 var loss 71664.328125 reconstruction mse 71660.9921875 imputation mse 1.001467227935791\n",
      "Train Epoch 241.6 var loss 71675.9296875 reconstruction mse 71672.703125 imputation mse 1.0016309022903442\n",
      "Train Epoch 241.7 var loss 71670.3671875 reconstruction mse 71667.203125 imputation mse 1.001554012298584\n",
      "Train Epoch 241.8 var loss 71690.5078125 reconstruction mse 71687.390625 imputation mse 1.0018361806869507\n",
      "Train Epoch 241.9 var loss 71709.2890625 reconstruction mse 71706.1484375 imputation mse 1.0020983219146729\n",
      "Train Epoch 242.0 var loss 70603.8046875 reconstruction mse 70599.4375 imputation mse 0.9956343770027161\n",
      "Train Epoch 242.1 var loss 70628.8984375 reconstruction mse 70625.5390625 imputation mse 0.9960024952888489\n",
      "Train Epoch 242.2 var loss 70599.90625 reconstruction mse 70596.4140625 imputation mse 0.9955917596817017\n",
      "Train Epoch 242.3 var loss 70585.1953125 reconstruction mse 70581.6875 imputation mse 0.9953840374946594\n",
      "Train Epoch 242.4 var loss 70599.296875 reconstruction mse 70595.8671875 imputation mse 0.9955840110778809\n",
      "Train Epoch 242.5 var loss 70612.453125 reconstruction mse 70609.140625 imputation mse 0.9957712292671204\n",
      "Train Epoch 242.6 var loss 70609.71875 reconstruction mse 70606.53125 imputation mse 0.9957343935966492\n",
      "Train Epoch 242.7 var loss 70608.4140625 reconstruction mse 70605.3046875 imputation mse 0.9957171082496643\n",
      "Train Epoch 242.8 var loss 70624.0859375 reconstruction mse 70621.03125 imputation mse 0.9959388971328735\n",
      "Train Epoch 242.9 var loss 70544.4921875 reconstruction mse 70541.4375 imputation mse 0.9948164224624634\n",
      "Train Epoch 243.0 var loss 71045.03125 reconstruction mse 71040.7109375 imputation mse 0.9987727999687195\n",
      "Train Epoch 243.1 var loss 71037.6640625 reconstruction mse 71034.3671875 imputation mse 0.9986835718154907\n",
      "Train Epoch 243.2 var loss 71011.3671875 reconstruction mse 71007.9375 imputation mse 0.9983119964599609\n",
      "Train Epoch 243.3 var loss 71058.4375 reconstruction mse 71054.9765625 imputation mse 0.9989733695983887\n",
      "Train Epoch 243.4 var loss 71031.046875 reconstruction mse 71027.6328125 imputation mse 0.9985889196395874\n",
      "Train Epoch 243.5 var loss 71024.6796875 reconstruction mse 71021.359375 imputation mse 0.9985007047653198\n",
      "Train Epoch 243.6 var loss 71076.875 reconstruction mse 71073.703125 imputation mse 0.9992366433143616\n",
      "Train Epoch 243.7 var loss 71039.71875 reconstruction mse 71036.6796875 imputation mse 0.9987161159515381\n",
      "Train Epoch 243.8 var loss 71040.9140625 reconstruction mse 71037.9609375 imputation mse 0.9987341165542603\n",
      "Train Epoch 243.9 var loss 71044.421875 reconstruction mse 71041.484375 imputation mse 0.9987836480140686\n",
      "Train Epoch 244.0 var loss 72141.3125 reconstruction mse 72137.046875 imputation mse 1.0031713247299194\n",
      "Train Epoch 244.1 var loss 72120.359375 reconstruction mse 72117.1640625 imputation mse 1.0028948783874512\n",
      "Train Epoch 244.2 var loss 72103.2890625 reconstruction mse 72099.96875 imputation mse 1.0026557445526123\n",
      "Train Epoch 244.3 var loss 72072.7890625 reconstruction mse 72069.4140625 imputation mse 1.0022307634353638\n",
      "Train Epoch 244.4 var loss 72082.546875 reconstruction mse 72079.2109375 imputation mse 1.0023670196533203\n",
      "Train Epoch 244.5 var loss 72122.546875 reconstruction mse 72119.296875 imputation mse 1.0029244422912598\n",
      "Train Epoch 244.6 var loss 72115.453125 reconstruction mse 72112.3125 imputation mse 1.0028274059295654\n",
      "Train Epoch 244.7 var loss 72114.40625 reconstruction mse 72111.359375 imputation mse 1.0028140544891357\n",
      "Train Epoch 244.8 var loss 72115.6328125 reconstruction mse 72112.59375 imputation mse 1.002831220626831\n",
      "Train Epoch 244.9 var loss 72070.9296875 reconstruction mse 72067.8671875 imputation mse 1.0022093057632446\n",
      "Train Epoch 245.0 var loss 71590.9765625 reconstruction mse 71586.671875 imputation mse 1.0026847124099731\n",
      "Train Epoch 245.1 var loss 71571.78125 reconstruction mse 71568.4765625 imputation mse 1.0024298429489136\n",
      "Train Epoch 245.2 var loss 71590.265625 reconstruction mse 71586.828125 imputation mse 1.002686858177185\n",
      "Train Epoch 245.3 var loss 71613.1328125 reconstruction mse 71609.6875 imputation mse 1.0030070543289185\n",
      "Train Epoch 245.4 var loss 71630.2890625 reconstruction mse 71626.8828125 imputation mse 1.003247857093811\n",
      "Train Epoch 245.5 var loss 71601.015625 reconstruction mse 71597.75 imputation mse 1.0028398036956787\n",
      "Train Epoch 245.6 var loss 71635.25 reconstruction mse 71632.1015625 imputation mse 1.0033209323883057\n",
      "Train Epoch 245.7 var loss 71621.6796875 reconstruction mse 71618.6171875 imputation mse 1.0031321048736572\n",
      "Train Epoch 245.8 var loss 71625.7578125 reconstruction mse 71622.71875 imputation mse 1.0031895637512207\n",
      "Train Epoch 245.9 var loss 71590.921875 reconstruction mse 71587.875 imputation mse 1.0027015209197998\n",
      "Train Epoch 246.0 var loss 71732.6953125 reconstruction mse 71728.4375 imputation mse 0.9990867972373962\n",
      "Train Epoch 246.1 var loss 71722.703125 reconstruction mse 71719.4296875 imputation mse 0.998961329460144\n",
      "Train Epoch 246.2 var loss 71703.71875 reconstruction mse 71700.359375 imputation mse 0.9986957311630249\n",
      "Train Epoch 246.3 var loss 71731.234375 reconstruction mse 71727.875 imputation mse 0.9990789890289307\n",
      "Train Epoch 246.4 var loss 71750.125 reconstruction mse 71746.8359375 imputation mse 0.9993430376052856\n",
      "Train Epoch 246.5 var loss 71754.5625 reconstruction mse 71751.3828125 imputation mse 0.9994063973426819\n",
      "Train Epoch 246.6 var loss 71700.4296875 reconstruction mse 71697.34375 imputation mse 0.9986537098884583\n",
      "Train Epoch 246.7 var loss 71693.875 reconstruction mse 71690.8203125 imputation mse 0.9985628128051758\n",
      "Train Epoch 246.8 var loss 71714.28125 reconstruction mse 71711.2578125 imputation mse 0.998847484588623\n",
      "Train Epoch 246.9 var loss 71693.015625 reconstruction mse 71689.984375 imputation mse 0.9985511898994446\n",
      "Train Epoch 247.0 var loss 70808.515625 reconstruction mse 70804.328125 imputation mse 0.9938983917236328\n",
      "Train Epoch 247.1 var loss 70776.46875 reconstruction mse 70773.2734375 imputation mse 0.9934625029563904\n",
      "Train Epoch 247.2 var loss 70759.734375 reconstruction mse 70756.421875 imputation mse 0.9932259321212769\n",
      "Train Epoch 247.3 var loss 70814.734375 reconstruction mse 70811.4375 imputation mse 0.9939981698989868\n",
      "Train Epoch 247.4 var loss 70808.046875 reconstruction mse 70804.7578125 imputation mse 0.9939044117927551\n",
      "Train Epoch 247.5 var loss 70774.21875 reconstruction mse 70771.0078125 imputation mse 0.9934306740760803\n",
      "Train Epoch 247.6 var loss 70796.0859375 reconstruction mse 70792.9453125 imputation mse 0.99373859167099\n",
      "Train Epoch 247.7 var loss 70791.9140625 reconstruction mse 70788.8046875 imputation mse 0.993680477142334\n",
      "Train Epoch 247.8 var loss 70797.0390625 reconstruction mse 70793.984375 imputation mse 0.99375319480896\n",
      "Train Epoch 247.9 var loss 70799.9765625 reconstruction mse 70796.90625 imputation mse 0.9937942028045654\n",
      "Train Epoch 248.0 var loss 71124.5625 reconstruction mse 71120.3203125 imputation mse 0.9951908588409424\n",
      "Train Epoch 248.1 var loss 71070.515625 reconstruction mse 71067.2265625 imputation mse 0.9944479465484619\n",
      "Train Epoch 248.2 var loss 71096.1796875 reconstruction mse 71092.8046875 imputation mse 0.9948058128356934\n",
      "Train Epoch 248.3 var loss 71082.2734375 reconstruction mse 71078.890625 imputation mse 0.9946111440658569\n",
      "Train Epoch 248.4 var loss 71109.8125 reconstruction mse 71106.46875 imputation mse 0.9949970245361328\n",
      "Train Epoch 248.5 var loss 71115.6796875 reconstruction mse 71112.4140625 imputation mse 0.9950802326202393\n",
      "Train Epoch 248.6 var loss 71103.265625 reconstruction mse 71100.09375 imputation mse 0.9949078559875488\n",
      "Train Epoch 248.7 var loss 71114.2109375 reconstruction mse 71111.1015625 imputation mse 0.9950618743896484\n",
      "Train Epoch 248.8 var loss 71082.1484375 reconstruction mse 71079.0859375 imputation mse 0.9946138858795166\n",
      "Train Epoch 248.9 var loss 71125.734375 reconstruction mse 71122.6640625 imputation mse 0.9952236413955688\n",
      "Train Epoch 249.0 var loss 71639.9296875 reconstruction mse 71635.703125 imputation mse 0.996975839138031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 249.1 var loss 71656.1640625 reconstruction mse 71652.8828125 imputation mse 0.9972149133682251\n",
      "Train Epoch 249.2 var loss 71635.71875 reconstruction mse 71632.328125 imputation mse 0.996928870677948\n",
      "Train Epoch 249.3 var loss 71632.140625 reconstruction mse 71628.78125 imputation mse 0.9968794584274292\n",
      "Train Epoch 249.4 var loss 71643.390625 reconstruction mse 71640.1015625 imputation mse 0.9970370531082153\n",
      "Train Epoch 249.5 var loss 71679.65625 reconstruction mse 71676.4453125 imputation mse 0.9975428581237793\n",
      "Train Epoch 249.6 var loss 71632.34375 reconstruction mse 71629.15625 imputation mse 0.9968847036361694\n",
      "Train Epoch 249.7 var loss 71628.8515625 reconstruction mse 71625.703125 imputation mse 0.9968366622924805\n",
      "Train Epoch 249.8 var loss 71689.2890625 reconstruction mse 71686.140625 imputation mse 0.997677743434906\n",
      "Train Epoch 249.9 var loss 71667.75 reconstruction mse 71664.5859375 imputation mse 0.9973778128623962\n",
      "Train Epoch 250.0 var loss 71088.2109375 reconstruction mse 71083.9921875 imputation mse 0.9998030066490173\n",
      "Train Epoch 250.1 var loss 71075.515625 reconstruction mse 71072.1875 imputation mse 0.9996369481086731\n",
      "Train Epoch 250.2 var loss 71029.8671875 reconstruction mse 71026.4765625 imputation mse 0.998993992805481\n",
      "Train Epoch 250.3 var loss 71050.421875 reconstruction mse 71047.0703125 imputation mse 0.9992836713790894\n",
      "Train Epoch 250.4 var loss 71087.828125 reconstruction mse 71084.5703125 imputation mse 0.9998111128807068\n",
      "Train Epoch 250.5 var loss 71071.6640625 reconstruction mse 71068.5 imputation mse 0.9995850920677185\n",
      "Train Epoch 250.6 var loss 71078.078125 reconstruction mse 71075.015625 imputation mse 0.9996767044067383\n",
      "Train Epoch 250.7 var loss 71047.90625 reconstruction mse 71044.8828125 imputation mse 0.9992529153823853\n",
      "Train Epoch 250.8 var loss 71073.3984375 reconstruction mse 71070.40625 imputation mse 0.9996119141578674\n",
      "Train Epoch 250.9 var loss 71076.1875 reconstruction mse 71073.1640625 imputation mse 0.9996506571769714\n",
      "====> Test imputation mse: 0.98795152\n",
      "====> Test imputation mse: 0.98509020\n",
      "====> Test imputation mse: 0.99464273\n",
      "Train Epoch 251.0 var loss 71884.171875 reconstruction mse 71880.0859375 imputation mse 1.004866123199463\n",
      "Train Epoch 251.1 var loss 71867.8125 reconstruction mse 71864.59375 imputation mse 1.0046496391296387\n",
      "Train Epoch 251.2 var loss 71892.7265625 reconstruction mse 71889.421875 imputation mse 1.004996657371521\n",
      "Train Epoch 251.3 var loss 71882.59375 reconstruction mse 71879.28125 imputation mse 1.0048549175262451\n",
      "Train Epoch 251.4 var loss 71871.34375 reconstruction mse 71868.0859375 imputation mse 1.004698395729065\n",
      "Train Epoch 251.5 var loss 71863.0078125 reconstruction mse 71859.8671875 imputation mse 1.004583477973938\n",
      "Train Epoch 251.6 var loss 71873.96875 reconstruction mse 71870.8984375 imputation mse 1.0047377347946167\n",
      "Train Epoch 251.7 var loss 71889.21875 reconstruction mse 71886.1953125 imputation mse 1.0049515962600708\n",
      "Train Epoch 251.8 var loss 71894.328125 reconstruction mse 71891.28125 imputation mse 1.005022644996643\n",
      "Train Epoch 251.9 var loss 71817.734375 reconstruction mse 71814.671875 imputation mse 1.0039516687393188\n",
      "Train Epoch 252.0 var loss 71975.5 reconstruction mse 71971.3671875 imputation mse 1.0098835229873657\n",
      "Train Epoch 252.1 var loss 71969.7890625 reconstruction mse 71966.53125 imputation mse 1.0098156929016113\n",
      "Train Epoch 252.2 var loss 72002.2734375 reconstruction mse 71998.9453125 imputation mse 1.0102704763412476\n",
      "Train Epoch 252.3 var loss 71983.8984375 reconstruction mse 71980.5546875 imputation mse 1.0100123882293701\n",
      "Train Epoch 252.4 var loss 71974.953125 reconstruction mse 71971.6953125 imputation mse 1.0098880529403687\n",
      "Train Epoch 252.5 var loss 71957.6328125 reconstruction mse 71954.4765625 imputation mse 1.0096465349197388\n",
      "Train Epoch 252.6 var loss 71975.9296875 reconstruction mse 71972.8671875 imputation mse 1.0099045038223267\n",
      "Train Epoch 252.7 var loss 71964.84375 reconstruction mse 71961.8125 imputation mse 1.009749412536621\n",
      "Train Epoch 252.8 var loss 71970.6328125 reconstruction mse 71967.59375 imputation mse 1.0098305940628052\n",
      "Train Epoch 252.9 var loss 71989.9453125 reconstruction mse 71986.8671875 imputation mse 1.0101009607315063\n",
      "Train Epoch 253.0 var loss 72247.5078125 reconstruction mse 72243.375 imputation mse 1.0085067749023438\n",
      "Train Epoch 253.1 var loss 72231.59375 reconstruction mse 72228.2890625 imputation mse 1.0082961320877075\n",
      "Train Epoch 253.2 var loss 72277.5 reconstruction mse 72274.1171875 imputation mse 1.0089359283447266\n",
      "Train Epoch 253.3 var loss 72262.5 reconstruction mse 72259.1328125 imputation mse 1.008726716041565\n",
      "Train Epoch 253.4 var loss 72257.265625 reconstruction mse 72253.984375 imputation mse 1.0086548328399658\n",
      "Train Epoch 253.5 var loss 72255.390625 reconstruction mse 72252.21875 imputation mse 1.0086302757263184\n",
      "Train Epoch 253.6 var loss 72279.625 reconstruction mse 72276.53125 imputation mse 1.0089696645736694\n",
      "Train Epoch 253.7 var loss 72282.0546875 reconstruction mse 72279.0 imputation mse 1.0090041160583496\n",
      "Train Epoch 253.8 var loss 72278.78125 reconstruction mse 72275.7109375 imputation mse 1.0089582204818726\n",
      "Train Epoch 253.9 var loss 72249.375 reconstruction mse 72246.2890625 imputation mse 1.0085474252700806\n",
      "Train Epoch 254.0 var loss 71732.8203125 reconstruction mse 71728.7578125 imputation mse 1.005576252937317\n",
      "Train Epoch 254.1 var loss 71672.7578125 reconstruction mse 71669.53125 imputation mse 1.0047459602355957\n",
      "Train Epoch 254.2 var loss 71674.4921875 reconstruction mse 71671.2109375 imputation mse 1.0047694444656372\n",
      "Train Epoch 254.3 var loss 71693.515625 reconstruction mse 71690.2734375 imputation mse 1.00503671169281\n",
      "Train Epoch 254.4 var loss 71683.5 reconstruction mse 71680.3203125 imputation mse 1.004897117614746\n",
      "Train Epoch 254.5 var loss 71668.8046875 reconstruction mse 71665.703125 imputation mse 1.0046921968460083\n",
      "Train Epoch 254.6 var loss 71638.125 reconstruction mse 71635.0625 imputation mse 1.0042626857757568\n",
      "Train Epoch 254.7 var loss 71699.390625 reconstruction mse 71696.34375 imputation mse 1.0051218271255493\n",
      "Train Epoch 254.8 var loss 71652.921875 reconstruction mse 71649.8515625 imputation mse 1.0044699907302856\n",
      "Train Epoch 254.9 var loss 71641.2265625 reconstruction mse 71638.1328125 imputation mse 1.0043057203292847\n",
      "Train Epoch 255.0 var loss 71975.4453125 reconstruction mse 71971.390625 imputation mse 1.0086524486541748\n",
      "Train Epoch 255.1 var loss 71967.421875 reconstruction mse 71964.1328125 imputation mse 1.008550763130188\n",
      "Train Epoch 255.2 var loss 71931.546875 reconstruction mse 71928.1796875 imputation mse 1.0080468654632568\n",
      "Train Epoch 255.3 var loss 71958.0703125 reconstruction mse 71954.703125 imputation mse 1.0084186792373657\n",
      "Train Epoch 255.4 var loss 71993.8984375 reconstruction mse 71990.609375 imputation mse 1.0089218616485596\n",
      "Train Epoch 255.5 var loss 71979.1875 reconstruction mse 71976.0 imputation mse 1.0087170600891113\n",
      "Train Epoch 255.6 var loss 71944.7578125 reconstruction mse 71941.640625 imputation mse 1.0082355737686157\n",
      "Train Epoch 255.7 var loss 71932.8828125 reconstruction mse 71929.8203125 imputation mse 1.0080698728561401\n",
      "Train Epoch 255.8 var loss 71977.921875 reconstruction mse 71974.8671875 imputation mse 1.008701205253601\n",
      "Train Epoch 255.9 var loss 71917.140625 reconstruction mse 71914.0859375 imputation mse 1.0078494548797607\n",
      "Train Epoch 256.0 var loss 71688.171875 reconstruction mse 71684.171875 imputation mse 1.003994107246399\n",
      "Train Epoch 256.1 var loss 71677.0078125 reconstruction mse 71673.7734375 imputation mse 1.0038484334945679\n",
      "Train Epoch 256.2 var loss 71673.5078125 reconstruction mse 71670.1875 imputation mse 1.003798246383667\n",
      "Train Epoch 256.3 var loss 71708.0 reconstruction mse 71704.6875 imputation mse 1.0042814016342163\n",
      "Train Epoch 256.4 var loss 71695.0078125 reconstruction mse 71691.7734375 imputation mse 1.0041005611419678\n",
      "Train Epoch 256.5 var loss 71691.1640625 reconstruction mse 71688.0546875 imputation mse 1.004048466682434\n",
      "Train Epoch 256.6 var loss 71691.4921875 reconstruction mse 71688.4921875 imputation mse 1.0040545463562012\n",
      "Train Epoch 256.7 var loss 71677.125 reconstruction mse 71674.1796875 imputation mse 1.0038541555404663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 256.8 var loss 71683.640625 reconstruction mse 71680.703125 imputation mse 1.0039454698562622\n",
      "Train Epoch 256.9 var loss 71686.90625 reconstruction mse 71683.953125 imputation mse 1.0039910078048706\n",
      "Train Epoch 257.0 var loss 71166.8046875 reconstruction mse 71162.8671875 imputation mse 0.9977128505706787\n",
      "Train Epoch 257.1 var loss 71222.640625 reconstruction mse 71219.4609375 imputation mse 0.9985063076019287\n",
      "Train Epoch 257.2 var loss 71176.078125 reconstruction mse 71172.8203125 imputation mse 0.9978523850440979\n",
      "Train Epoch 257.3 var loss 71152.34375 reconstruction mse 71149.1171875 imputation mse 0.9975200891494751\n",
      "Train Epoch 257.4 var loss 71182.2734375 reconstruction mse 71179.15625 imputation mse 0.997941255569458\n",
      "Train Epoch 257.5 var loss 71190.65625 reconstruction mse 71187.6171875 imputation mse 0.998059868812561\n",
      "Train Epoch 257.6 var loss 71182.8203125 reconstruction mse 71179.8671875 imputation mse 0.9979512095451355\n",
      "Train Epoch 257.7 var loss 71145.75 reconstruction mse 71142.875 imputation mse 0.9974325895309448\n",
      "Train Epoch 257.8 var loss 71182.484375 reconstruction mse 71179.609375 imputation mse 0.9979475736618042\n",
      "Train Epoch 257.9 var loss 71185.0234375 reconstruction mse 71182.109375 imputation mse 0.9979826211929321\n",
      "Train Epoch 258.0 var loss 71511.2890625 reconstruction mse 71507.375 imputation mse 1.001503825187683\n",
      "Train Epoch 258.1 var loss 71473.53125 reconstruction mse 71470.390625 imputation mse 1.000985860824585\n",
      "Train Epoch 258.2 var loss 71499.7421875 reconstruction mse 71496.4765625 imputation mse 1.001351237297058\n",
      "Train Epoch 258.3 var loss 71475.6953125 reconstruction mse 71472.4296875 imputation mse 1.0010144710540771\n",
      "Train Epoch 258.4 var loss 71501.8828125 reconstruction mse 71498.6640625 imputation mse 1.0013818740844727\n",
      "Train Epoch 258.5 var loss 71466.3515625 reconstruction mse 71463.2421875 imputation mse 1.0008857250213623\n",
      "Train Epoch 258.6 var loss 71479.625 reconstruction mse 71476.609375 imputation mse 1.0010730028152466\n",
      "Train Epoch 258.7 var loss 71477.2578125 reconstruction mse 71474.2578125 imputation mse 1.001039981842041\n",
      "Train Epoch 258.8 var loss 71499.4609375 reconstruction mse 71496.484375 imputation mse 1.0013513565063477\n",
      "Train Epoch 258.9 var loss 71511.7265625 reconstruction mse 71508.71875 imputation mse 1.0015226602554321\n",
      "Train Epoch 259.0 var loss 71964.7890625 reconstruction mse 71960.859375 imputation mse 1.0057423114776611\n",
      "Train Epoch 259.1 var loss 71973.109375 reconstruction mse 71969.8203125 imputation mse 1.0058674812316895\n",
      "Train Epoch 259.2 var loss 71992.7734375 reconstruction mse 71989.390625 imputation mse 1.0061410665512085\n",
      "Train Epoch 259.3 var loss 71934.984375 reconstruction mse 71931.6171875 imputation mse 1.0053335428237915\n",
      "Train Epoch 259.4 var loss 71964.0859375 reconstruction mse 71960.796875 imputation mse 1.0057413578033447\n",
      "Train Epoch 259.5 var loss 71972.1875 reconstruction mse 71969.0078125 imputation mse 1.0058561563491821\n",
      "Train Epoch 259.6 var loss 71977.875 reconstruction mse 71974.796875 imputation mse 1.005937099456787\n",
      "Train Epoch 259.7 var loss 71985.109375 reconstruction mse 71982.0625 imputation mse 1.0060386657714844\n",
      "Train Epoch 259.8 var loss 71980.9765625 reconstruction mse 71977.9375 imputation mse 1.0059809684753418\n",
      "Train Epoch 259.9 var loss 71995.7421875 reconstruction mse 71992.6875 imputation mse 1.006187081336975\n",
      "Train Epoch 260.0 var loss 71132.78125 reconstruction mse 71128.78125 imputation mse 0.9930581450462341\n",
      "Train Epoch 260.1 var loss 71142.9453125 reconstruction mse 71139.6640625 imputation mse 0.9932100772857666\n",
      "Train Epoch 260.2 var loss 71107.5 reconstruction mse 71104.1640625 imputation mse 0.9927144050598145\n",
      "Train Epoch 260.3 var loss 71133.8125 reconstruction mse 71130.515625 imputation mse 0.9930823445320129\n",
      "Train Epoch 260.4 var loss 71152.5625 reconstruction mse 71149.375 imputation mse 0.9933456182479858\n",
      "Train Epoch 260.5 var loss 71121.9296875 reconstruction mse 71118.859375 imputation mse 0.9929196238517761\n",
      "Train Epoch 260.6 var loss 71148.6484375 reconstruction mse 71145.6875 imputation mse 0.9932941794395447\n",
      "Train Epoch 260.7 var loss 71124.578125 reconstruction mse 71121.671875 imputation mse 0.9929588437080383\n",
      "Train Epoch 260.8 var loss 71174.3046875 reconstruction mse 71171.4140625 imputation mse 0.9936533570289612\n",
      "Train Epoch 260.9 var loss 71175.7109375 reconstruction mse 71172.8125 imputation mse 0.9936728477478027\n",
      "====> Test imputation mse: 1.01021850\n",
      "====> Test imputation mse: 0.99292862\n",
      "====> Test imputation mse: 1.01874387\n",
      "Train Epoch 261.0 var loss 71253.3828125 reconstruction mse 71249.5546875 imputation mse 0.9992364048957825\n",
      "Train Epoch 261.1 var loss 71237.6171875 reconstruction mse 71234.484375 imputation mse 0.9990251064300537\n",
      "Train Epoch 261.2 var loss 71281.2109375 reconstruction mse 71277.9609375 imputation mse 0.9996348023414612\n",
      "Train Epoch 261.3 var loss 71274.140625 reconstruction mse 71270.90625 imputation mse 0.999535858631134\n",
      "Train Epoch 261.4 var loss 71271.3203125 reconstruction mse 71268.15625 imputation mse 0.9994972944259644\n",
      "Train Epoch 261.5 var loss 71204.1875 reconstruction mse 71201.15625 imputation mse 0.9985576868057251\n",
      "Train Epoch 261.6 var loss 71240.828125 reconstruction mse 71237.8984375 imputation mse 0.9990729689598083\n",
      "Train Epoch 261.7 var loss 71266.078125 reconstruction mse 71263.1953125 imputation mse 0.9994277358055115\n",
      "Train Epoch 261.8 var loss 71231.390625 reconstruction mse 71228.5078125 imputation mse 0.9989412426948547\n",
      "Train Epoch 261.9 var loss 71242.9296875 reconstruction mse 71239.9921875 imputation mse 0.9991023540496826\n",
      "Train Epoch 262.0 var loss 70913.9609375 reconstruction mse 70910.1328125 imputation mse 0.9981437921524048\n",
      "Train Epoch 262.1 var loss 70836.6015625 reconstruction mse 70833.421875 imputation mse 0.9970639944076538\n",
      "Train Epoch 262.2 var loss 70891.609375 reconstruction mse 70888.3125 imputation mse 0.9978366494178772\n",
      "Train Epoch 262.3 var loss 70882.828125 reconstruction mse 70879.546875 imputation mse 0.9977132678031921\n",
      "Train Epoch 262.4 var loss 70895.5390625 reconstruction mse 70892.3046875 imputation mse 0.9978928565979004\n",
      "Train Epoch 262.5 var loss 70867.203125 reconstruction mse 70864.0546875 imputation mse 0.9974952340126038\n",
      "Train Epoch 262.6 var loss 70901.2890625 reconstruction mse 70898.2265625 imputation mse 0.9979762434959412\n",
      "Train Epoch 262.7 var loss 70880.3125 reconstruction mse 70877.2734375 imputation mse 0.9976812601089478\n",
      "Train Epoch 262.8 var loss 70866.421875 reconstruction mse 70863.4140625 imputation mse 0.9974861741065979\n",
      "Train Epoch 262.9 var loss 70861.359375 reconstruction mse 70858.328125 imputation mse 0.9974145889282227\n",
      "Train Epoch 263.0 var loss 71338.7109375 reconstruction mse 71334.84375 imputation mse 0.9988076686859131\n",
      "Train Epoch 263.1 var loss 71310.421875 reconstruction mse 71307.296875 imputation mse 0.9984219670295715\n",
      "Train Epoch 263.2 var loss 71264.8359375 reconstruction mse 71261.6484375 imputation mse 0.997782826423645\n",
      "Train Epoch 263.3 var loss 71289.6171875 reconstruction mse 71286.4296875 imputation mse 0.9981297850608826\n",
      "Train Epoch 263.4 var loss 71308.390625 reconstruction mse 71305.3125 imputation mse 0.9983941912651062\n",
      "Train Epoch 263.5 var loss 71295.3671875 reconstruction mse 71292.3984375 imputation mse 0.9982133507728577\n",
      "Train Epoch 263.6 var loss 71282.8046875 reconstruction mse 71279.8984375 imputation mse 0.9980383515357971\n",
      "Train Epoch 263.7 var loss 71286.2109375 reconstruction mse 71283.328125 imputation mse 0.9980863928794861\n",
      "Train Epoch 263.8 var loss 71277.9375 reconstruction mse 71275.046875 imputation mse 0.9979704022407532\n",
      "Train Epoch 263.9 var loss 71309.5 reconstruction mse 71306.5625 imputation mse 0.9984116554260254\n",
      "Train Epoch 264.0 var loss 72216.8203125 reconstruction mse 72213.0 imputation mse 1.0112732648849487\n",
      "Train Epoch 264.1 var loss 72170.9765625 reconstruction mse 72167.8359375 imputation mse 1.0106407403945923\n",
      "Train Epoch 264.2 var loss 72146.96875 reconstruction mse 72143.765625 imputation mse 1.0103037357330322\n",
      "Train Epoch 264.3 var loss 72174.7421875 reconstruction mse 72171.5390625 imputation mse 1.0106925964355469\n",
      "Train Epoch 264.4 var loss 72190.9765625 reconstruction mse 72187.859375 imputation mse 1.0109211206436157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 264.5 var loss 72164.015625 reconstruction mse 72160.984375 imputation mse 1.010544776916504\n",
      "Train Epoch 264.6 var loss 72161.796875 reconstruction mse 72158.84375 imputation mse 1.0105148553848267\n",
      "Train Epoch 264.7 var loss 72179.7890625 reconstruction mse 72176.8671875 imputation mse 1.0107672214508057\n",
      "Train Epoch 264.8 var loss 72186.3828125 reconstruction mse 72183.4453125 imputation mse 1.0108593702316284\n",
      "Train Epoch 264.9 var loss 72187.46875 reconstruction mse 72184.515625 imputation mse 1.0108743906021118\n",
      "Train Epoch 265.0 var loss 71725.34375 reconstruction mse 71721.53125 imputation mse 1.0004817247390747\n",
      "Train Epoch 265.1 var loss 71762.46875 reconstruction mse 71759.2890625 imputation mse 1.00100839138031\n",
      "Train Epoch 265.2 var loss 71764.3671875 reconstruction mse 71761.0859375 imputation mse 1.0010334253311157\n",
      "Train Epoch 265.3 var loss 71766.75 reconstruction mse 71763.421875 imputation mse 1.0010660886764526\n",
      "Train Epoch 265.4 var loss 71776.84375 reconstruction mse 71773.578125 imputation mse 1.001207709312439\n",
      "Train Epoch 265.5 var loss 71786.015625 reconstruction mse 71782.8828125 imputation mse 1.0013375282287598\n",
      "Train Epoch 265.6 var loss 71778.9921875 reconstruction mse 71775.9296875 imputation mse 1.0012404918670654\n",
      "Train Epoch 265.7 var loss 71824.890625 reconstruction mse 71821.8984375 imputation mse 1.001881718635559\n",
      "Train Epoch 265.8 var loss 71774.3984375 reconstruction mse 71771.4375 imputation mse 1.0011779069900513\n",
      "Train Epoch 265.9 var loss 71736.1015625 reconstruction mse 71733.1171875 imputation mse 1.0006433725357056\n",
      "Train Epoch 266.0 var loss 71580.203125 reconstruction mse 71576.390625 imputation mse 1.002709150314331\n",
      "Train Epoch 266.1 var loss 71533.9375 reconstruction mse 71530.7421875 imputation mse 1.0020697116851807\n",
      "Train Epoch 266.2 var loss 71531.7421875 reconstruction mse 71528.421875 imputation mse 1.0020371675491333\n",
      "Train Epoch 266.3 var loss 71554.765625 reconstruction mse 71551.4375 imputation mse 1.0023596286773682\n",
      "Train Epoch 266.4 var loss 71550.59375 reconstruction mse 71547.3359375 imputation mse 1.0023021697998047\n",
      "Train Epoch 266.5 var loss 71555.1953125 reconstruction mse 71552.0703125 imputation mse 1.002368450164795\n",
      "Train Epoch 266.6 var loss 71546.4453125 reconstruction mse 71543.4453125 imputation mse 1.00224769115448\n",
      "Train Epoch 266.7 var loss 71594.359375 reconstruction mse 71591.421875 imputation mse 1.0029197931289673\n",
      "Train Epoch 266.8 var loss 71551.1171875 reconstruction mse 71548.1953125 imputation mse 1.0023142099380493\n",
      "Train Epoch 266.9 var loss 71548.7109375 reconstruction mse 71545.78125 imputation mse 1.002280354499817\n",
      "Train Epoch 267.0 var loss 71930.6796875 reconstruction mse 71926.9296875 imputation mse 0.9997627139091492\n",
      "Train Epoch 267.1 var loss 71942.9765625 reconstruction mse 71939.8046875 imputation mse 0.9999417066574097\n",
      "Train Epoch 267.2 var loss 71918.0078125 reconstruction mse 71914.7421875 imputation mse 0.9995933175086975\n",
      "Train Epoch 267.3 var loss 71950.8203125 reconstruction mse 71947.5625 imputation mse 1.0000494718551636\n",
      "Train Epoch 267.4 var loss 71958.0234375 reconstruction mse 71954.875 imputation mse 1.0001511573791504\n",
      "Train Epoch 267.5 var loss 71965.828125 reconstruction mse 71962.8046875 imputation mse 1.0002614259719849\n",
      "Train Epoch 267.6 var loss 71990.0703125 reconstruction mse 71987.140625 imputation mse 1.0005996227264404\n",
      "Train Epoch 267.7 var loss 71969.0859375 reconstruction mse 71966.234375 imputation mse 1.0003091096878052\n",
      "Train Epoch 267.8 var loss 71925.0078125 reconstruction mse 71922.1640625 imputation mse 0.9996964931488037\n",
      "Train Epoch 267.9 var loss 71956.4375 reconstruction mse 71953.578125 imputation mse 1.0001331567764282\n",
      "Train Epoch 268.0 var loss 72196.0234375 reconstruction mse 72192.3359375 imputation mse 1.0093159675598145\n",
      "Train Epoch 268.1 var loss 72166.296875 reconstruction mse 72163.203125 imputation mse 1.008908748626709\n",
      "Train Epoch 268.2 var loss 72182.8515625 reconstruction mse 72179.65625 imputation mse 1.0091387033462524\n",
      "Train Epoch 268.3 var loss 72220.1953125 reconstruction mse 72216.9765625 imputation mse 1.0096604824066162\n",
      "Train Epoch 268.4 var loss 72165.859375 reconstruction mse 72162.6953125 imputation mse 1.008901596069336\n",
      "Train Epoch 268.5 var loss 72160.3125 reconstruction mse 72157.2421875 imputation mse 1.0088253021240234\n",
      "Train Epoch 268.6 var loss 72180.546875 reconstruction mse 72177.546875 imputation mse 1.0091092586517334\n",
      "Train Epoch 268.7 var loss 72163.3671875 reconstruction mse 72160.453125 imputation mse 1.008870244026184\n",
      "Train Epoch 268.8 var loss 72156.0703125 reconstruction mse 72153.1875 imputation mse 1.0087686777114868\n",
      "Train Epoch 268.9 var loss 72153.296875 reconstruction mse 72150.4375 imputation mse 1.008730173110962\n",
      "Train Epoch 269.0 var loss 71271.5234375 reconstruction mse 71267.8515625 imputation mse 0.9988486766815186\n",
      "Train Epoch 269.1 var loss 71303.90625 reconstruction mse 71300.8671875 imputation mse 0.9993113875389099\n",
      "Train Epoch 269.2 var loss 71277.8359375 reconstruction mse 71274.7265625 imputation mse 0.9989449977874756\n",
      "Train Epoch 269.3 var loss 71270.765625 reconstruction mse 71267.6328125 imputation mse 0.9988455772399902\n",
      "Train Epoch 269.4 var loss 71260.4921875 reconstruction mse 71257.40625 imputation mse 0.9987022876739502\n",
      "Train Epoch 269.5 var loss 71287.2421875 reconstruction mse 71284.2578125 imputation mse 0.9990785717964172\n",
      "Train Epoch 269.6 var loss 71290.34375 reconstruction mse 71287.4609375 imputation mse 0.9991235136985779\n",
      "Train Epoch 269.7 var loss 71263.7421875 reconstruction mse 71260.90625 imputation mse 0.9987513422966003\n",
      "Train Epoch 269.8 var loss 71270.6484375 reconstruction mse 71267.84375 imputation mse 0.998848557472229\n",
      "Train Epoch 269.9 var loss 71225.9609375 reconstruction mse 71223.15625 imputation mse 0.9982222318649292\n",
      "Train Epoch 270.0 var loss 72079.265625 reconstruction mse 72075.609375 imputation mse 1.0051825046539307\n",
      "Train Epoch 270.1 var loss 72128.6484375 reconstruction mse 72125.640625 imputation mse 1.0058802366256714\n",
      "Train Epoch 270.2 var loss 72126.125 reconstruction mse 72122.9921875 imputation mse 1.0058434009552002\n",
      "Train Epoch 270.3 var loss 72107.7421875 reconstruction mse 72104.609375 imputation mse 1.0055869817733765\n",
      "Train Epoch 270.4 var loss 72122.2734375 reconstruction mse 72119.1953125 imputation mse 1.00579035282135\n",
      "Train Epoch 270.5 var loss 72085.3359375 reconstruction mse 72082.359375 imputation mse 1.0052766799926758\n",
      "Train Epoch 270.6 var loss 72171.1484375 reconstruction mse 72168.2890625 imputation mse 1.0064750909805298\n",
      "Train Epoch 270.7 var loss 72100.8203125 reconstruction mse 72098.0390625 imputation mse 1.005495309829712\n",
      "Train Epoch 270.8 var loss 72124.5390625 reconstruction mse 72121.7578125 imputation mse 1.0058261156082153\n",
      "Train Epoch 270.9 var loss 72071.4453125 reconstruction mse 72068.625 imputation mse 1.0050851106643677\n",
      "====> Test imputation mse: 0.99817789\n",
      "====> Test imputation mse: 1.01979375\n",
      "====> Test imputation mse: 0.98915571\n",
      "Train Epoch 271.0 var loss 71623.96875 reconstruction mse 71620.3125 imputation mse 0.9989164471626282\n",
      "Train Epoch 271.1 var loss 71685.515625 reconstruction mse 71682.421875 imputation mse 0.9997827410697937\n",
      "Train Epoch 271.2 var loss 71652.96875 reconstruction mse 71649.7421875 imputation mse 0.9993269443511963\n",
      "Train Epoch 271.3 var loss 71665.2109375 reconstruction mse 71661.953125 imputation mse 0.9994972348213196\n",
      "Train Epoch 271.4 var loss 71657.3125 reconstruction mse 71654.1171875 imputation mse 0.9993879199028015\n",
      "Train Epoch 271.5 var loss 71630.7734375 reconstruction mse 71627.6953125 imputation mse 0.9990194439888\n",
      "Train Epoch 271.6 var loss 71619.4765625 reconstruction mse 71616.515625 imputation mse 0.9988635182380676\n",
      "Train Epoch 271.7 var loss 71584.3828125 reconstruction mse 71581.5 imputation mse 0.9983751177787781\n",
      "Train Epoch 271.8 var loss 71615.6171875 reconstruction mse 71612.78125 imputation mse 0.9988114237785339\n",
      "Train Epoch 271.9 var loss 71615.3984375 reconstruction mse 71612.546875 imputation mse 0.9988081455230713\n",
      "Train Epoch 272.0 var loss 70861.6171875 reconstruction mse 70857.9453125 imputation mse 0.9957132935523987\n",
      "Train Epoch 272.1 var loss 70834.0859375 reconstruction mse 70831.0 imputation mse 0.9953346252441406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 272.2 var loss 70834.90625 reconstruction mse 70831.6953125 imputation mse 0.9953444004058838\n",
      "Train Epoch 272.3 var loss 70843.984375 reconstruction mse 70840.765625 imputation mse 0.9954718947410583\n",
      "Train Epoch 272.4 var loss 70787.3984375 reconstruction mse 70784.2421875 imputation mse 0.9946776032447815\n",
      "Train Epoch 272.5 var loss 70834.6796875 reconstruction mse 70831.65625 imputation mse 0.9953438639640808\n",
      "Train Epoch 272.6 var loss 70837.7421875 reconstruction mse 70834.828125 imputation mse 0.9953884482383728\n",
      "Train Epoch 272.7 var loss 70840.4140625 reconstruction mse 70837.5703125 imputation mse 0.9954269528388977\n",
      "Train Epoch 272.8 var loss 70796.9140625 reconstruction mse 70794.1015625 imputation mse 0.9948161244392395\n",
      "Train Epoch 272.9 var loss 70793.6953125 reconstruction mse 70790.8515625 imputation mse 0.9947704672813416\n",
      "Train Epoch 273.0 var loss 71356.90625 reconstruction mse 71353.2421875 imputation mse 0.9976544380187988\n",
      "Train Epoch 273.1 var loss 71333.9296875 reconstruction mse 71330.8671875 imputation mse 0.9973415732383728\n",
      "Train Epoch 273.2 var loss 71309.21875 reconstruction mse 71306.0703125 imputation mse 0.9969948530197144\n",
      "Train Epoch 273.3 var loss 71341.953125 reconstruction mse 71338.8046875 imputation mse 0.9974525570869446\n",
      "Train Epoch 273.4 var loss 71337.3125 reconstruction mse 71334.25 imputation mse 0.9973888993263245\n",
      "Train Epoch 273.5 var loss 71309.03125 reconstruction mse 71306.078125 imputation mse 0.9969949722290039\n",
      "Train Epoch 273.6 var loss 71328.296875 reconstruction mse 71325.421875 imputation mse 0.9972654581069946\n",
      "Train Epoch 273.7 var loss 71361.2265625 reconstruction mse 71358.40625 imputation mse 0.9977266192436218\n",
      "Train Epoch 273.8 var loss 71342.703125 reconstruction mse 71339.890625 imputation mse 0.9974677562713623\n",
      "Train Epoch 273.9 var loss 71331.375 reconstruction mse 71328.578125 imputation mse 0.9973095655441284\n",
      "Train Epoch 274.0 var loss 71404.4375 reconstruction mse 71400.8671875 imputation mse 0.9990326762199402\n",
      "Train Epoch 274.1 var loss 71436.625 reconstruction mse 71433.5859375 imputation mse 0.99949049949646\n",
      "Train Epoch 274.2 var loss 71417.4609375 reconstruction mse 71414.3203125 imputation mse 0.9992209076881409\n",
      "Train Epoch 274.3 var loss 71380.78125 reconstruction mse 71377.6171875 imputation mse 0.9987074136734009\n",
      "Train Epoch 274.4 var loss 71435.9453125 reconstruction mse 71432.8359375 imputation mse 0.9994800090789795\n",
      "Train Epoch 274.5 var loss 71426.53125 reconstruction mse 71423.5390625 imputation mse 0.9993499517440796\n",
      "Train Epoch 274.6 var loss 71434.2890625 reconstruction mse 71431.40625 imputation mse 0.999459981918335\n",
      "Train Epoch 274.7 var loss 71402.7734375 reconstruction mse 71399.96875 imputation mse 0.9990201592445374\n",
      "Train Epoch 274.8 var loss 71387.4140625 reconstruction mse 71384.625 imputation mse 0.9988054633140564\n",
      "Train Epoch 274.9 var loss 71421.3046875 reconstruction mse 71418.4765625 imputation mse 0.9992790818214417\n",
      "Train Epoch 275.0 var loss 71663.4453125 reconstruction mse 71659.84375 imputation mse 0.9967153072357178\n",
      "Train Epoch 275.1 var loss 71711.671875 reconstruction mse 71708.546875 imputation mse 0.9973927140235901\n",
      "Train Epoch 275.2 var loss 71697.84375 reconstruction mse 71694.5703125 imputation mse 0.9971983432769775\n",
      "Train Epoch 275.3 var loss 71709.125 reconstruction mse 71705.8203125 imputation mse 0.9973548054695129\n",
      "Train Epoch 275.4 var loss 71681.5 reconstruction mse 71678.234375 imputation mse 0.9969711303710938\n",
      "Train Epoch 275.5 var loss 71720.65625 reconstruction mse 71717.5 imputation mse 0.9975172281265259\n",
      "Train Epoch 275.6 var loss 71674.921875 reconstruction mse 71671.8984375 imputation mse 0.996882975101471\n",
      "Train Epoch 275.7 var loss 71649.328125 reconstruction mse 71646.375 imputation mse 0.9965279698371887\n",
      "Train Epoch 275.8 var loss 71689.1953125 reconstruction mse 71686.2890625 imputation mse 0.9970831274986267\n",
      "Train Epoch 275.9 var loss 71678.03125 reconstruction mse 71675.1484375 imputation mse 0.9969281554222107\n",
      "Train Epoch 276.0 var loss 72104.5859375 reconstruction mse 72101.0078125 imputation mse 1.0043182373046875\n",
      "Train Epoch 276.1 var loss 72078.4921875 reconstruction mse 72075.4453125 imputation mse 1.0039621591567993\n",
      "Train Epoch 276.2 var loss 72124.5078125 reconstruction mse 72121.3671875 imputation mse 1.0046018362045288\n",
      "Train Epoch 276.3 var loss 72034.2578125 reconstruction mse 72031.078125 imputation mse 1.003344178199768\n",
      "Train Epoch 276.4 var loss 72096.578125 reconstruction mse 72093.453125 imputation mse 1.0042129755020142\n",
      "Train Epoch 276.5 var loss 72121.1328125 reconstruction mse 72118.078125 imputation mse 1.0045559406280518\n",
      "Train Epoch 276.6 var loss 72091.1875 reconstruction mse 72088.2265625 imputation mse 1.0041401386260986\n",
      "Train Epoch 276.7 var loss 72080.921875 reconstruction mse 72078.0078125 imputation mse 1.003997802734375\n",
      "Train Epoch 276.8 var loss 72111.1171875 reconstruction mse 72108.234375 imputation mse 1.0044188499450684\n",
      "Train Epoch 276.9 var loss 72092.828125 reconstruction mse 72089.9296875 imputation mse 1.0041638612747192\n",
      "Train Epoch 277.0 var loss 72188.921875 reconstruction mse 72185.34375 imputation mse 1.001211404800415\n",
      "Train Epoch 277.1 var loss 72231.8359375 reconstruction mse 72228.71875 imputation mse 1.0018130540847778\n",
      "Train Epoch 277.2 var loss 72214.7265625 reconstruction mse 72211.5390625 imputation mse 1.0015747547149658\n",
      "Train Epoch 277.3 var loss 72225.25 reconstruction mse 72222.1015625 imputation mse 1.0017212629318237\n",
      "Train Epoch 277.4 var loss 72173.203125 reconstruction mse 72170.140625 imputation mse 1.0010006427764893\n",
      "Train Epoch 277.5 var loss 72167.2421875 reconstruction mse 72164.28125 imputation mse 1.0009193420410156\n",
      "Train Epoch 277.6 var loss 72191.453125 reconstruction mse 72188.5625 imputation mse 1.0012561082839966\n",
      "Train Epoch 277.7 var loss 72199.140625 reconstruction mse 72196.2578125 imputation mse 1.0013628005981445\n",
      "Train Epoch 277.8 var loss 72189.609375 reconstruction mse 72186.703125 imputation mse 1.0012303590774536\n",
      "Train Epoch 277.9 var loss 72204.2109375 reconstruction mse 72201.25 imputation mse 1.0014320611953735\n",
      "Train Epoch 278.0 var loss 72442.546875 reconstruction mse 72438.953125 imputation mse 1.0065299272537231\n",
      "Train Epoch 278.1 var loss 72463.90625 reconstruction mse 72460.734375 imputation mse 1.0068325996398926\n",
      "Train Epoch 278.2 var loss 72491.9921875 reconstruction mse 72488.734375 imputation mse 1.0072216987609863\n",
      "Train Epoch 278.3 var loss 72449.625 reconstruction mse 72446.3671875 imputation mse 1.006632924079895\n",
      "Train Epoch 278.4 var loss 72474.78125 reconstruction mse 72471.6484375 imputation mse 1.0069842338562012\n",
      "Train Epoch 278.5 var loss 72475.46875 reconstruction mse 72472.4375 imputation mse 1.0069952011108398\n",
      "Train Epoch 278.6 var loss 72477.3828125 reconstruction mse 72474.4140625 imputation mse 1.0070226192474365\n",
      "Train Epoch 278.7 var loss 72460.0546875 reconstruction mse 72457.1171875 imputation mse 1.0067822933197021\n",
      "Train Epoch 278.8 var loss 72445.5234375 reconstruction mse 72442.5625 imputation mse 1.006580114364624\n",
      "Train Epoch 278.9 var loss 72405.8046875 reconstruction mse 72402.8359375 imputation mse 1.0060280561447144\n",
      "Train Epoch 279.0 var loss 71315.203125 reconstruction mse 71311.65625 imputation mse 1.0005704164505005\n",
      "Train Epoch 279.1 var loss 71323.109375 reconstruction mse 71319.921875 imputation mse 1.0006864070892334\n",
      "Train Epoch 279.2 var loss 71290.1015625 reconstruction mse 71286.84375 imputation mse 1.0002223253250122\n",
      "Train Epoch 279.3 var loss 71301.3984375 reconstruction mse 71298.15625 imputation mse 1.0003809928894043\n",
      "Train Epoch 279.4 var loss 71320.8359375 reconstruction mse 71317.6953125 imputation mse 1.000655174255371\n",
      "Train Epoch 279.5 var loss 71339.03125 reconstruction mse 71336.0234375 imputation mse 1.0009123086929321\n",
      "Train Epoch 279.6 var loss 71327.75 reconstruction mse 71324.859375 imputation mse 1.0007556676864624\n",
      "Train Epoch 279.7 var loss 71307.8515625 reconstruction mse 71305.03125 imputation mse 1.0004774332046509\n",
      "Train Epoch 279.8 var loss 71326.6640625 reconstruction mse 71323.859375 imputation mse 1.000741720199585\n",
      "Train Epoch 279.9 var loss 71337.1875 reconstruction mse 71334.34375 imputation mse 1.0008888244628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 280.0 var loss 71775.546875 reconstruction mse 71772.046875 imputation mse 1.0031594038009644\n",
      "Train Epoch 280.1 var loss 71764.7109375 reconstruction mse 71761.6328125 imputation mse 1.0030138492584229\n",
      "Train Epoch 280.2 var loss 71738.7109375 reconstruction mse 71735.5234375 imputation mse 1.002648949623108\n",
      "Train Epoch 280.3 var loss 71772.703125 reconstruction mse 71769.5390625 imputation mse 1.0031243562698364\n",
      "Train Epoch 280.4 var loss 71773.5546875 reconstruction mse 71770.4453125 imputation mse 1.0031371116638184\n",
      "Train Epoch 280.5 var loss 71751.53125 reconstruction mse 71748.4921875 imputation mse 1.0028302669525146\n",
      "Train Epoch 280.6 var loss 71760.5390625 reconstruction mse 71757.5859375 imputation mse 1.0029573440551758\n",
      "Train Epoch 280.7 var loss 71772.7578125 reconstruction mse 71769.8671875 imputation mse 1.003129005432129\n",
      "Train Epoch 280.8 var loss 71762.890625 reconstruction mse 71760.015625 imputation mse 1.0029913187026978\n",
      "Train Epoch 280.9 var loss 71780.9921875 reconstruction mse 71778.1015625 imputation mse 1.0032440423965454\n",
      "====> Test imputation mse: 1.00219381\n",
      "====> Test imputation mse: 0.98613739\n",
      "====> Test imputation mse: 0.99205166\n",
      "Train Epoch 281.0 var loss 71521.203125 reconstruction mse 71517.65625 imputation mse 0.999380350112915\n",
      "Train Epoch 281.1 var loss 71518.875 reconstruction mse 71515.71875 imputation mse 0.999353289604187\n",
      "Train Epoch 281.2 var loss 71530.7109375 reconstruction mse 71527.4296875 imputation mse 0.9995169043540955\n",
      "Train Epoch 281.3 var loss 71535.0546875 reconstruction mse 71531.7421875 imputation mse 0.9995771646499634\n",
      "Train Epoch 281.4 var loss 71520.1484375 reconstruction mse 71516.9140625 imputation mse 0.9993699789047241\n",
      "Train Epoch 281.5 var loss 71549.640625 reconstruction mse 71546.546875 imputation mse 0.9997840523719788\n",
      "Train Epoch 281.6 var loss 71515.4609375 reconstruction mse 71512.4609375 imputation mse 0.9993077516555786\n",
      "Train Epoch 281.7 var loss 71527.359375 reconstruction mse 71524.40625 imputation mse 0.9994746446609497\n",
      "Train Epoch 281.8 var loss 71532.84375 reconstruction mse 71529.90625 imputation mse 0.99955153465271\n",
      "Train Epoch 281.9 var loss 71509.28125 reconstruction mse 71506.3203125 imputation mse 0.999221920967102\n",
      "Train Epoch 282.0 var loss 70968.3984375 reconstruction mse 70964.828125 imputation mse 0.9911150336265564\n",
      "Train Epoch 282.1 var loss 70953.46875 reconstruction mse 70950.3203125 imputation mse 0.9909124374389648\n",
      "Train Epoch 282.2 var loss 70973.359375 reconstruction mse 70970.1484375 imputation mse 0.9911893606185913\n",
      "Train Epoch 282.3 var loss 71002.53125 reconstruction mse 70999.3984375 imputation mse 0.9915978312492371\n",
      "Train Epoch 282.4 var loss 70989.359375 reconstruction mse 70986.3515625 imputation mse 0.9914156198501587\n",
      "Train Epoch 282.5 var loss 70976.3125 reconstruction mse 70973.453125 imputation mse 0.9912354946136475\n",
      "Train Epoch 282.6 var loss 71003.8671875 reconstruction mse 71001.078125 imputation mse 0.9916213154792786\n",
      "Train Epoch 282.7 var loss 70968.15625 reconstruction mse 70965.3828125 imputation mse 0.9911227822303772\n",
      "Train Epoch 282.8 var loss 71013.9140625 reconstruction mse 71011.0703125 imputation mse 0.9917608499526978\n",
      "Train Epoch 282.9 var loss 70955.421875 reconstruction mse 70952.5 imputation mse 0.9909428358078003\n",
      "Train Epoch 283.0 var loss 72105.1171875 reconstruction mse 72101.59375 imputation mse 1.0091619491577148\n",
      "Train Epoch 283.1 var loss 72106.7109375 reconstruction mse 72103.546875 imputation mse 1.009189248085022\n",
      "Train Epoch 283.2 var loss 72113.8671875 reconstruction mse 72110.6171875 imputation mse 1.0092881917953491\n",
      "Train Epoch 283.3 var loss 72089.1875 reconstruction mse 72085.984375 imputation mse 1.0089434385299683\n",
      "Train Epoch 283.4 var loss 72083.640625 reconstruction mse 72080.5234375 imputation mse 1.0088670253753662\n",
      "Train Epoch 283.5 var loss 72091.609375 reconstruction mse 72088.5859375 imputation mse 1.0089799165725708\n",
      "Train Epoch 283.6 var loss 72109.578125 reconstruction mse 72106.6484375 imputation mse 1.0092326402664185\n",
      "Train Epoch 283.7 var loss 72154.9140625 reconstruction mse 72152.03125 imputation mse 1.0098679065704346\n",
      "Train Epoch 283.8 var loss 72124.96875 reconstruction mse 72122.0625 imputation mse 1.0094484090805054\n",
      "Train Epoch 283.9 var loss 72110.5 reconstruction mse 72107.5546875 imputation mse 1.0092453956604004\n",
      "Train Epoch 284.0 var loss 71525.5078125 reconstruction mse 71522.0 imputation mse 1.0080478191375732\n",
      "Train Epoch 284.1 var loss 71510.1328125 reconstruction mse 71506.9453125 imputation mse 1.0078356266021729\n",
      "Train Epoch 284.2 var loss 71502.625 reconstruction mse 71499.359375 imputation mse 1.0077286958694458\n",
      "Train Epoch 284.3 var loss 71489.4375 reconstruction mse 71486.1796875 imputation mse 1.0075429677963257\n",
      "Train Epoch 284.4 var loss 71544.515625 reconstruction mse 71541.34375 imputation mse 1.0083204507827759\n",
      "Train Epoch 284.5 var loss 71530.515625 reconstruction mse 71527.4375 imputation mse 1.0081244707107544\n",
      "Train Epoch 284.6 var loss 71508.484375 reconstruction mse 71505.5 imputation mse 1.0078152418136597\n",
      "Train Epoch 284.7 var loss 71509.015625 reconstruction mse 71506.1015625 imputation mse 1.0078237056732178\n",
      "Train Epoch 284.8 var loss 71510.0390625 reconstruction mse 71507.1328125 imputation mse 1.007838249206543\n",
      "Train Epoch 284.9 var loss 71484.0390625 reconstruction mse 71481.1171875 imputation mse 1.0074715614318848\n",
      "Train Epoch 285.0 var loss 71216.75 reconstruction mse 71213.265625 imputation mse 0.997147262096405\n",
      "Train Epoch 285.1 var loss 71216.1640625 reconstruction mse 71213.015625 imputation mse 0.9971437454223633\n",
      "Train Epoch 285.2 var loss 71217.078125 reconstruction mse 71213.859375 imputation mse 0.9971555471420288\n",
      "Train Epoch 285.3 var loss 71223.484375 reconstruction mse 71220.28125 imputation mse 0.9972454905509949\n",
      "Train Epoch 285.4 var loss 71206.3125 reconstruction mse 71203.1796875 imputation mse 0.9970060586929321\n",
      "Train Epoch 285.5 var loss 71208.8984375 reconstruction mse 71205.875 imputation mse 0.997043788433075\n",
      "Train Epoch 285.6 var loss 71241.78125 reconstruction mse 71238.8671875 imputation mse 0.9975057244300842\n",
      "Train Epoch 285.7 var loss 71182.296875 reconstruction mse 71179.4609375 imputation mse 0.9966739416122437\n",
      "Train Epoch 285.8 var loss 71198.8359375 reconstruction mse 71196.0234375 imputation mse 0.9969058036804199\n",
      "Train Epoch 285.9 var loss 71181.5234375 reconstruction mse 71178.6796875 imputation mse 0.996662974357605\n",
      "Train Epoch 286.0 var loss 71749.7109375 reconstruction mse 71746.3125 imputation mse 1.00152587890625\n",
      "Train Epoch 286.1 var loss 71733.359375 reconstruction mse 71730.2421875 imputation mse 1.001301646232605\n",
      "Train Epoch 286.2 var loss 71782.234375 reconstruction mse 71779.015625 imputation mse 1.0019824504852295\n",
      "Train Epoch 286.3 var loss 71732.4375 reconstruction mse 71729.203125 imputation mse 1.0012871026992798\n",
      "Train Epoch 286.4 var loss 71732.25 reconstruction mse 71729.1015625 imputation mse 1.0012856721878052\n",
      "Train Epoch 286.5 var loss 71714.6640625 reconstruction mse 71711.65625 imputation mse 1.001042127609253\n",
      "Train Epoch 286.6 var loss 71745.2109375 reconstruction mse 71742.3203125 imputation mse 1.0014702081680298\n",
      "Train Epoch 286.7 var loss 71750.359375 reconstruction mse 71747.5390625 imputation mse 1.0015430450439453\n",
      "Train Epoch 286.8 var loss 71730.7734375 reconstruction mse 71727.9453125 imputation mse 1.0012695789337158\n",
      "Train Epoch 286.9 var loss 71714.53125 reconstruction mse 71711.6640625 imputation mse 1.0010422468185425\n",
      "Train Epoch 287.0 var loss 72103.484375 reconstruction mse 72100.03125 imputation mse 1.0042766332626343\n",
      "Train Epoch 287.1 var loss 72100.703125 reconstruction mse 72097.609375 imputation mse 1.0042428970336914\n",
      "Train Epoch 287.2 var loss 72096.484375 reconstruction mse 72093.3046875 imputation mse 1.0041829347610474\n",
      "Train Epoch 287.3 var loss 72057.0703125 reconstruction mse 72053.890625 imputation mse 1.003633975982666\n",
      "Train Epoch 287.4 var loss 72114.5703125 reconstruction mse 72111.484375 imputation mse 1.0044361352920532\n",
      "Train Epoch 287.5 var loss 72111.0390625 reconstruction mse 72108.03125 imputation mse 1.0043880939483643\n",
      "Train Epoch 287.6 var loss 72087.796875 reconstruction mse 72084.875 imputation mse 1.0040655136108398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 287.7 var loss 72082.265625 reconstruction mse 72079.375 imputation mse 1.0039888620376587\n",
      "Train Epoch 287.8 var loss 72055.3359375 reconstruction mse 72052.4375 imputation mse 1.0036137104034424\n",
      "Train Epoch 287.9 var loss 72071.8203125 reconstruction mse 72068.9296875 imputation mse 1.0038434267044067\n",
      "Train Epoch 288.0 var loss 72086.3671875 reconstruction mse 72082.90625 imputation mse 1.0064634084701538\n",
      "Train Epoch 288.1 var loss 72073.6328125 reconstruction mse 72070.53125 imputation mse 1.0062905550003052\n",
      "Train Epoch 288.2 var loss 72060.3828125 reconstruction mse 72057.15625 imputation mse 1.0061038732528687\n",
      "Train Epoch 288.3 var loss 72074.5625 reconstruction mse 72071.3515625 imputation mse 1.006301999092102\n",
      "Train Epoch 288.4 var loss 72028.4609375 reconstruction mse 72025.328125 imputation mse 1.0056594610214233\n",
      "Train Epoch 288.5 var loss 72067.2265625 reconstruction mse 72064.2421875 imputation mse 1.0062028169631958\n",
      "Train Epoch 288.6 var loss 72083.203125 reconstruction mse 72080.3125 imputation mse 1.0064271688461304\n",
      "Train Epoch 288.7 var loss 72055.125 reconstruction mse 72052.2890625 imputation mse 1.0060359239578247\n",
      "Train Epoch 288.8 var loss 72053.8203125 reconstruction mse 72050.9609375 imputation mse 1.0060173273086548\n",
      "Train Epoch 288.9 var loss 72064.8359375 reconstruction mse 72061.9296875 imputation mse 1.0061705112457275\n",
      "Train Epoch 289.0 var loss 71704.125 reconstruction mse 71700.6640625 imputation mse 0.9997164607048035\n",
      "Train Epoch 289.1 var loss 71666.5234375 reconstruction mse 71663.3671875 imputation mse 0.9991964101791382\n",
      "Train Epoch 289.2 var loss 71710.90625 reconstruction mse 71707.640625 imputation mse 0.9998137354850769\n",
      "Train Epoch 289.3 var loss 71656.9921875 reconstruction mse 71653.7109375 imputation mse 0.9990618228912354\n",
      "Train Epoch 289.4 var loss 71740.015625 reconstruction mse 71736.8046875 imputation mse 1.0002204179763794\n",
      "Train Epoch 289.5 var loss 71685.4140625 reconstruction mse 71682.3203125 imputation mse 0.9994606971740723\n",
      "Train Epoch 289.6 var loss 71676.0234375 reconstruction mse 71673.03125 imputation mse 0.9993311762809753\n",
      "Train Epoch 289.7 var loss 71674.7421875 reconstruction mse 71671.84375 imputation mse 0.9993146061897278\n",
      "Train Epoch 289.8 var loss 71648.640625 reconstruction mse 71645.7890625 imputation mse 0.9989513158798218\n",
      "Train Epoch 289.9 var loss 71693.8359375 reconstruction mse 71690.9921875 imputation mse 0.9995815753936768\n",
      "Train Epoch 290.0 var loss 71454.6015625 reconstruction mse 71451.1796875 imputation mse 0.9984235167503357\n",
      "Train Epoch 290.1 var loss 71440.953125 reconstruction mse 71437.90625 imputation mse 0.9982380270957947\n",
      "Train Epoch 290.2 var loss 71467.03125 reconstruction mse 71463.8828125 imputation mse 0.9986010193824768\n",
      "Train Epoch 290.3 var loss 71451.5546875 reconstruction mse 71448.3984375 imputation mse 0.9983846545219421\n",
      "Train Epoch 290.4 var loss 71451.3515625 reconstruction mse 71448.2578125 imputation mse 0.9983826875686646\n",
      "Train Epoch 290.5 var loss 71468.546875 reconstruction mse 71465.5625 imputation mse 0.9986245036125183\n",
      "Train Epoch 290.6 var loss 71480.15625 reconstruction mse 71477.2578125 imputation mse 0.9987878799438477\n",
      "Train Epoch 290.7 var loss 71435.265625 reconstruction mse 71432.421875 imputation mse 0.9981613755226135\n",
      "Train Epoch 290.8 var loss 71444.78125 reconstruction mse 71441.9375 imputation mse 0.9982943534851074\n",
      "Train Epoch 290.9 var loss 71466.609375 reconstruction mse 71463.75 imputation mse 0.9985991716384888\n",
      "====> Test imputation mse: 0.99065250\n",
      "====> Test imputation mse: 0.99913371\n",
      "====> Test imputation mse: 1.00490558\n",
      "Train Epoch 291.0 var loss 71779.7578125 reconstruction mse 71776.3359375 imputation mse 1.0073589086532593\n",
      "Train Epoch 291.1 var loss 71780.875 reconstruction mse 71777.796875 imputation mse 1.007379412651062\n",
      "Train Epoch 291.2 var loss 71747.8125 reconstruction mse 71744.640625 imputation mse 1.0069140195846558\n",
      "Train Epoch 291.3 var loss 71766.4453125 reconstruction mse 71763.2421875 imputation mse 1.007175087928772\n",
      "Train Epoch 291.4 var loss 71790.9765625 reconstruction mse 71787.859375 imputation mse 1.0075206756591797\n",
      "Train Epoch 291.5 var loss 71756.921875 reconstruction mse 71753.9140625 imputation mse 1.0070441961288452\n",
      "Train Epoch 291.6 var loss 71744.1328125 reconstruction mse 71741.234375 imputation mse 1.006866216659546\n",
      "Train Epoch 291.7 var loss 71751.7265625 reconstruction mse 71748.90625 imputation mse 1.0069739818572998\n",
      "Train Epoch 291.8 var loss 71803.03125 reconstruction mse 71800.203125 imputation mse 1.007693886756897\n",
      "Train Epoch 291.9 var loss 71762.875 reconstruction mse 71760.046875 imputation mse 1.0071302652359009\n",
      "Train Epoch 292.0 var loss 72861.5390625 reconstruction mse 72858.1484375 imputation mse 1.0143277645111084\n",
      "Train Epoch 292.1 var loss 72887.9375 reconstruction mse 72884.859375 imputation mse 1.0146995782852173\n",
      "Train Epoch 292.2 var loss 72846.15625 reconstruction mse 72842.9921875 imputation mse 1.0141167640686035\n",
      "Train Epoch 292.3 var loss 72868.234375 reconstruction mse 72865.078125 imputation mse 1.014424204826355\n",
      "Train Epoch 292.4 var loss 72855.03125 reconstruction mse 72851.9609375 imputation mse 1.0142415761947632\n",
      "Train Epoch 292.5 var loss 72813.7890625 reconstruction mse 72810.8125 imputation mse 1.0136687755584717\n",
      "Train Epoch 292.6 var loss 72836.4609375 reconstruction mse 72833.546875 imputation mse 1.013985276222229\n",
      "Train Epoch 292.7 var loss 72867.609375 reconstruction mse 72864.7265625 imputation mse 1.0144193172454834\n",
      "Train Epoch 292.8 var loss 72850.71875 reconstruction mse 72847.828125 imputation mse 1.0141841173171997\n",
      "Train Epoch 292.9 var loss 72844.921875 reconstruction mse 72842.03125 imputation mse 1.0141034126281738\n",
      "Train Epoch 293.0 var loss 72000.4140625 reconstruction mse 71997.015625 imputation mse 1.0038484334945679\n",
      "Train Epoch 293.1 var loss 71995.1484375 reconstruction mse 71992.0625 imputation mse 1.003779411315918\n",
      "Train Epoch 293.2 var loss 72021.6328125 reconstruction mse 72018.453125 imputation mse 1.0041474103927612\n",
      "Train Epoch 293.3 var loss 72014.09375 reconstruction mse 72010.9453125 imputation mse 1.004042625427246\n",
      "Train Epoch 293.4 var loss 72035.859375 reconstruction mse 72032.7890625 imputation mse 1.0043472051620483\n",
      "Train Epoch 293.5 var loss 72016.8828125 reconstruction mse 72013.9296875 imputation mse 1.0040843486785889\n",
      "Train Epoch 293.6 var loss 72039.5234375 reconstruction mse 72036.6875 imputation mse 1.0044015645980835\n",
      "Train Epoch 293.7 var loss 72034.140625 reconstruction mse 72031.34375 imputation mse 1.0043270587921143\n",
      "Train Epoch 293.8 var loss 71982.1171875 reconstruction mse 71979.3125 imputation mse 1.0036016702651978\n",
      "Train Epoch 293.9 var loss 72028.484375 reconstruction mse 72025.6328125 imputation mse 1.0042474269866943\n",
      "Train Epoch 294.0 var loss 71091.234375 reconstruction mse 71087.8359375 imputation mse 0.9998710751533508\n",
      "Train Epoch 294.1 var loss 71079.484375 reconstruction mse 71076.3828125 imputation mse 0.9997100234031677\n",
      "Train Epoch 294.2 var loss 71070.03125 reconstruction mse 71066.859375 imputation mse 0.9995760917663574\n",
      "Train Epoch 294.3 var loss 71114.984375 reconstruction mse 71111.7890625 imputation mse 1.0002080202102661\n",
      "Train Epoch 294.4 var loss 71069.140625 reconstruction mse 71066.03125 imputation mse 0.9995644092559814\n",
      "Train Epoch 294.5 var loss 71094.3046875 reconstruction mse 71091.34375 imputation mse 0.9999204277992249\n",
      "Train Epoch 294.6 var loss 71096.8828125 reconstruction mse 71094.046875 imputation mse 0.9999584555625916\n",
      "Train Epoch 294.7 var loss 71088.9765625 reconstruction mse 71086.21875 imputation mse 0.9998483657836914\n",
      "Train Epoch 294.8 var loss 71097.3828125 reconstruction mse 71094.671875 imputation mse 0.9999672770500183\n",
      "Train Epoch 294.9 var loss 71147.0703125 reconstruction mse 71144.34375 imputation mse 1.0006659030914307\n",
      "Train Epoch 295.0 var loss 71693.4921875 reconstruction mse 71690.140625 imputation mse 1.0019166469573975\n",
      "Train Epoch 295.1 var loss 71660.296875 reconstruction mse 71657.234375 imputation mse 1.0014567375183105\n",
      "Train Epoch 295.2 var loss 71702.3046875 reconstruction mse 71699.1015625 imputation mse 1.0020418167114258\n",
      "Train Epoch 295.3 var loss 71677.46875 reconstruction mse 71674.21875 imputation mse 1.0016940832138062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 295.4 var loss 71692.2265625 reconstruction mse 71689.0625 imputation mse 1.0019015073776245\n",
      "Train Epoch 295.5 var loss 71672.7890625 reconstruction mse 71669.796875 imputation mse 1.0016323328018188\n",
      "Train Epoch 295.6 var loss 71694.125 reconstruction mse 71691.2890625 imputation mse 1.0019326210021973\n",
      "Train Epoch 295.7 var loss 71677.7265625 reconstruction mse 71674.984375 imputation mse 1.0017048120498657\n",
      "Train Epoch 295.8 var loss 71708.9765625 reconstruction mse 71706.265625 imputation mse 1.0021419525146484\n",
      "Train Epoch 295.9 var loss 71692.46875 reconstruction mse 71689.71875 imputation mse 1.00191068649292\n",
      "Train Epoch 296.0 var loss 71247.390625 reconstruction mse 71244.0703125 imputation mse 1.0043004751205444\n",
      "Train Epoch 296.1 var loss 71217.484375 reconstruction mse 71214.484375 imputation mse 1.0038833618164062\n",
      "Train Epoch 296.2 var loss 71226.4453125 reconstruction mse 71223.359375 imputation mse 1.0040085315704346\n",
      "Train Epoch 296.3 var loss 71199.8359375 reconstruction mse 71196.765625 imputation mse 1.0036336183547974\n",
      "Train Epoch 296.4 var loss 71216.453125 reconstruction mse 71213.4765625 imputation mse 1.0038691759109497\n",
      "Train Epoch 296.5 var loss 71218.9765625 reconstruction mse 71216.1171875 imputation mse 1.0039063692092896\n",
      "Train Epoch 296.6 var loss 71231.1796875 reconstruction mse 71228.40625 imputation mse 1.0040796995162964\n",
      "Train Epoch 296.7 var loss 71220.203125 reconstruction mse 71217.4609375 imputation mse 1.0039253234863281\n",
      "Train Epoch 296.8 var loss 71222.7890625 reconstruction mse 71220.03125 imputation mse 1.0039615631103516\n",
      "Train Epoch 296.9 var loss 71196.2265625 reconstruction mse 71193.46875 imputation mse 1.0035871267318726\n",
      "Train Epoch 297.0 var loss 71306.3359375 reconstruction mse 71303.0390625 imputation mse 1.0017566680908203\n",
      "Train Epoch 297.1 var loss 71293.859375 reconstruction mse 71290.96875 imputation mse 1.001587152481079\n",
      "Train Epoch 297.2 var loss 71301.1640625 reconstruction mse 71298.1875 imputation mse 1.0016885995864868\n",
      "Train Epoch 297.3 var loss 71296.5 reconstruction mse 71293.4921875 imputation mse 1.0016225576400757\n",
      "Train Epoch 297.4 var loss 71332.7109375 reconstruction mse 71329.7421875 imputation mse 1.0021318197250366\n",
      "Train Epoch 297.5 var loss 71283.625 reconstruction mse 71280.7421875 imputation mse 1.0014435052871704\n",
      "Train Epoch 297.6 var loss 71253.0625 reconstruction mse 71250.265625 imputation mse 1.001015305519104\n",
      "Train Epoch 297.7 var loss 71307.90625 reconstruction mse 71305.1796875 imputation mse 1.0017868280410767\n",
      "Train Epoch 297.8 var loss 71314.1328125 reconstruction mse 71311.4375 imputation mse 1.0018746852874756\n",
      "Train Epoch 297.9 var loss 71259.4375 reconstruction mse 71256.71875 imputation mse 1.0011059045791626\n",
      "Train Epoch 298.0 var loss 71854.84375 reconstruction mse 71851.546875 imputation mse 0.9989509582519531\n",
      "Train Epoch 298.1 var loss 71866.515625 reconstruction mse 71863.5390625 imputation mse 0.9991177320480347\n",
      "Train Epoch 298.2 var loss 71899.625 reconstruction mse 71896.5234375 imputation mse 0.9995762705802917\n",
      "Train Epoch 298.3 var loss 71860.203125 reconstruction mse 71857.109375 imputation mse 0.9990283250808716\n",
      "Train Epoch 298.4 var loss 71872.3515625 reconstruction mse 71869.296875 imputation mse 0.999197781085968\n",
      "Train Epoch 298.5 var loss 71849.453125 reconstruction mse 71846.5078125 imputation mse 0.998880922794342\n",
      "Train Epoch 298.6 var loss 71877.609375 reconstruction mse 71874.7734375 imputation mse 0.9992738962173462\n",
      "Train Epoch 298.7 var loss 71850.28125 reconstruction mse 71847.515625 imputation mse 0.9988949298858643\n",
      "Train Epoch 298.8 var loss 71847.0 reconstruction mse 71844.265625 imputation mse 0.9988497495651245\n",
      "Train Epoch 298.9 var loss 71838.6015625 reconstruction mse 71835.8515625 imputation mse 0.9987327456474304\n",
      "Train Epoch 299.0 var loss 71335.4765625 reconstruction mse 71332.1875 imputation mse 0.9930972456932068\n",
      "Train Epoch 299.1 var loss 71344.3828125 reconstruction mse 71341.375 imputation mse 0.9932251572608948\n",
      "Train Epoch 299.2 var loss 71308.0546875 reconstruction mse 71304.921875 imputation mse 0.9927176237106323\n",
      "Train Epoch 299.3 var loss 71313.3671875 reconstruction mse 71310.234375 imputation mse 0.9927915930747986\n",
      "Train Epoch 299.4 var loss 71337.890625 reconstruction mse 71334.8828125 imputation mse 0.9931347370147705\n",
      "Train Epoch 299.5 var loss 71327.125 reconstruction mse 71324.2265625 imputation mse 0.9929863810539246\n",
      "Train Epoch 299.6 var loss 71305.7734375 reconstruction mse 71302.9609375 imputation mse 0.9926903247833252\n",
      "Train Epoch 299.7 var loss 71351.0390625 reconstruction mse 71348.28125 imputation mse 0.9933212995529175\n",
      "Train Epoch 299.8 var loss 71331.671875 reconstruction mse 71328.8984375 imputation mse 0.9930514097213745\n",
      "Train Epoch 299.9 var loss 71375.75 reconstruction mse 71372.9296875 imputation mse 0.9936644434928894\n",
      "Train Epoch 300.0 var loss 71230.4921875 reconstruction mse 71227.2109375 imputation mse 0.9984189867973328\n",
      "Train Epoch 300.1 var loss 71166.1171875 reconstruction mse 71163.0703125 imputation mse 0.9975199103355408\n",
      "Train Epoch 300.2 var loss 71190.734375 reconstruction mse 71187.59375 imputation mse 0.9978636503219604\n",
      "Train Epoch 300.3 var loss 71205.4375 reconstruction mse 71202.3203125 imputation mse 0.9980701208114624\n",
      "Train Epoch 300.4 var loss 71203.2109375 reconstruction mse 71200.1953125 imputation mse 0.9980403184890747\n",
      "Train Epoch 300.5 var loss 71206.5078125 reconstruction mse 71203.609375 imputation mse 0.9980881810188293\n",
      "Train Epoch 300.6 var loss 71185.5859375 reconstruction mse 71182.8046875 imputation mse 0.9977965354919434\n",
      "Train Epoch 300.7 var loss 71227.875 reconstruction mse 71225.15625 imputation mse 0.9983901977539062\n",
      "Train Epoch 300.8 var loss 71225.921875 reconstruction mse 71223.203125 imputation mse 0.9983628392219543\n",
      "Train Epoch 300.9 var loss 71248.2578125 reconstruction mse 71245.5 imputation mse 0.9986753463745117\n",
      "====> Test imputation mse: 1.00834787\n",
      "====> Test imputation mse: 0.99784350\n",
      "====> Test imputation mse: 1.00296688\n",
      "Train Epoch 301.0 var loss 71794.734375 reconstruction mse 71791.46875 imputation mse 1.0049619674682617\n",
      "Train Epoch 301.1 var loss 71790.4375 reconstruction mse 71787.4296875 imputation mse 1.0049054622650146\n",
      "Train Epoch 301.2 var loss 71791.171875 reconstruction mse 71788.0703125 imputation mse 1.004914402961731\n",
      "Train Epoch 301.3 var loss 71778.9609375 reconstruction mse 71775.8671875 imputation mse 1.0047435760498047\n",
      "Train Epoch 301.4 var loss 71758.328125 reconstruction mse 71755.328125 imputation mse 1.0044560432434082\n",
      "Train Epoch 301.5 var loss 71766.78125 reconstruction mse 71763.8984375 imputation mse 1.0045760869979858\n",
      "Train Epoch 301.6 var loss 71772.5 reconstruction mse 71769.6953125 imputation mse 1.0046571493148804\n",
      "Train Epoch 301.7 var loss 71824.5234375 reconstruction mse 71821.7421875 imputation mse 1.0053857564926147\n",
      "Train Epoch 301.8 var loss 71799.578125 reconstruction mse 71796.7890625 imputation mse 1.005036473274231\n",
      "Train Epoch 301.9 var loss 71806.25 reconstruction mse 71803.4375 imputation mse 1.0051295757293701\n",
      "Train Epoch 302.0 var loss 72416.8359375 reconstruction mse 72413.5546875 imputation mse 1.0109107494354248\n",
      "Train Epoch 302.1 var loss 72407.625 reconstruction mse 72404.65625 imputation mse 1.0107864141464233\n",
      "Train Epoch 302.2 var loss 72425.5625 reconstruction mse 72422.5390625 imputation mse 1.0110361576080322\n",
      "Train Epoch 302.3 var loss 72399.875 reconstruction mse 72396.8828125 imputation mse 1.0106779336929321\n",
      "Train Epoch 302.4 var loss 72418.421875 reconstruction mse 72415.4921875 imputation mse 1.0109376907348633\n",
      "Train Epoch 302.5 var loss 72405.6015625 reconstruction mse 72402.7578125 imputation mse 1.010759949684143\n",
      "Train Epoch 302.6 var loss 72421.546875 reconstruction mse 72418.8046875 imputation mse 1.010983943939209\n",
      "Train Epoch 302.7 var loss 72377.9921875 reconstruction mse 72375.2734375 imputation mse 1.0103763341903687\n",
      "Train Epoch 302.8 var loss 72361.859375 reconstruction mse 72359.140625 imputation mse 1.0101510286331177\n",
      "Train Epoch 302.9 var loss 72386.9921875 reconstruction mse 72384.21875 imputation mse 1.0105011463165283\n",
      "Train Epoch 303.0 var loss 72316.03125 reconstruction mse 72312.7734375 imputation mse 1.0101807117462158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 303.1 var loss 72296.0 reconstruction mse 72292.953125 imputation mse 1.0099037885665894\n",
      "Train Epoch 303.2 var loss 72291.96875 reconstruction mse 72288.8125 imputation mse 1.0098459720611572\n",
      "Train Epoch 303.3 var loss 72324.6640625 reconstruction mse 72321.5390625 imputation mse 1.0103031396865845\n",
      "Train Epoch 303.4 var loss 72317.359375 reconstruction mse 72314.328125 imputation mse 1.010202407836914\n",
      "Train Epoch 303.5 var loss 72278.2421875 reconstruction mse 72275.3125 imputation mse 1.009657382965088\n",
      "Train Epoch 303.6 var loss 72300.703125 reconstruction mse 72297.859375 imputation mse 1.009972333908081\n",
      "Train Epoch 303.7 var loss 72304.046875 reconstruction mse 72301.234375 imputation mse 1.0100194215774536\n",
      "Train Epoch 303.8 var loss 72292.1875 reconstruction mse 72289.40625 imputation mse 1.0098541975021362\n",
      "Train Epoch 303.9 var loss 72257.6953125 reconstruction mse 72254.921875 imputation mse 1.0093724727630615\n",
      "Train Epoch 304.0 var loss 71327.1484375 reconstruction mse 71323.8828125 imputation mse 0.996338427066803\n",
      "Train Epoch 304.1 var loss 71362.2578125 reconstruction mse 71359.265625 imputation mse 0.9968327283859253\n",
      "Train Epoch 304.2 var loss 71333.1484375 reconstruction mse 71330.0546875 imputation mse 0.996424674987793\n",
      "Train Epoch 304.3 var loss 71353.8515625 reconstruction mse 71350.75 imputation mse 0.9967137575149536\n",
      "Train Epoch 304.4 var loss 71373.546875 reconstruction mse 71370.5078125 imputation mse 0.9969897270202637\n",
      "Train Epoch 304.5 var loss 71318.578125 reconstruction mse 71315.65625 imputation mse 0.996223509311676\n",
      "Train Epoch 304.6 var loss 71363.6875 reconstruction mse 71360.8671875 imputation mse 0.9968550801277161\n",
      "Train Epoch 304.7 var loss 71359.4296875 reconstruction mse 71356.6953125 imputation mse 0.9967967867851257\n",
      "Train Epoch 304.8 var loss 71337.71875 reconstruction mse 71334.96875 imputation mse 0.9964932799339294\n",
      "Train Epoch 304.9 var loss 71355.3984375 reconstruction mse 71352.59375 imputation mse 0.9967395067214966\n",
      "Train Epoch 305.0 var loss 71879.6015625 reconstruction mse 71876.3125 imputation mse 1.0014952421188354\n",
      "Train Epoch 305.1 var loss 71876.6484375 reconstruction mse 71873.6015625 imputation mse 1.0014574527740479\n",
      "Train Epoch 305.2 var loss 71895.3203125 reconstruction mse 71892.1875 imputation mse 1.0017164945602417\n",
      "Train Epoch 305.3 var loss 71872.3359375 reconstruction mse 71869.234375 imputation mse 1.001396656036377\n",
      "Train Epoch 305.4 var loss 71837.9921875 reconstruction mse 71834.984375 imputation mse 1.0009193420410156\n",
      "Train Epoch 305.5 var loss 71891.9140625 reconstruction mse 71889.015625 imputation mse 1.0016722679138184\n",
      "Train Epoch 305.6 var loss 71866.9609375 reconstruction mse 71864.15625 imputation mse 1.0013258457183838\n",
      "Train Epoch 305.7 var loss 71860.390625 reconstruction mse 71857.640625 imputation mse 1.0012351274490356\n",
      "Train Epoch 305.8 var loss 71856.703125 reconstruction mse 71853.9609375 imputation mse 1.0011838674545288\n",
      "Train Epoch 305.9 var loss 71816.359375 reconstruction mse 71813.6171875 imputation mse 1.0006216764450073\n",
      "Train Epoch 306.0 var loss 71645.4609375 reconstruction mse 71642.203125 imputation mse 0.9990267157554626\n",
      "Train Epoch 306.1 var loss 71594.71875 reconstruction mse 71591.71875 imputation mse 0.9983227252960205\n",
      "Train Epoch 306.2 var loss 71600.890625 reconstruction mse 71597.796875 imputation mse 0.9984074831008911\n",
      "Train Epoch 306.3 var loss 71627.171875 reconstruction mse 71624.125 imputation mse 0.9987745881080627\n",
      "Train Epoch 306.4 var loss 71634.6015625 reconstruction mse 71631.65625 imputation mse 0.998879611492157\n",
      "Train Epoch 306.5 var loss 71578.4765625 reconstruction mse 71575.6484375 imputation mse 0.998098611831665\n",
      "Train Epoch 306.6 var loss 71653.90625 reconstruction mse 71651.1796875 imputation mse 0.999151885509491\n",
      "Train Epoch 306.7 var loss 71601.8125 reconstruction mse 71599.1328125 imputation mse 0.998426079750061\n",
      "Train Epoch 306.8 var loss 71615.0859375 reconstruction mse 71612.3828125 imputation mse 0.9986108541488647\n",
      "Train Epoch 306.9 var loss 71605.6015625 reconstruction mse 71602.8359375 imputation mse 0.9984777569770813\n",
      "Train Epoch 307.0 var loss 71299.6328125 reconstruction mse 71296.3828125 imputation mse 1.0004544258117676\n",
      "Train Epoch 307.1 var loss 71324.203125 reconstruction mse 71321.1953125 imputation mse 1.0008026361465454\n",
      "Train Epoch 307.2 var loss 71299.984375 reconstruction mse 71296.859375 imputation mse 1.0004611015319824\n",
      "Train Epoch 307.3 var loss 71337.0703125 reconstruction mse 71333.96875 imputation mse 1.0009818077087402\n",
      "Train Epoch 307.4 var loss 71320.34375 reconstruction mse 71317.34375 imputation mse 1.0007485151290894\n",
      "Train Epoch 307.5 var loss 71316.6640625 reconstruction mse 71313.796875 imputation mse 1.0006988048553467\n",
      "Train Epoch 307.6 var loss 71309.8359375 reconstruction mse 71307.0625 imputation mse 1.000604271888733\n",
      "Train Epoch 307.7 var loss 71290.1484375 reconstruction mse 71287.4375 imputation mse 1.0003288984298706\n",
      "Train Epoch 307.8 var loss 71316.78125 reconstruction mse 71314.0625 imputation mse 1.0007025003433228\n",
      "Train Epoch 307.9 var loss 71274.796875 reconstruction mse 71272.046875 imputation mse 1.0001128911972046\n",
      "Train Epoch 308.0 var loss 71496.3671875 reconstruction mse 71493.1796875 imputation mse 1.0003522634506226\n",
      "Train Epoch 308.1 var loss 71501.8125 reconstruction mse 71498.8515625 imputation mse 1.0004316568374634\n",
      "Train Epoch 308.2 var loss 71514.765625 reconstruction mse 71511.703125 imputation mse 1.0006115436553955\n",
      "Train Epoch 308.3 var loss 71502.1953125 reconstruction mse 71499.171875 imputation mse 1.0004361867904663\n",
      "Train Epoch 308.4 var loss 71496.875 reconstruction mse 71493.9453125 imputation mse 1.0003629922866821\n",
      "Train Epoch 308.5 var loss 71473.75 reconstruction mse 71470.9296875 imputation mse 1.0000410079956055\n",
      "Train Epoch 308.6 var loss 71499.7890625 reconstruction mse 71497.046875 imputation mse 1.0004063844680786\n",
      "Train Epoch 308.7 var loss 71505.71875 reconstruction mse 71503.0078125 imputation mse 1.0004898309707642\n",
      "Train Epoch 308.8 var loss 71496.4453125 reconstruction mse 71493.7265625 imputation mse 1.0003600120544434\n",
      "Train Epoch 308.9 var loss 71501.328125 reconstruction mse 71498.5625 imputation mse 1.0004276037216187\n",
      "Train Epoch 309.0 var loss 72173.46875 reconstruction mse 72170.25 imputation mse 1.00619375705719\n",
      "Train Epoch 309.1 var loss 72176.5703125 reconstruction mse 72173.546875 imputation mse 1.006239652633667\n",
      "Train Epoch 309.2 var loss 72146.2421875 reconstruction mse 72143.1328125 imputation mse 1.0058156251907349\n",
      "Train Epoch 309.3 var loss 72155.5859375 reconstruction mse 72152.4765625 imputation mse 1.0059459209442139\n",
      "Train Epoch 309.4 var loss 72145.34375 reconstruction mse 72142.3125 imputation mse 1.005804181098938\n",
      "Train Epoch 309.5 var loss 72197.3515625 reconstruction mse 72194.4375 imputation mse 1.0065308809280396\n",
      "Train Epoch 309.6 var loss 72156.8046875 reconstruction mse 72153.9765625 imputation mse 1.0059667825698853\n",
      "Train Epoch 309.7 var loss 72169.890625 reconstruction mse 72167.1328125 imputation mse 1.006150245666504\n",
      "Train Epoch 309.8 var loss 72166.046875 reconstruction mse 72163.28125 imputation mse 1.006096601486206\n",
      "Train Epoch 309.9 var loss 72167.4609375 reconstruction mse 72164.640625 imputation mse 1.0061155557632446\n",
      "Train Epoch 310.0 var loss 70386.4453125 reconstruction mse 70383.21875 imputation mse 0.9901136755943298\n",
      "Train Epoch 310.1 var loss 70403.828125 reconstruction mse 70400.7421875 imputation mse 0.9903601408004761\n",
      "Train Epoch 310.2 var loss 70365.859375 reconstruction mse 70362.6953125 imputation mse 0.9898249506950378\n",
      "Train Epoch 310.3 var loss 70381.953125 reconstruction mse 70378.8125 imputation mse 0.9900516867637634\n",
      "Train Epoch 310.4 var loss 70406.4609375 reconstruction mse 70403.453125 imputation mse 0.9903982877731323\n",
      "Train Epoch 310.5 var loss 70395.4375 reconstruction mse 70392.578125 imputation mse 0.9902452826499939\n",
      "Train Epoch 310.6 var loss 70376.4375 reconstruction mse 70373.671875 imputation mse 0.9899793267250061\n",
      "Train Epoch 310.7 var loss 70378.9765625 reconstruction mse 70376.25 imputation mse 0.9900156259536743\n",
      "Train Epoch 310.8 var loss 70383.84375 reconstruction mse 70381.1171875 imputation mse 0.9900841116905212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 310.9 var loss 70367.2734375 reconstruction mse 70364.5078125 imputation mse 0.9898504614830017\n",
      "====> Test imputation mse: 1.01179409\n",
      "====> Test imputation mse: 1.00587904\n",
      "====> Test imputation mse: 1.00602829\n",
      "Train Epoch 311.0 var loss 71635.2734375 reconstruction mse 71632.109375 imputation mse 0.9951391816139221\n",
      "Train Epoch 311.1 var loss 71638.5078125 reconstruction mse 71635.5078125 imputation mse 0.9951863884925842\n",
      "Train Epoch 311.2 var loss 71618.046875 reconstruction mse 71614.953125 imputation mse 0.9949008226394653\n",
      "Train Epoch 311.3 var loss 71679.3984375 reconstruction mse 71676.28125 imputation mse 0.9957528710365295\n",
      "Train Epoch 311.4 var loss 71636.7578125 reconstruction mse 71633.7109375 imputation mse 0.9951614141464233\n",
      "Train Epoch 311.5 var loss 71632.734375 reconstruction mse 71629.796875 imputation mse 0.9951070547103882\n",
      "Train Epoch 311.6 var loss 71644.5234375 reconstruction mse 71641.6875 imputation mse 0.9952722787857056\n",
      "Train Epoch 311.7 var loss 71632.375 reconstruction mse 71629.59375 imputation mse 0.9951042532920837\n",
      "Train Epoch 311.8 var loss 71666.7109375 reconstruction mse 71663.953125 imputation mse 0.9955815672874451\n",
      "Train Epoch 311.9 var loss 71677.75 reconstruction mse 71674.96875 imputation mse 0.9957346320152283\n",
      "Train Epoch 312.0 var loss 71392.3515625 reconstruction mse 71389.15625 imputation mse 0.9967211484909058\n",
      "Train Epoch 312.1 var loss 71380.6796875 reconstruction mse 71377.703125 imputation mse 0.9965612292289734\n",
      "Train Epoch 312.2 var loss 71342.328125 reconstruction mse 71339.2578125 imputation mse 0.996024489402771\n",
      "Train Epoch 312.3 var loss 71367.8359375 reconstruction mse 71364.796875 imputation mse 0.9963810443878174\n",
      "Train Epoch 312.4 var loss 71385.84375 reconstruction mse 71382.8828125 imputation mse 0.9966335892677307\n",
      "Train Epoch 312.5 var loss 71379.0625 reconstruction mse 71376.21875 imputation mse 0.9965405464172363\n",
      "Train Epoch 312.6 var loss 71357.15625 reconstruction mse 71354.3828125 imputation mse 0.9962356686592102\n",
      "Train Epoch 312.7 var loss 71369.7109375 reconstruction mse 71367.0078125 imputation mse 0.996411919593811\n",
      "Train Epoch 312.8 var loss 71361.3828125 reconstruction mse 71358.671875 imputation mse 0.9962955713272095\n",
      "Train Epoch 312.9 var loss 71347.0 reconstruction mse 71344.2890625 imputation mse 0.9960947036743164\n",
      "Train Epoch 313.0 var loss 71716.7578125 reconstruction mse 71713.6171875 imputation mse 0.9969779253005981\n",
      "Train Epoch 313.1 var loss 71696.8203125 reconstruction mse 71693.9375 imputation mse 0.9967042803764343\n",
      "Train Epoch 313.2 var loss 71687.171875 reconstruction mse 71684.1484375 imputation mse 0.9965682029724121\n",
      "Train Epoch 313.3 var loss 71690.9765625 reconstruction mse 71687.9296875 imputation mse 0.996620774269104\n",
      "Train Epoch 313.4 var loss 71645.328125 reconstruction mse 71642.34375 imputation mse 0.995987057685852\n",
      "Train Epoch 313.5 var loss 71699.109375 reconstruction mse 71696.2265625 imputation mse 0.9967361092567444\n",
      "Train Epoch 313.6 var loss 71719.15625 reconstruction mse 71716.375 imputation mse 0.9970162510871887\n",
      "Train Epoch 313.7 var loss 71697.25 reconstruction mse 71694.53125 imputation mse 0.9967125654220581\n",
      "Train Epoch 313.8 var loss 71674.2578125 reconstruction mse 71671.5546875 imputation mse 0.9963931441307068\n",
      "Train Epoch 313.9 var loss 71643.8046875 reconstruction mse 71641.0859375 imputation mse 0.9959695339202881\n",
      "Train Epoch 314.0 var loss 71961.4375 reconstruction mse 71958.265625 imputation mse 0.9995036721229553\n",
      "Train Epoch 314.1 var loss 71966.421875 reconstruction mse 71963.40625 imputation mse 0.9995750784873962\n",
      "Train Epoch 314.2 var loss 71972.8125 reconstruction mse 71969.671875 imputation mse 0.9996621012687683\n",
      "Train Epoch 314.3 var loss 71969.8671875 reconstruction mse 71966.703125 imputation mse 0.9996208548545837\n",
      "Train Epoch 314.4 var loss 71937.9921875 reconstruction mse 71934.8984375 imputation mse 0.9991790652275085\n",
      "Train Epoch 314.5 var loss 71962.9140625 reconstruction mse 71959.984375 imputation mse 0.9995275139808655\n",
      "Train Epoch 314.6 var loss 71937.1953125 reconstruction mse 71934.390625 imputation mse 0.999172031879425\n",
      "Train Epoch 314.7 var loss 71924.3515625 reconstruction mse 71921.6328125 imputation mse 0.9989948272705078\n",
      "Train Epoch 314.8 var loss 71972.9921875 reconstruction mse 71970.2890625 imputation mse 0.9996706247329712\n",
      "Train Epoch 314.9 var loss 71962.765625 reconstruction mse 71960.0390625 imputation mse 0.9995282888412476\n",
      "Train Epoch 315.0 var loss 71744.828125 reconstruction mse 71741.6953125 imputation mse 1.0000375509262085\n",
      "Train Epoch 315.1 var loss 71748.0546875 reconstruction mse 71745.0625 imputation mse 1.0000845193862915\n",
      "Train Epoch 315.2 var loss 71719.0 reconstruction mse 71715.9140625 imputation mse 0.9996781945228577\n",
      "Train Epoch 315.3 var loss 71741.890625 reconstruction mse 71738.7890625 imputation mse 0.999997079372406\n",
      "Train Epoch 315.4 var loss 71730.09375 reconstruction mse 71727.0625 imputation mse 0.9998335838317871\n",
      "Train Epoch 315.5 var loss 71763.53125 reconstruction mse 71760.6171875 imputation mse 1.0003013610839844\n",
      "Train Epoch 315.6 var loss 71712.5625 reconstruction mse 71709.7578125 imputation mse 0.9995923638343811\n",
      "Train Epoch 315.7 var loss 71737.4375 reconstruction mse 71734.671875 imputation mse 0.9999396800994873\n",
      "Train Epoch 315.8 var loss 71736.25 reconstruction mse 71733.4765625 imputation mse 0.9999229907989502\n",
      "Train Epoch 315.9 var loss 71745.4453125 reconstruction mse 71742.6328125 imputation mse 1.000050663948059\n",
      "Train Epoch 316.0 var loss 71662.5859375 reconstruction mse 71659.4296875 imputation mse 1.0036896467208862\n",
      "Train Epoch 316.1 var loss 71682.1328125 reconstruction mse 71679.125 imputation mse 1.0039656162261963\n",
      "Train Epoch 316.2 var loss 71657.421875 reconstruction mse 71654.3125 imputation mse 1.0036180019378662\n",
      "Train Epoch 316.3 var loss 71646.9609375 reconstruction mse 71643.8671875 imputation mse 1.0034717321395874\n",
      "Train Epoch 316.4 var loss 71662.8984375 reconstruction mse 71659.9453125 imputation mse 1.0036969184875488\n",
      "Train Epoch 316.5 var loss 71660.0078125 reconstruction mse 71657.171875 imputation mse 1.0036580562591553\n",
      "Train Epoch 316.6 var loss 71664.34375 reconstruction mse 71661.6015625 imputation mse 1.0037201642990112\n",
      "Train Epoch 316.7 var loss 71645.265625 reconstruction mse 71642.5546875 imputation mse 1.0034533739089966\n",
      "Train Epoch 316.8 var loss 71667.8828125 reconstruction mse 71665.171875 imputation mse 1.003770112991333\n",
      "Train Epoch 316.9 var loss 71688.8515625 reconstruction mse 71686.1328125 imputation mse 1.0040637254714966\n",
      "Train Epoch 317.0 var loss 71472.21875 reconstruction mse 71469.0859375 imputation mse 1.0035396814346313\n",
      "Train Epoch 317.1 var loss 71443.3203125 reconstruction mse 71440.3828125 imputation mse 1.0031366348266602\n",
      "Train Epoch 317.2 var loss 71464.859375 reconstruction mse 71461.84375 imputation mse 1.0034379959106445\n",
      "Train Epoch 317.3 var loss 71483.0390625 reconstruction mse 71480.0234375 imputation mse 1.0036932229995728\n",
      "Train Epoch 317.4 var loss 71464.8515625 reconstruction mse 71461.890625 imputation mse 1.0034387111663818\n",
      "Train Epoch 317.5 var loss 71482.9921875 reconstruction mse 71480.109375 imputation mse 1.0036944150924683\n",
      "Train Epoch 317.6 var loss 71478.859375 reconstruction mse 71476.046875 imputation mse 1.003637433052063\n",
      "Train Epoch 317.7 var loss 71449.671875 reconstruction mse 71446.8984375 imputation mse 1.0032281875610352\n",
      "Train Epoch 317.8 var loss 71495.8671875 reconstruction mse 71493.109375 imputation mse 1.00387704372406\n",
      "Train Epoch 317.9 var loss 71459.4921875 reconstruction mse 71456.6953125 imputation mse 1.0033657550811768\n",
      "Train Epoch 318.0 var loss 72273.0 reconstruction mse 72269.84375 imputation mse 1.0092707872390747\n",
      "Train Epoch 318.1 var loss 72258.53125 reconstruction mse 72255.546875 imputation mse 1.0090711116790771\n",
      "Train Epoch 318.2 var loss 72258.2734375 reconstruction mse 72255.2109375 imputation mse 1.0090664625167847\n",
      "Train Epoch 318.3 var loss 72291.59375 reconstruction mse 72288.5390625 imputation mse 1.009531855583191\n",
      "Train Epoch 318.4 var loss 72286.4375 reconstruction mse 72283.4375 imputation mse 1.0094605684280396\n",
      "Train Epoch 318.5 var loss 72266.4375 reconstruction mse 72263.515625 imputation mse 1.0091824531555176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 318.6 var loss 72291.6171875 reconstruction mse 72288.7890625 imputation mse 1.009535312652588\n",
      "Train Epoch 318.7 var loss 72274.96875 reconstruction mse 72272.2265625 imputation mse 1.0093040466308594\n",
      "Train Epoch 318.8 var loss 72265.484375 reconstruction mse 72262.75 imputation mse 1.009171724319458\n",
      "Train Epoch 318.9 var loss 72247.25 reconstruction mse 72244.5 imputation mse 1.0089168548583984\n",
      "Train Epoch 319.0 var loss 71964.625 reconstruction mse 71961.4921875 imputation mse 0.9995484352111816\n",
      "Train Epoch 319.1 var loss 71984.1171875 reconstruction mse 71981.1484375 imputation mse 0.9998214840888977\n",
      "Train Epoch 319.2 var loss 72007.0703125 reconstruction mse 72003.9765625 imputation mse 1.000138521194458\n",
      "Train Epoch 319.3 var loss 72020.3828125 reconstruction mse 72017.296875 imputation mse 1.0003236532211304\n",
      "Train Epoch 319.4 var loss 71992.21875 reconstruction mse 71989.2109375 imputation mse 0.9999334812164307\n",
      "Train Epoch 319.5 var loss 71995.9765625 reconstruction mse 71993.109375 imputation mse 0.9999876022338867\n",
      "Train Epoch 319.6 var loss 71978.6796875 reconstruction mse 71975.9296875 imputation mse 0.9997490048408508\n",
      "Train Epoch 319.7 var loss 71975.90625 reconstruction mse 71973.2109375 imputation mse 0.9997112154960632\n",
      "Train Epoch 319.8 var loss 72005.8046875 reconstruction mse 72003.0859375 imputation mse 1.0001262426376343\n",
      "Train Epoch 319.9 var loss 71962.3125 reconstruction mse 71959.515625 imputation mse 0.999521017074585\n",
      "Train Epoch 320.0 var loss 72877.7265625 reconstruction mse 72874.59375 imputation mse 1.0126394033432007\n",
      "Train Epoch 320.1 var loss 72838.0390625 reconstruction mse 72834.9921875 imputation mse 1.0120891332626343\n",
      "Train Epoch 320.2 var loss 72883.8515625 reconstruction mse 72880.6953125 imputation mse 1.0127241611480713\n",
      "Train Epoch 320.3 var loss 72854.1015625 reconstruction mse 72850.96875 imputation mse 1.0123111009597778\n",
      "Train Epoch 320.4 var loss 72840.3046875 reconstruction mse 72837.3046875 imputation mse 1.0121212005615234\n",
      "Train Epoch 320.5 var loss 72873.9921875 reconstruction mse 72871.1484375 imputation mse 1.0125914812088013\n",
      "Train Epoch 320.6 var loss 72845.328125 reconstruction mse 72842.6015625 imputation mse 1.0121948719024658\n",
      "Train Epoch 320.7 var loss 72838.4765625 reconstruction mse 72835.796875 imputation mse 1.012100338935852\n",
      "Train Epoch 320.8 var loss 72848.1015625 reconstruction mse 72845.390625 imputation mse 1.0122336149215698\n",
      "Train Epoch 320.9 var loss 72840.0078125 reconstruction mse 72837.265625 imputation mse 1.0121207237243652\n",
      "====> Test imputation mse: 0.99258029\n",
      "====> Test imputation mse: 1.01277220\n",
      "====> Test imputation mse: 0.99846441\n",
      "Train Epoch 321.0 var loss 71404.0234375 reconstruction mse 71400.9375 imputation mse 1.005123257637024\n",
      "Train Epoch 321.1 var loss 71440.109375 reconstruction mse 71437.15625 imputation mse 1.0056331157684326\n",
      "Train Epoch 321.2 var loss 71419.9140625 reconstruction mse 71416.8515625 imputation mse 1.0053472518920898\n",
      "Train Epoch 321.3 var loss 71446.0703125 reconstruction mse 71443.0390625 imputation mse 1.0057158470153809\n",
      "Train Epoch 321.4 var loss 71449.875 reconstruction mse 71446.9375 imputation mse 1.0057708024978638\n",
      "Train Epoch 321.5 var loss 71397.359375 reconstruction mse 71394.5546875 imputation mse 1.0050333738327026\n",
      "Train Epoch 321.6 var loss 71398.796875 reconstruction mse 71396.1171875 imputation mse 1.00505530834198\n",
      "Train Epoch 321.7 var loss 71451.3203125 reconstruction mse 71448.6875 imputation mse 1.0057953596115112\n",
      "Train Epoch 321.8 var loss 71413.5625 reconstruction mse 71410.921875 imputation mse 1.0052638053894043\n",
      "Train Epoch 321.9 var loss 71438.7421875 reconstruction mse 71436.0390625 imputation mse 1.005617380142212\n",
      "Train Epoch 322.0 var loss 71998.1875 reconstruction mse 71995.0703125 imputation mse 1.0038493871688843\n",
      "Train Epoch 322.1 var loss 72026.90625 reconstruction mse 72023.9296875 imputation mse 1.0042517185211182\n",
      "Train Epoch 322.2 var loss 71999.1171875 reconstruction mse 71996.0390625 imputation mse 1.0038628578186035\n",
      "Train Epoch 322.3 var loss 72016.78125 reconstruction mse 72013.7265625 imputation mse 1.004109501838684\n",
      "Train Epoch 322.4 var loss 72000.4921875 reconstruction mse 71997.515625 imputation mse 1.0038834810256958\n",
      "Train Epoch 322.5 var loss 71977.0625 reconstruction mse 71974.2109375 imputation mse 1.0035585165023804\n",
      "Train Epoch 322.6 var loss 72026.703125 reconstruction mse 72023.96875 imputation mse 1.004252314567566\n",
      "Train Epoch 322.7 var loss 72017.3984375 reconstruction mse 72014.7421875 imputation mse 1.004123568534851\n",
      "Train Epoch 322.8 var loss 72001.59375 reconstruction mse 71998.953125 imputation mse 1.0039035081863403\n",
      "Train Epoch 322.9 var loss 72044.7109375 reconstruction mse 72042.0234375 imputation mse 1.0045039653778076\n",
      "Train Epoch 323.0 var loss 71954.171875 reconstruction mse 71951.09375 imputation mse 1.009939193725586\n",
      "Train Epoch 323.1 var loss 71984.90625 reconstruction mse 71981.9296875 imputation mse 1.0103719234466553\n",
      "Train Epoch 323.2 var loss 71937.0234375 reconstruction mse 71933.90625 imputation mse 1.0096979141235352\n",
      "Train Epoch 323.3 var loss 71986.46875 reconstruction mse 71983.3359375 imputation mse 1.0103917121887207\n",
      "Train Epoch 323.4 var loss 72008.40625 reconstruction mse 72005.375 imputation mse 1.010701060295105\n",
      "Train Epoch 323.5 var loss 71949.015625 reconstruction mse 71946.1328125 imputation mse 1.0098694562911987\n",
      "Train Epoch 323.6 var loss 71972.375 reconstruction mse 71969.625 imputation mse 1.0101991891860962\n",
      "Train Epoch 323.7 var loss 71973.0546875 reconstruction mse 71970.4140625 imputation mse 1.0102102756500244\n",
      "Train Epoch 323.8 var loss 72028.484375 reconstruction mse 72025.859375 imputation mse 1.0109885931015015\n",
      "Train Epoch 323.9 var loss 71952.15625 reconstruction mse 71949.5078125 imputation mse 1.00991690158844\n",
      "Train Epoch 324.0 var loss 70895.890625 reconstruction mse 70892.84375 imputation mse 0.997142493724823\n",
      "Train Epoch 324.1 var loss 70963.2109375 reconstruction mse 70960.28125 imputation mse 0.9980910420417786\n",
      "Train Epoch 324.2 var loss 70964.3125 reconstruction mse 70961.3203125 imputation mse 0.9981056451797485\n",
      "Train Epoch 324.3 var loss 70915.1484375 reconstruction mse 70912.1640625 imputation mse 0.997414231300354\n",
      "Train Epoch 324.4 var loss 70910.640625 reconstruction mse 70907.75 imputation mse 0.9973521828651428\n",
      "Train Epoch 324.5 var loss 70929.53125 reconstruction mse 70926.7578125 imputation mse 0.9976195096969604\n",
      "Train Epoch 324.6 var loss 70942.734375 reconstruction mse 70940.03125 imputation mse 0.9978062510490417\n",
      "Train Epoch 324.7 var loss 70934.375 reconstruction mse 70931.7265625 imputation mse 0.997689425945282\n",
      "Train Epoch 324.8 var loss 70917.3046875 reconstruction mse 70914.671875 imputation mse 0.997449517250061\n",
      "Train Epoch 324.9 var loss 70879.5546875 reconstruction mse 70876.8984375 imputation mse 0.9969182014465332\n",
      "Train Epoch 325.0 var loss 71643.140625 reconstruction mse 71640.0703125 imputation mse 1.0011188983917236\n",
      "Train Epoch 325.1 var loss 71640.7421875 reconstruction mse 71637.84375 imputation mse 1.0010877847671509\n",
      "Train Epoch 325.2 var loss 71661.9296875 reconstruction mse 71658.9453125 imputation mse 1.0013827085494995\n",
      "Train Epoch 325.3 var loss 71671.1484375 reconstruction mse 71668.1875 imputation mse 1.001511812210083\n",
      "Train Epoch 325.4 var loss 71682.984375 reconstruction mse 71680.0859375 imputation mse 1.0016781091690063\n",
      "Train Epoch 325.5 var loss 71633.0859375 reconstruction mse 71630.2890625 imputation mse 1.0009822845458984\n",
      "Train Epoch 325.6 var loss 71634.5625 reconstruction mse 71631.8515625 imputation mse 1.0010040998458862\n",
      "Train Epoch 325.7 var loss 71637.9296875 reconstruction mse 71635.265625 imputation mse 1.0010517835617065\n",
      "Train Epoch 325.8 var loss 71648.875 reconstruction mse 71646.234375 imputation mse 1.0012050867080688\n",
      "Train Epoch 325.9 var loss 71656.6796875 reconstruction mse 71654.0 imputation mse 1.00131356716156\n",
      "Train Epoch 326.0 var loss 70939.84375 reconstruction mse 70936.8125 imputation mse 0.9896180629730225\n",
      "Train Epoch 326.1 var loss 70967.515625 reconstruction mse 70964.6015625 imputation mse 0.9900057315826416\n",
      "Train Epoch 326.2 var loss 70921.0 reconstruction mse 70918.03125 imputation mse 0.9893560409545898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 326.3 var loss 70908.4375 reconstruction mse 70905.4921875 imputation mse 0.9891811013221741\n",
      "Train Epoch 326.4 var loss 70934.2109375 reconstruction mse 70931.3515625 imputation mse 0.9895418882369995\n",
      "Train Epoch 326.5 var loss 70881.2890625 reconstruction mse 70878.5625 imputation mse 0.9888054132461548\n",
      "Train Epoch 326.6 var loss 70919.1015625 reconstruction mse 70916.46875 imputation mse 0.989334225654602\n",
      "Train Epoch 326.7 var loss 70887.1875 reconstruction mse 70884.6015625 imputation mse 0.9888896942138672\n",
      "Train Epoch 326.8 var loss 70890.6875 reconstruction mse 70888.1015625 imputation mse 0.9889385104179382\n",
      "Train Epoch 326.9 var loss 70913.15625 reconstruction mse 70910.5234375 imputation mse 0.9892513155937195\n",
      "Train Epoch 327.0 var loss 71128.3359375 reconstruction mse 71125.34375 imputation mse 0.9958882331848145\n",
      "Train Epoch 327.1 var loss 71091.6640625 reconstruction mse 71088.8125 imputation mse 0.9953767657279968\n",
      "Train Epoch 327.2 var loss 71090.5625 reconstruction mse 71087.609375 imputation mse 0.9953598976135254\n",
      "Train Epoch 327.3 var loss 71103.921875 reconstruction mse 71100.9765625 imputation mse 0.9955470561981201\n",
      "Train Epoch 327.4 var loss 71102.1328125 reconstruction mse 71099.28125 imputation mse 0.9955233335494995\n",
      "Train Epoch 327.5 var loss 71091.0234375 reconstruction mse 71088.3125 imputation mse 0.9953697323799133\n",
      "Train Epoch 327.6 var loss 71113.4296875 reconstruction mse 71110.8125 imputation mse 0.995684802532196\n",
      "Train Epoch 327.7 var loss 71067.7890625 reconstruction mse 71065.234375 imputation mse 0.9950466156005859\n",
      "Train Epoch 327.8 var loss 71104.7734375 reconstruction mse 71102.21875 imputation mse 0.9955644607543945\n",
      "Train Epoch 327.9 var loss 71090.6875 reconstruction mse 71088.078125 imputation mse 0.9953664541244507\n",
      "Train Epoch 328.0 var loss 70935.75 reconstruction mse 70932.75 imputation mse 0.9907915592193604\n",
      "Train Epoch 328.1 var loss 70992.1328125 reconstruction mse 70989.3046875 imputation mse 0.9915814995765686\n",
      "Train Epoch 328.2 var loss 70994.203125 reconstruction mse 70991.265625 imputation mse 0.9916089177131653\n",
      "Train Epoch 328.3 var loss 70975.0625 reconstruction mse 70972.1484375 imputation mse 0.9913418889045715\n",
      "Train Epoch 328.4 var loss 70972.9453125 reconstruction mse 70970.1484375 imputation mse 0.9913139343261719\n",
      "Train Epoch 328.5 var loss 70924.9375 reconstruction mse 70922.265625 imputation mse 0.9906451106071472\n",
      "Train Epoch 328.6 var loss 70961.0546875 reconstruction mse 70958.484375 imputation mse 0.9911510348320007\n",
      "Train Epoch 328.7 var loss 70957.7109375 reconstruction mse 70955.171875 imputation mse 0.991104781627655\n",
      "Train Epoch 328.8 var loss 70945.71875 reconstruction mse 70943.1640625 imputation mse 0.9909370541572571\n",
      "Train Epoch 328.9 var loss 70962.0625 reconstruction mse 70959.453125 imputation mse 0.9911645650863647\n",
      "Train Epoch 329.0 var loss 71296.828125 reconstruction mse 71293.8203125 imputation mse 0.9968236088752747\n",
      "Train Epoch 329.1 var loss 71330.4453125 reconstruction mse 71327.578125 imputation mse 0.997295618057251\n",
      "Train Epoch 329.2 var loss 71328.59375 reconstruction mse 71325.6484375 imputation mse 0.9972686171531677\n",
      "Train Epoch 329.3 var loss 71270.4921875 reconstruction mse 71267.5859375 imputation mse 0.9964568018913269\n",
      "Train Epoch 329.4 var loss 71287.234375 reconstruction mse 71284.4296875 imputation mse 0.9966922998428345\n",
      "Train Epoch 329.5 var loss 71279.671875 reconstruction mse 71276.9609375 imputation mse 0.996587872505188\n",
      "Train Epoch 329.6 var loss 71249.171875 reconstruction mse 71246.5234375 imputation mse 0.9961622953414917\n",
      "Train Epoch 329.7 var loss 71256.1953125 reconstruction mse 71253.5703125 imputation mse 0.9962608218193054\n",
      "Train Epoch 329.8 var loss 71267.1875 reconstruction mse 71264.5546875 imputation mse 0.9964144229888916\n",
      "Train Epoch 329.9 var loss 71280.234375 reconstruction mse 71277.5390625 imputation mse 0.9965959787368774\n",
      "Train Epoch 330.0 var loss 71490.09375 reconstruction mse 71487.1171875 imputation mse 1.0024555921554565\n",
      "Train Epoch 330.1 var loss 71438.671875 reconstruction mse 71435.765625 imputation mse 1.0017355680465698\n",
      "Train Epoch 330.2 var loss 71408.2265625 reconstruction mse 71405.2421875 imputation mse 1.001307487487793\n",
      "Train Epoch 330.3 var loss 71452.0078125 reconstruction mse 71449.0546875 imputation mse 1.0019218921661377\n",
      "Train Epoch 330.4 var loss 71456.3046875 reconstruction mse 71453.4453125 imputation mse 1.0019835233688354\n",
      "Train Epoch 330.5 var loss 71437.125 reconstruction mse 71434.375 imputation mse 1.0017160177230835\n",
      "Train Epoch 330.6 var loss 71458.5859375 reconstruction mse 71455.9375 imputation mse 1.0020184516906738\n",
      "Train Epoch 330.7 var loss 71473.828125 reconstruction mse 71471.2265625 imputation mse 1.0022327899932861\n",
      "Train Epoch 330.8 var loss 71469.25 reconstruction mse 71466.65625 imputation mse 1.0021687746047974\n",
      "Train Epoch 330.9 var loss 71443.1015625 reconstruction mse 71440.4921875 imputation mse 1.00180184841156\n",
      "====> Test imputation mse: 1.01453054\n",
      "====> Test imputation mse: 0.99224114\n",
      "====> Test imputation mse: 0.97883642\n",
      "Train Epoch 331.0 var loss 72280.328125 reconstruction mse 72277.3828125 imputation mse 1.0145047903060913\n",
      "Train Epoch 331.1 var loss 72293.984375 reconstruction mse 72291.1796875 imputation mse 1.0146985054016113\n",
      "Train Epoch 331.2 var loss 72313.671875 reconstruction mse 72310.7578125 imputation mse 1.0149732828140259\n",
      "Train Epoch 331.3 var loss 72299.7890625 reconstruction mse 72296.8984375 imputation mse 1.014778733253479\n",
      "Train Epoch 331.4 var loss 72290.890625 reconstruction mse 72288.046875 imputation mse 1.014654517173767\n",
      "Train Epoch 331.5 var loss 72324.2265625 reconstruction mse 72321.4765625 imputation mse 1.015123724937439\n",
      "Train Epoch 331.6 var loss 72317.1640625 reconstruction mse 72314.484375 imputation mse 1.0150256156921387\n",
      "Train Epoch 331.7 var loss 72318.2578125 reconstruction mse 72315.609375 imputation mse 1.0150413513183594\n",
      "Train Epoch 331.8 var loss 72309.0546875 reconstruction mse 72306.390625 imputation mse 1.0149120092391968\n",
      "Train Epoch 331.9 var loss 72321.015625 reconstruction mse 72318.328125 imputation mse 1.0150796175003052\n",
      "Train Epoch 332.0 var loss 71652.7890625 reconstruction mse 71649.796875 imputation mse 1.0030490159988403\n",
      "Train Epoch 332.1 var loss 71649.140625 reconstruction mse 71646.234375 imputation mse 1.002999186515808\n",
      "Train Epoch 332.2 var loss 71667.890625 reconstruction mse 71664.8984375 imputation mse 1.0032603740692139\n",
      "Train Epoch 332.3 var loss 71617.140625 reconstruction mse 71614.1640625 imputation mse 1.0025501251220703\n",
      "Train Epoch 332.4 var loss 71666.984375 reconstruction mse 71664.0703125 imputation mse 1.0032488107681274\n",
      "Train Epoch 332.5 var loss 71625.6171875 reconstruction mse 71622.8125 imputation mse 1.002671241760254\n",
      "Train Epoch 332.6 var loss 71634.0546875 reconstruction mse 71631.3515625 imputation mse 1.0027908086776733\n",
      "Train Epoch 332.7 var loss 71657.2109375 reconstruction mse 71654.5703125 imputation mse 1.0031158924102783\n",
      "Train Epoch 332.8 var loss 71630.484375 reconstruction mse 71627.8671875 imputation mse 1.002742052078247\n",
      "Train Epoch 332.9 var loss 71624.8203125 reconstruction mse 71622.2109375 imputation mse 1.0026627779006958\n",
      "Train Epoch 333.0 var loss 71512.3359375 reconstruction mse 71509.375 imputation mse 1.0016160011291504\n",
      "Train Epoch 333.1 var loss 71484.1796875 reconstruction mse 71481.3984375 imputation mse 1.001224160194397\n",
      "Train Epoch 333.2 var loss 71483.6015625 reconstruction mse 71480.78125 imputation mse 1.0012155771255493\n",
      "Train Epoch 333.3 var loss 71521.28125 reconstruction mse 71518.46875 imputation mse 1.0017434358596802\n",
      "Train Epoch 333.4 var loss 71514.8203125 reconstruction mse 71512.0546875 imputation mse 1.0016535520553589\n",
      "Train Epoch 333.5 var loss 71491.5234375 reconstruction mse 71488.828125 imputation mse 1.0013282299041748\n",
      "Train Epoch 333.6 var loss 71468.15625 reconstruction mse 71465.5078125 imputation mse 1.0010015964508057\n",
      "Train Epoch 333.7 var loss 71489.328125 reconstruction mse 71486.6953125 imputation mse 1.0012983083724976\n",
      "Train Epoch 333.8 var loss 71487.1484375 reconstruction mse 71484.515625 imputation mse 1.0012677907943726\n",
      "Train Epoch 333.9 var loss 71490.1640625 reconstruction mse 71487.484375 imputation mse 1.0013093948364258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 334.0 var loss 72092.8046875 reconstruction mse 72089.828125 imputation mse 1.0056052207946777\n",
      "Train Epoch 334.1 var loss 72093.6171875 reconstruction mse 72090.7421875 imputation mse 1.0056179761886597\n",
      "Train Epoch 334.2 var loss 72063.4375 reconstruction mse 72060.4921875 imputation mse 1.00519597530365\n",
      "Train Epoch 334.3 var loss 72082.9296875 reconstruction mse 72080.046875 imputation mse 1.0054688453674316\n",
      "Train Epoch 334.4 var loss 72106.34375 reconstruction mse 72103.5703125 imputation mse 1.0057969093322754\n",
      "Train Epoch 334.5 var loss 72091.546875 reconstruction mse 72088.890625 imputation mse 1.0055921077728271\n",
      "Train Epoch 334.6 var loss 72114.7265625 reconstruction mse 72112.1171875 imputation mse 1.0059161186218262\n",
      "Train Epoch 334.7 var loss 72114.2578125 reconstruction mse 72111.6796875 imputation mse 1.005910038948059\n",
      "Train Epoch 334.8 var loss 72022.8984375 reconstruction mse 72020.2734375 imputation mse 1.004634976387024\n",
      "Train Epoch 334.9 var loss 72131.0 reconstruction mse 72128.3046875 imputation mse 1.0061419010162354\n",
      "Train Epoch 335.0 var loss 71136.921875 reconstruction mse 71133.90625 imputation mse 0.9974466562271118\n",
      "Train Epoch 335.1 var loss 71157.7734375 reconstruction mse 71154.890625 imputation mse 0.9977409243583679\n",
      "Train Epoch 335.2 var loss 71150.6484375 reconstruction mse 71147.703125 imputation mse 0.9976401329040527\n",
      "Train Epoch 335.3 var loss 71135.796875 reconstruction mse 71132.859375 imputation mse 0.9974319934844971\n",
      "Train Epoch 335.4 var loss 71130.5078125 reconstruction mse 71127.6640625 imputation mse 0.9973591566085815\n",
      "Train Epoch 335.5 var loss 71148.453125 reconstruction mse 71145.6875 imputation mse 0.9976118803024292\n",
      "Train Epoch 335.6 var loss 71186.4765625 reconstruction mse 71183.7890625 imputation mse 0.998146116733551\n",
      "Train Epoch 335.7 var loss 71155.03125 reconstruction mse 71152.3984375 imputation mse 0.9977059364318848\n",
      "Train Epoch 335.8 var loss 71136.6328125 reconstruction mse 71134.0390625 imputation mse 0.9974485039710999\n",
      "Train Epoch 335.9 var loss 71108.96875 reconstruction mse 71106.390625 imputation mse 0.9970608353614807\n",
      "Train Epoch 336.0 var loss 71445.125 reconstruction mse 71442.171875 imputation mse 0.9998764395713806\n",
      "Train Epoch 336.1 var loss 71398.4296875 reconstruction mse 71395.734375 imputation mse 0.9992265105247498\n",
      "Train Epoch 336.2 var loss 71392.5390625 reconstruction mse 71389.7265625 imputation mse 0.9991424679756165\n",
      "Train Epoch 336.3 var loss 71400.109375 reconstruction mse 71397.28125 imputation mse 0.9992481470108032\n",
      "Train Epoch 336.4 var loss 71442.5234375 reconstruction mse 71439.7265625 imputation mse 0.9998422265052795\n",
      "Train Epoch 336.5 var loss 71408.1484375 reconstruction mse 71405.4140625 imputation mse 0.9993619918823242\n",
      "Train Epoch 336.6 var loss 71424.859375 reconstruction mse 71422.1796875 imputation mse 0.9995966553688049\n",
      "Train Epoch 336.7 var loss 71422.6171875 reconstruction mse 71419.96875 imputation mse 0.9995657205581665\n",
      "Train Epoch 336.8 var loss 71464.8359375 reconstruction mse 71462.203125 imputation mse 1.0001567602157593\n",
      "Train Epoch 336.9 var loss 71422.2265625 reconstruction mse 71419.609375 imputation mse 0.9995606541633606\n",
      "Train Epoch 337.0 var loss 71847.21875 reconstruction mse 71844.2421875 imputation mse 1.0009926557540894\n",
      "Train Epoch 337.1 var loss 71818.5390625 reconstruction mse 71815.75 imputation mse 1.0005955696105957\n",
      "Train Epoch 337.2 var loss 71820.71875 reconstruction mse 71817.8515625 imputation mse 1.0006248950958252\n",
      "Train Epoch 337.3 var loss 71862.90625 reconstruction mse 71860.1015625 imputation mse 1.001213550567627\n",
      "Train Epoch 337.4 var loss 71805.8203125 reconstruction mse 71803.078125 imputation mse 1.000419020652771\n",
      "Train Epoch 337.5 var loss 71825.09375 reconstruction mse 71822.4609375 imputation mse 1.000689148902893\n",
      "Train Epoch 337.6 var loss 71845.953125 reconstruction mse 71843.421875 imputation mse 1.0009812116622925\n",
      "Train Epoch 337.7 var loss 71841.390625 reconstruction mse 71838.875 imputation mse 1.0009177923202515\n",
      "Train Epoch 337.8 var loss 71819.9140625 reconstruction mse 71817.375 imputation mse 1.0006182193756104\n",
      "Train Epoch 337.9 var loss 71808.96875 reconstruction mse 71806.390625 imputation mse 1.0004652738571167\n",
      "Train Epoch 338.0 var loss 70938.1484375 reconstruction mse 70935.2265625 imputation mse 0.9981738924980164\n",
      "Train Epoch 338.1 var loss 70955.1875 reconstruction mse 70952.390625 imputation mse 0.9984154105186462\n",
      "Train Epoch 338.2 var loss 70958.671875 reconstruction mse 70955.7890625 imputation mse 0.9984632134437561\n",
      "Train Epoch 338.3 var loss 70970.1328125 reconstruction mse 70967.2578125 imputation mse 0.9986246228218079\n",
      "Train Epoch 338.4 var loss 70942.234375 reconstruction mse 70939.4453125 imputation mse 0.9982332587242126\n",
      "Train Epoch 338.5 var loss 70964.484375 reconstruction mse 70961.8203125 imputation mse 0.9985480904579163\n",
      "Train Epoch 338.6 var loss 70944.3203125 reconstruction mse 70941.75 imputation mse 0.9982656836509705\n",
      "Train Epoch 338.7 var loss 70945.7890625 reconstruction mse 70943.265625 imputation mse 0.9982870221138\n",
      "Train Epoch 338.8 var loss 70972.1796875 reconstruction mse 70969.640625 imputation mse 0.9986581206321716\n",
      "Train Epoch 338.9 var loss 70953.2578125 reconstruction mse 70950.6953125 imputation mse 0.9983915686607361\n",
      "Train Epoch 339.0 var loss 72248.5234375 reconstruction mse 72245.671875 imputation mse 1.0110087394714355\n",
      "Train Epoch 339.1 var loss 72249.65625 reconstruction mse 72246.859375 imputation mse 1.011025309562683\n",
      "Train Epoch 339.2 var loss 72236.8984375 reconstruction mse 72233.9921875 imputation mse 1.0108453035354614\n",
      "Train Epoch 339.3 var loss 72206.1328125 reconstruction mse 72203.25 imputation mse 1.0104150772094727\n",
      "Train Epoch 339.4 var loss 72261.453125 reconstruction mse 72258.6796875 imputation mse 1.0111907720565796\n",
      "Train Epoch 339.5 var loss 72248.1171875 reconstruction mse 72245.4453125 imputation mse 1.0110055208206177\n",
      "Train Epoch 339.6 var loss 72277.7421875 reconstruction mse 72275.1484375 imputation mse 1.0114212036132812\n",
      "Train Epoch 339.7 var loss 72274.921875 reconstruction mse 72272.359375 imputation mse 1.0113822221755981\n",
      "Train Epoch 339.8 var loss 72247.8671875 reconstruction mse 72245.3203125 imputation mse 1.011003851890564\n",
      "Train Epoch 339.9 var loss 72226.140625 reconstruction mse 72223.5625 imputation mse 1.0106992721557617\n",
      "Train Epoch 340.0 var loss 71535.6953125 reconstruction mse 71532.765625 imputation mse 0.9986286163330078\n",
      "Train Epoch 340.1 var loss 71553.859375 reconstruction mse 71551.03125 imputation mse 0.9988836050033569\n",
      "Train Epoch 340.2 var loss 71535.0234375 reconstruction mse 71532.1015625 imputation mse 0.9986193180084229\n",
      "Train Epoch 340.3 var loss 71532.453125 reconstruction mse 71529.515625 imputation mse 0.9985832571983337\n",
      "Train Epoch 340.4 var loss 71559.4765625 reconstruction mse 71556.609375 imputation mse 0.9989614486694336\n",
      "Train Epoch 340.5 var loss 71517.65625 reconstruction mse 71514.8828125 imputation mse 0.9983789324760437\n",
      "Train Epoch 340.6 var loss 71559.6171875 reconstruction mse 71556.9296875 imputation mse 0.9989659190177917\n",
      "Train Epoch 340.7 var loss 71513.3203125 reconstruction mse 71510.7109375 imputation mse 0.9983206987380981\n",
      "Train Epoch 340.8 var loss 71524.8671875 reconstruction mse 71522.25 imputation mse 0.998481810092926\n",
      "Train Epoch 340.9 var loss 71537.34375 reconstruction mse 71534.7109375 imputation mse 0.9986557364463806\n",
      "====> Test imputation mse: 1.01038575\n",
      "====> Test imputation mse: 0.99620676\n",
      "====> Test imputation mse: 1.02085543\n",
      "Train Epoch 341.0 var loss 71935.125 reconstruction mse 71932.1875 imputation mse 1.0069177150726318\n",
      "Train Epoch 341.1 var loss 71920.8828125 reconstruction mse 71918.0234375 imputation mse 1.0067194700241089\n",
      "Train Epoch 341.2 var loss 71930.0390625 reconstruction mse 71927.078125 imputation mse 1.0068461894989014\n",
      "Train Epoch 341.3 var loss 71900.3125 reconstruction mse 71897.3359375 imputation mse 1.00642991065979\n",
      "Train Epoch 341.4 var loss 71928.46875 reconstruction mse 71925.6015625 imputation mse 1.006825566291809\n",
      "Train Epoch 341.5 var loss 71965.0703125 reconstruction mse 71962.328125 imputation mse 1.007339596748352\n",
      "Train Epoch 341.6 var loss 71925.546875 reconstruction mse 71922.9140625 imputation mse 1.006787896156311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 341.7 var loss 71927.3203125 reconstruction mse 71924.734375 imputation mse 1.006813406944275\n",
      "Train Epoch 341.8 var loss 71940.1796875 reconstruction mse 71937.5859375 imputation mse 1.006993293762207\n",
      "Train Epoch 341.9 var loss 71927.265625 reconstruction mse 71924.6171875 imputation mse 1.0068117380142212\n",
      "Train Epoch 342.0 var loss 70958.703125 reconstruction mse 70955.7734375 imputation mse 0.9918612837791443\n",
      "Train Epoch 342.1 var loss 70985.796875 reconstruction mse 70982.8984375 imputation mse 0.9922404885292053\n",
      "Train Epoch 342.2 var loss 70951.703125 reconstruction mse 70948.7109375 imputation mse 0.9917625784873962\n",
      "Train Epoch 342.3 var loss 70971.296875 reconstruction mse 70968.3671875 imputation mse 0.9920373558998108\n",
      "Train Epoch 342.4 var loss 70979.296875 reconstruction mse 70976.46875 imputation mse 0.992150604724884\n",
      "Train Epoch 342.5 var loss 70929.359375 reconstruction mse 70926.6328125 imputation mse 0.9914539456367493\n",
      "Train Epoch 342.6 var loss 70957.3203125 reconstruction mse 70954.6875 imputation mse 0.9918461441993713\n",
      "Train Epoch 342.7 var loss 70956.1171875 reconstruction mse 70953.5234375 imputation mse 0.9918298721313477\n",
      "Train Epoch 342.8 var loss 70996.7578125 reconstruction mse 70994.1796875 imputation mse 0.9923981428146362\n",
      "Train Epoch 342.9 var loss 70942.421875 reconstruction mse 70939.8203125 imputation mse 0.9916383028030396\n",
      "Train Epoch 343.0 var loss 71781.140625 reconstruction mse 71778.21875 imputation mse 1.0068342685699463\n",
      "Train Epoch 343.1 var loss 71795.8125 reconstruction mse 71793.0 imputation mse 1.007041573524475\n",
      "Train Epoch 343.2 var loss 71805.8828125 reconstruction mse 71802.96875 imputation mse 1.0071814060211182\n",
      "Train Epoch 343.3 var loss 71816.5 reconstruction mse 71813.6015625 imputation mse 1.0073305368423462\n",
      "Train Epoch 343.4 var loss 71768.28125 reconstruction mse 71765.4765625 imputation mse 1.0066554546356201\n",
      "Train Epoch 343.5 var loss 71814.0625 reconstruction mse 71811.3671875 imputation mse 1.0072991847991943\n",
      "Train Epoch 343.6 var loss 71808.921875 reconstruction mse 71806.3046875 imputation mse 1.007228136062622\n",
      "Train Epoch 343.7 var loss 71768.5390625 reconstruction mse 71765.96875 imputation mse 1.006662368774414\n",
      "Train Epoch 343.8 var loss 71748.125 reconstruction mse 71745.53125 imputation mse 1.0063756704330444\n",
      "Train Epoch 343.9 var loss 71804.8046875 reconstruction mse 71802.203125 imputation mse 1.0071706771850586\n",
      "Train Epoch 344.0 var loss 71622.34375 reconstruction mse 71619.4609375 imputation mse 1.001152753829956\n",
      "Train Epoch 344.1 var loss 71556.75 reconstruction mse 71553.921875 imputation mse 1.0002365112304688\n",
      "Train Epoch 344.2 var loss 71605.1015625 reconstruction mse 71602.203125 imputation mse 1.0009114742279053\n",
      "Train Epoch 344.3 var loss 71608.2578125 reconstruction mse 71605.3828125 imputation mse 1.0009559392929077\n",
      "Train Epoch 344.4 var loss 71558.7421875 reconstruction mse 71556.0 imputation mse 1.0002655982971191\n",
      "Train Epoch 344.5 var loss 71590.375 reconstruction mse 71587.765625 imputation mse 1.0007096529006958\n",
      "Train Epoch 344.6 var loss 71581.0859375 reconstruction mse 71578.578125 imputation mse 1.0005812644958496\n",
      "Train Epoch 344.7 var loss 71595.953125 reconstruction mse 71593.484375 imputation mse 1.0007895231246948\n",
      "Train Epoch 344.8 var loss 71592.703125 reconstruction mse 71590.2109375 imputation mse 1.0007438659667969\n",
      "Train Epoch 344.9 var loss 71590.859375 reconstruction mse 71588.3125 imputation mse 1.000717282295227\n",
      "Train Epoch 345.0 var loss 71817.3828125 reconstruction mse 71814.4765625 imputation mse 0.998741090297699\n",
      "Train Epoch 345.1 var loss 71845.546875 reconstruction mse 71842.7421875 imputation mse 0.9991341829299927\n",
      "Train Epoch 345.2 var loss 71799.953125 reconstruction mse 71797.0078125 imputation mse 0.9984981417655945\n",
      "Train Epoch 345.3 var loss 71857.1171875 reconstruction mse 71854.1796875 imputation mse 0.9992932081222534\n",
      "Train Epoch 345.4 var loss 71825.2578125 reconstruction mse 71822.390625 imputation mse 0.9988511204719543\n",
      "Train Epoch 345.5 var loss 71839.234375 reconstruction mse 71836.4765625 imputation mse 0.999047040939331\n",
      "Train Epoch 345.6 var loss 71796.3359375 reconstruction mse 71793.6875 imputation mse 0.9984519481658936\n",
      "Train Epoch 345.7 var loss 71839.4375 reconstruction mse 71836.875 imputation mse 0.9990525841712952\n",
      "Train Epoch 345.8 var loss 71818.7578125 reconstruction mse 71816.2265625 imputation mse 0.9987654089927673\n",
      "Train Epoch 345.9 var loss 71829.6953125 reconstruction mse 71827.15625 imputation mse 0.9989174008369446\n",
      "Train Epoch 346.0 var loss 71584.0625 reconstruction mse 71581.1875 imputation mse 0.9992348551750183\n",
      "Train Epoch 346.1 var loss 71585.90625 reconstruction mse 71583.125 imputation mse 0.9992619156837463\n",
      "Train Epoch 346.2 var loss 71570.296875 reconstruction mse 71567.375 imputation mse 0.9990420341491699\n",
      "Train Epoch 346.3 var loss 71573.3125 reconstruction mse 71570.3671875 imputation mse 0.9990838170051575\n",
      "Train Epoch 346.4 var loss 71587.6796875 reconstruction mse 71584.796875 imputation mse 0.9992852210998535\n",
      "Train Epoch 346.5 var loss 71563.0625 reconstruction mse 71560.296875 imputation mse 0.9989432096481323\n",
      "Train Epoch 346.6 var loss 71567.8125 reconstruction mse 71565.1640625 imputation mse 0.9990111589431763\n",
      "Train Epoch 346.7 var loss 71591.0546875 reconstruction mse 71588.4609375 imputation mse 0.9993363618850708\n",
      "Train Epoch 346.8 var loss 71599.8515625 reconstruction mse 71597.2890625 imputation mse 0.9994596242904663\n",
      "Train Epoch 346.9 var loss 71579.1171875 reconstruction mse 71576.5234375 imputation mse 0.9991697669029236\n",
      "Train Epoch 347.0 var loss 71128.59375 reconstruction mse 71125.703125 imputation mse 0.9940977096557617\n",
      "Train Epoch 347.1 var loss 71195.015625 reconstruction mse 71192.21875 imputation mse 0.9950273633003235\n",
      "Train Epoch 347.2 var loss 71138.75 reconstruction mse 71135.859375 imputation mse 0.9942396879196167\n",
      "Train Epoch 347.3 var loss 71123.109375 reconstruction mse 71120.2421875 imputation mse 0.9940214157104492\n",
      "Train Epoch 347.4 var loss 71148.5859375 reconstruction mse 71145.828125 imputation mse 0.9943789839744568\n",
      "Train Epoch 347.5 var loss 71142.3984375 reconstruction mse 71139.7578125 imputation mse 0.9942941665649414\n",
      "Train Epoch 347.6 var loss 71146.6328125 reconstruction mse 71144.0703125 imputation mse 0.9943544268608093\n",
      "Train Epoch 347.7 var loss 71134.3984375 reconstruction mse 71131.875 imputation mse 0.9941839575767517\n",
      "Train Epoch 347.8 var loss 71141.515625 reconstruction mse 71138.9765625 imputation mse 0.9942832589149475\n",
      "Train Epoch 347.9 var loss 71172.2421875 reconstruction mse 71169.6796875 imputation mse 0.9947123527526855\n",
      "Train Epoch 348.0 var loss 71804.890625 reconstruction mse 71802.015625 imputation mse 1.006123661994934\n",
      "Train Epoch 348.1 var loss 71772.875 reconstruction mse 71770.09375 imputation mse 1.0056763887405396\n",
      "Train Epoch 348.2 var loss 71809.1171875 reconstruction mse 71806.234375 imputation mse 1.0061827898025513\n",
      "Train Epoch 348.3 var loss 71789.703125 reconstruction mse 71786.8046875 imputation mse 1.0059105157852173\n",
      "Train Epoch 348.4 var loss 71787.625 reconstruction mse 71784.7890625 imputation mse 1.0058822631835938\n",
      "Train Epoch 348.5 var loss 71778.484375 reconstruction mse 71775.734375 imputation mse 1.0057554244995117\n",
      "Train Epoch 348.6 var loss 71780.578125 reconstruction mse 71777.9140625 imputation mse 1.0057859420776367\n",
      "Train Epoch 348.7 var loss 71761.1875 reconstruction mse 71758.578125 imputation mse 1.0055149793624878\n",
      "Train Epoch 348.8 var loss 71807.828125 reconstruction mse 71805.2265625 imputation mse 1.0061686038970947\n",
      "Train Epoch 348.9 var loss 71780.0546875 reconstruction mse 71777.453125 imputation mse 1.005779504776001\n",
      "Train Epoch 349.0 var loss 71698.1953125 reconstruction mse 71695.3046875 imputation mse 0.9967926144599915\n",
      "Train Epoch 349.1 var loss 71681.8515625 reconstruction mse 71679.046875 imputation mse 0.9965665936470032\n",
      "Train Epoch 349.2 var loss 71677.6484375 reconstruction mse 71674.7578125 imputation mse 0.996506929397583\n",
      "Train Epoch 349.3 var loss 71649.6640625 reconstruction mse 71646.765625 imputation mse 0.9961177706718445\n",
      "Train Epoch 349.4 var loss 71642.71875 reconstruction mse 71639.90625 imputation mse 0.9960224032402039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 349.5 var loss 71663.859375 reconstruction mse 71661.1484375 imputation mse 0.9963177442550659\n",
      "Train Epoch 349.6 var loss 71658.1015625 reconstruction mse 71655.4765625 imputation mse 0.9962388873100281\n",
      "Train Epoch 349.7 var loss 71673.2109375 reconstruction mse 71670.6328125 imputation mse 0.9964495897293091\n",
      "Train Epoch 349.8 var loss 71632.375 reconstruction mse 71629.7734375 imputation mse 0.9958814978599548\n",
      "Train Epoch 349.9 var loss 71633.859375 reconstruction mse 71631.2421875 imputation mse 0.9959019422531128\n",
      "Train Epoch 350.0 var loss 71656.9765625 reconstruction mse 71654.09375 imputation mse 0.9986911416053772\n",
      "Train Epoch 350.1 var loss 71629.421875 reconstruction mse 71626.5703125 imputation mse 0.9983075261116028\n",
      "Train Epoch 350.2 var loss 71653.609375 reconstruction mse 71650.6953125 imputation mse 0.9986438155174255\n",
      "Train Epoch 350.3 var loss 71666.4375 reconstruction mse 71663.5625 imputation mse 0.9988231658935547\n",
      "Train Epoch 350.4 var loss 71641.8203125 reconstruction mse 71639.0234375 imputation mse 0.9984810948371887\n",
      "Train Epoch 350.5 var loss 71660.0234375 reconstruction mse 71657.328125 imputation mse 0.9987362623214722\n",
      "Train Epoch 350.6 var loss 71650.1953125 reconstruction mse 71647.5625 imputation mse 0.9986001253128052\n",
      "Train Epoch 350.7 var loss 71643.8671875 reconstruction mse 71641.2578125 imputation mse 0.9985122680664062\n",
      "Train Epoch 350.8 var loss 71663.7890625 reconstruction mse 71661.15625 imputation mse 0.9987896084785461\n",
      "Train Epoch 350.9 var loss 71651.2578125 reconstruction mse 71648.59375 imputation mse 0.998614490032196\n",
      "====> Test imputation mse: 1.00731349\n",
      "====> Test imputation mse: 1.00489771\n",
      "====> Test imputation mse: 1.00564218\n",
      "Train Epoch 351.0 var loss 72200.9921875 reconstruction mse 72198.078125 imputation mse 1.009749174118042\n",
      "Train Epoch 351.1 var loss 72184.9296875 reconstruction mse 72182.0390625 imputation mse 1.009524941444397\n",
      "Train Epoch 351.2 var loss 72231.8203125 reconstruction mse 72228.8515625 imputation mse 1.0101796388626099\n",
      "Train Epoch 351.3 var loss 72212.5390625 reconstruction mse 72209.6015625 imputation mse 1.0099103450775146\n",
      "Train Epoch 351.4 var loss 72188.1484375 reconstruction mse 72185.328125 imputation mse 1.009570837020874\n",
      "Train Epoch 351.5 var loss 72170.7109375 reconstruction mse 72168.0234375 imputation mse 1.009328842163086\n",
      "Train Epoch 351.6 var loss 72214.609375 reconstruction mse 72212.015625 imputation mse 1.0099440813064575\n",
      "Train Epoch 351.7 var loss 72204.46875 reconstruction mse 72201.9140625 imputation mse 1.0098028182983398\n",
      "Train Epoch 351.8 var loss 72202.6875 reconstruction mse 72200.125 imputation mse 1.0097777843475342\n",
      "Train Epoch 351.9 var loss 72233.578125 reconstruction mse 72230.984375 imputation mse 1.0102094411849976\n",
      "Train Epoch 352.0 var loss 71246.8984375 reconstruction mse 71244.015625 imputation mse 0.9957234859466553\n",
      "Train Epoch 352.1 var loss 71252.3828125 reconstruction mse 71249.5078125 imputation mse 0.995800256729126\n",
      "Train Epoch 352.2 var loss 71223.4609375 reconstruction mse 71220.4765625 imputation mse 0.9953945279121399\n",
      "Train Epoch 352.3 var loss 71261.78125 reconstruction mse 71258.8125 imputation mse 0.9959303140640259\n",
      "Train Epoch 352.4 var loss 71236.546875 reconstruction mse 71233.6484375 imputation mse 0.9955785870552063\n",
      "Train Epoch 352.5 var loss 71285.28125 reconstruction mse 71282.5 imputation mse 0.9962613582611084\n",
      "Train Epoch 352.6 var loss 71257.6796875 reconstruction mse 71254.984375 imputation mse 0.9958767890930176\n",
      "Train Epoch 352.7 var loss 71243.484375 reconstruction mse 71240.859375 imputation mse 0.9956793785095215\n",
      "Train Epoch 352.8 var loss 71219.8671875 reconstruction mse 71217.2734375 imputation mse 0.9953497052192688\n",
      "Train Epoch 352.9 var loss 71219.1328125 reconstruction mse 71216.546875 imputation mse 0.995339572429657\n",
      "Train Epoch 353.0 var loss 72448.4375 reconstruction mse 72445.5859375 imputation mse 1.0111885070800781\n",
      "Train Epoch 353.1 var loss 72490.25 reconstruction mse 72487.46875 imputation mse 1.0117731094360352\n",
      "Train Epoch 353.2 var loss 72464.0078125 reconstruction mse 72461.125 imputation mse 1.011405348777771\n",
      "Train Epoch 353.3 var loss 72484.8515625 reconstruction mse 72481.9765625 imputation mse 1.0116963386535645\n",
      "Train Epoch 353.4 var loss 72483.0078125 reconstruction mse 72480.203125 imputation mse 1.0116716623306274\n",
      "Train Epoch 353.5 var loss 72473.296875 reconstruction mse 72470.5546875 imputation mse 1.011536955833435\n",
      "Train Epoch 353.6 var loss 72513.0703125 reconstruction mse 72510.3984375 imputation mse 1.0120930671691895\n",
      "Train Epoch 353.7 var loss 72462.1796875 reconstruction mse 72459.5234375 imputation mse 1.0113829374313354\n",
      "Train Epoch 353.8 var loss 72513.25 reconstruction mse 72510.5703125 imputation mse 1.0120954513549805\n",
      "Train Epoch 353.9 var loss 72470.75 reconstruction mse 72468.0625 imputation mse 1.0115021467208862\n",
      "Train Epoch 354.0 var loss 72229.265625 reconstruction mse 72226.375 imputation mse 1.009566068649292\n",
      "Train Epoch 354.1 var loss 72257.0859375 reconstruction mse 72254.2109375 imputation mse 1.0099551677703857\n",
      "Train Epoch 354.2 var loss 72221.71875 reconstruction mse 72218.765625 imputation mse 1.0094597339630127\n",
      "Train Epoch 354.3 var loss 72239.7265625 reconstruction mse 72236.8125 imputation mse 1.0097119808197021\n",
      "Train Epoch 354.4 var loss 72220.546875 reconstruction mse 72217.7421875 imputation mse 1.0094454288482666\n",
      "Train Epoch 354.5 var loss 72237.890625 reconstruction mse 72235.1953125 imputation mse 1.0096893310546875\n",
      "Train Epoch 354.6 var loss 72240.78125 reconstruction mse 72238.1796875 imputation mse 1.0097310543060303\n",
      "Train Epoch 354.7 var loss 72220.0625 reconstruction mse 72217.5 imputation mse 1.0094419717788696\n",
      "Train Epoch 354.8 var loss 72235.546875 reconstruction mse 72232.9765625 imputation mse 1.0096583366394043\n",
      "Train Epoch 354.9 var loss 72206.2265625 reconstruction mse 72203.609375 imputation mse 1.009247899055481\n",
      "Train Epoch 355.0 var loss 72199.7890625 reconstruction mse 72196.9140625 imputation mse 1.0127357244491577\n",
      "Train Epoch 355.1 var loss 72198.5546875 reconstruction mse 72195.6796875 imputation mse 1.0127183198928833\n",
      "Train Epoch 355.2 var loss 72204.9453125 reconstruction mse 72201.984375 imputation mse 1.01280677318573\n",
      "Train Epoch 355.3 var loss 72213.078125 reconstruction mse 72210.1328125 imputation mse 1.0129210948944092\n",
      "Train Epoch 355.4 var loss 72198.21875 reconstruction mse 72195.421875 imputation mse 1.0127147436141968\n",
      "Train Epoch 355.5 var loss 72151.4765625 reconstruction mse 72148.828125 imputation mse 1.0120611190795898\n",
      "Train Epoch 355.6 var loss 72197.8515625 reconstruction mse 72195.2890625 imputation mse 1.012712836265564\n",
      "Train Epoch 355.7 var loss 72207.5234375 reconstruction mse 72205.0078125 imputation mse 1.01284921169281\n",
      "Train Epoch 355.8 var loss 72205.2890625 reconstruction mse 72202.71875 imputation mse 1.012817144393921\n",
      "Train Epoch 355.9 var loss 72170.1171875 reconstruction mse 72167.5 imputation mse 1.012323021888733\n",
      "Train Epoch 356.0 var loss 71956.6875 reconstruction mse 71953.8359375 imputation mse 1.0048717260360718\n",
      "Train Epoch 356.1 var loss 72016.421875 reconstruction mse 72013.5859375 imputation mse 1.0057060718536377\n",
      "Train Epoch 356.2 var loss 71993.96875 reconstruction mse 71991.0625 imputation mse 1.0053915977478027\n",
      "Train Epoch 356.3 var loss 71984.4296875 reconstruction mse 71981.5703125 imputation mse 1.0052590370178223\n",
      "Train Epoch 356.4 var loss 71994.5234375 reconstruction mse 71991.7578125 imputation mse 1.0054012537002563\n",
      "Train Epoch 356.5 var loss 71985.359375 reconstruction mse 71982.6796875 imputation mse 1.0052745342254639\n",
      "Train Epoch 356.6 var loss 71960.90625 reconstruction mse 71958.2890625 imputation mse 1.0049338340759277\n",
      "Train Epoch 356.7 var loss 71996.1328125 reconstruction mse 71993.5625 imputation mse 1.0054265260696411\n",
      "Train Epoch 356.8 var loss 71990.4609375 reconstruction mse 71987.8984375 imputation mse 1.0053473711013794\n",
      "Train Epoch 356.9 var loss 71977.4296875 reconstruction mse 71974.84375 imputation mse 1.0051651000976562\n",
      "Train Epoch 357.0 var loss 71216.6875 reconstruction mse 71213.859375 imputation mse 1.0005319118499756\n",
      "Train Epoch 357.1 var loss 71197.6953125 reconstruction mse 71194.9140625 imputation mse 1.0002657175064087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 357.2 var loss 71195.8515625 reconstruction mse 71193.0 imputation mse 1.0002388954162598\n",
      "Train Epoch 357.3 var loss 71169.4921875 reconstruction mse 71166.6484375 imputation mse 0.999868631362915\n",
      "Train Epoch 357.4 var loss 71183.078125 reconstruction mse 71180.3359375 imputation mse 1.0000609159469604\n",
      "Train Epoch 357.5 var loss 71215.4296875 reconstruction mse 71212.8046875 imputation mse 1.0005171298980713\n",
      "Train Epoch 357.6 var loss 71194.703125 reconstruction mse 71192.1484375 imputation mse 1.0002268552780151\n",
      "Train Epoch 357.7 var loss 71201.4140625 reconstruction mse 71198.9140625 imputation mse 1.0003219842910767\n",
      "Train Epoch 357.8 var loss 71195.4765625 reconstruction mse 71192.9375 imputation mse 1.0002379417419434\n",
      "Train Epoch 357.9 var loss 71187.984375 reconstruction mse 71185.421875 imputation mse 1.0001323223114014\n",
      "Train Epoch 358.0 var loss 71416.4140625 reconstruction mse 71413.5546875 imputation mse 1.0004140138626099\n",
      "Train Epoch 358.1 var loss 71470.03125 reconstruction mse 71467.2890625 imputation mse 1.001166820526123\n",
      "Train Epoch 358.2 var loss 71429.3046875 reconstruction mse 71426.5 imputation mse 1.0005953311920166\n",
      "Train Epoch 358.3 var loss 71458.53125 reconstruction mse 71455.7109375 imputation mse 1.0010045766830444\n",
      "Train Epoch 358.4 var loss 71417.390625 reconstruction mse 71414.6484375 imputation mse 1.000429391860962\n",
      "Train Epoch 358.5 var loss 71474.78125 reconstruction mse 71472.15625 imputation mse 1.001235008239746\n",
      "Train Epoch 358.6 var loss 71415.0 reconstruction mse 71412.4765625 imputation mse 1.000398874282837\n",
      "Train Epoch 358.7 var loss 71423.828125 reconstruction mse 71421.34375 imputation mse 1.0005230903625488\n",
      "Train Epoch 358.8 var loss 71460.8046875 reconstruction mse 71458.296875 imputation mse 1.0010408163070679\n",
      "Train Epoch 358.9 var loss 71430.046875 reconstruction mse 71427.46875 imputation mse 1.0006089210510254\n",
      "Train Epoch 359.0 var loss 71634.46875 reconstruction mse 71631.640625 imputation mse 1.00254225730896\n",
      "Train Epoch 359.1 var loss 71659.796875 reconstruction mse 71656.984375 imputation mse 1.0028969049453735\n",
      "Train Epoch 359.2 var loss 71628.921875 reconstruction mse 71626.03125 imputation mse 1.002463698387146\n",
      "Train Epoch 359.3 var loss 71603.3828125 reconstruction mse 71600.515625 imputation mse 1.0021065473556519\n",
      "Train Epoch 359.4 var loss 71671.25 reconstruction mse 71668.5 imputation mse 1.0030580759048462\n",
      "Train Epoch 359.5 var loss 71637.21875 reconstruction mse 71634.609375 imputation mse 1.0025837421417236\n",
      "Train Epoch 359.6 var loss 71632.8203125 reconstruction mse 71630.3203125 imputation mse 1.0025237798690796\n",
      "Train Epoch 359.7 var loss 71649.375 reconstruction mse 71646.9140625 imputation mse 1.0027559995651245\n",
      "Train Epoch 359.8 var loss 71644.1171875 reconstruction mse 71641.65625 imputation mse 1.0026823282241821\n",
      "Train Epoch 359.9 var loss 71650.3125 reconstruction mse 71647.8046875 imputation mse 1.0027683973312378\n",
      "Train Epoch 360.0 var loss 71612.546875 reconstruction mse 71609.7734375 imputation mse 0.9972116947174072\n",
      "Train Epoch 360.1 var loss 71568.0078125 reconstruction mse 71565.21875 imputation mse 0.9965912699699402\n",
      "Train Epoch 360.2 var loss 71561.6953125 reconstruction mse 71558.8046875 imputation mse 0.9965019226074219\n",
      "Train Epoch 360.3 var loss 71585.53125 reconstruction mse 71582.640625 imputation mse 0.996833860874176\n",
      "Train Epoch 360.4 var loss 71579.9453125 reconstruction mse 71577.1640625 imputation mse 0.9967576265335083\n",
      "Train Epoch 360.5 var loss 71594.46875 reconstruction mse 71591.8359375 imputation mse 0.9969619512557983\n",
      "Train Epoch 360.6 var loss 71608.1640625 reconstruction mse 71605.625 imputation mse 0.9971539378166199\n",
      "Train Epoch 360.7 var loss 71576.3515625 reconstruction mse 71573.859375 imputation mse 0.9967116117477417\n",
      "Train Epoch 360.8 var loss 71574.9609375 reconstruction mse 71572.4765625 imputation mse 0.9966923594474792\n",
      "Train Epoch 360.9 var loss 71571.4609375 reconstruction mse 71568.9453125 imputation mse 0.9966431856155396\n",
      "====> Test imputation mse: 0.99508560\n",
      "====> Test imputation mse: 1.01300049\n",
      "====> Test imputation mse: 0.99397951\n",
      "Train Epoch 361.0 var loss 72185.5859375 reconstruction mse 72182.75 imputation mse 1.0087306499481201\n",
      "Train Epoch 361.1 var loss 72157.3984375 reconstruction mse 72154.6328125 imputation mse 1.0083377361297607\n",
      "Train Epoch 361.2 var loss 72155.046875 reconstruction mse 72152.1953125 imputation mse 1.0083036422729492\n",
      "Train Epoch 361.3 var loss 72145.4140625 reconstruction mse 72142.59375 imputation mse 1.0081695318222046\n",
      "Train Epoch 361.4 var loss 72168.234375 reconstruction mse 72165.4921875 imputation mse 1.0084894895553589\n",
      "Train Epoch 361.5 var loss 72168.828125 reconstruction mse 72166.1796875 imputation mse 1.0084991455078125\n",
      "Train Epoch 361.6 var loss 72193.296875 reconstruction mse 72190.7421875 imputation mse 1.0088423490524292\n",
      "Train Epoch 361.7 var loss 72124.3515625 reconstruction mse 72121.8359375 imputation mse 1.007879376411438\n",
      "Train Epoch 361.8 var loss 72165.171875 reconstruction mse 72162.6328125 imputation mse 1.0084495544433594\n",
      "Train Epoch 361.9 var loss 72161.6015625 reconstruction mse 72159.046875 imputation mse 1.008399486541748\n",
      "Train Epoch 362.0 var loss 71222.3203125 reconstruction mse 71219.4609375 imputation mse 1.0001468658447266\n",
      "Train Epoch 362.1 var loss 71263.140625 reconstruction mse 71260.40625 imputation mse 1.0007219314575195\n",
      "Train Epoch 362.2 var loss 71235.8515625 reconstruction mse 71233.046875 imputation mse 1.0003377199172974\n",
      "Train Epoch 362.3 var loss 71244.703125 reconstruction mse 71241.921875 imputation mse 1.000462293624878\n",
      "Train Epoch 362.4 var loss 71240.1953125 reconstruction mse 71237.5 imputation mse 1.000400185585022\n",
      "Train Epoch 362.5 var loss 71260.8671875 reconstruction mse 71258.28125 imputation mse 1.0006920099258423\n",
      "Train Epoch 362.6 var loss 71229.640625 reconstruction mse 71227.125 imputation mse 1.000254511833191\n",
      "Train Epoch 362.7 var loss 71296.6796875 reconstruction mse 71294.1875 imputation mse 1.001196265220642\n",
      "Train Epoch 362.8 var loss 71229.0078125 reconstruction mse 71226.4765625 imputation mse 1.000245451927185\n",
      "Train Epoch 362.9 var loss 71224.90625 reconstruction mse 71222.3046875 imputation mse 1.000186800956726\n",
      "Train Epoch 363.0 var loss 72338.5078125 reconstruction mse 72335.65625 imputation mse 1.0073060989379883\n",
      "Train Epoch 363.1 var loss 72356.375 reconstruction mse 72353.5546875 imputation mse 1.007555365562439\n",
      "Train Epoch 363.2 var loss 72338.4765625 reconstruction mse 72335.5703125 imputation mse 1.0073049068450928\n",
      "Train Epoch 363.3 var loss 72392.4921875 reconstruction mse 72389.6015625 imputation mse 1.0080572366714478\n",
      "Train Epoch 363.4 var loss 72332.765625 reconstruction mse 72329.984375 imputation mse 1.0072270631790161\n",
      "Train Epoch 363.5 var loss 72333.4296875 reconstruction mse 72330.7890625 imputation mse 1.0072382688522339\n",
      "Train Epoch 363.6 var loss 72327.5859375 reconstruction mse 72325.0234375 imputation mse 1.0071580410003662\n",
      "Train Epoch 363.7 var loss 72341.359375 reconstruction mse 72338.8515625 imputation mse 1.0073505640029907\n",
      "Train Epoch 363.8 var loss 72342.96875 reconstruction mse 72340.4140625 imputation mse 1.0073723793029785\n",
      "Train Epoch 363.9 var loss 72343.8671875 reconstruction mse 72341.2421875 imputation mse 1.0073838233947754\n",
      "Train Epoch 364.0 var loss 71162.9375 reconstruction mse 71160.0546875 imputation mse 0.9984993934631348\n",
      "Train Epoch 364.1 var loss 71134.171875 reconstruction mse 71131.28125 imputation mse 0.9980956315994263\n",
      "Train Epoch 364.2 var loss 71133.0 reconstruction mse 71130.0234375 imputation mse 0.9980779886245728\n",
      "Train Epoch 364.3 var loss 71153.78125 reconstruction mse 71150.8671875 imputation mse 0.9983704686164856\n",
      "Train Epoch 364.4 var loss 71154.8203125 reconstruction mse 71152.0390625 imputation mse 0.9983869194984436\n",
      "Train Epoch 364.5 var loss 71134.1640625 reconstruction mse 71131.5703125 imputation mse 0.998099684715271\n",
      "Train Epoch 364.6 var loss 71106.6484375 reconstruction mse 71104.1796875 imputation mse 0.9977153539657593\n",
      "Train Epoch 364.7 var loss 71085.5 reconstruction mse 71083.046875 imputation mse 0.9974188208580017\n",
      "Train Epoch 364.8 var loss 71148.4453125 reconstruction mse 71145.9609375 imputation mse 0.99830162525177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 364.9 var loss 71152.0859375 reconstruction mse 71149.5078125 imputation mse 0.9983513951301575\n",
      "Train Epoch 365.0 var loss 71381.359375 reconstruction mse 71378.5390625 imputation mse 0.998748242855072\n",
      "Train Epoch 365.1 var loss 71375.078125 reconstruction mse 71372.2265625 imputation mse 0.9986599087715149\n",
      "Train Epoch 365.2 var loss 71419.703125 reconstruction mse 71416.7578125 imputation mse 0.9992830157279968\n",
      "Train Epoch 365.3 var loss 71403.375 reconstruction mse 71400.4609375 imputation mse 0.9990549683570862\n",
      "Train Epoch 365.4 var loss 71442.8515625 reconstruction mse 71440.1015625 imputation mse 0.999609649181366\n",
      "Train Epoch 365.5 var loss 71387.1015625 reconstruction mse 71384.5234375 imputation mse 0.9988319873809814\n",
      "Train Epoch 365.6 var loss 71398.5625 reconstruction mse 71396.1015625 imputation mse 0.998993992805481\n",
      "Train Epoch 365.7 var loss 71433.9140625 reconstruction mse 71431.4765625 imputation mse 0.9994889497756958\n",
      "Train Epoch 365.8 var loss 71389.9765625 reconstruction mse 71387.515625 imputation mse 0.9988738298416138\n",
      "Train Epoch 365.9 var loss 71399.453125 reconstruction mse 71396.8984375 imputation mse 0.999005138874054\n",
      "Train Epoch 366.0 var loss 72284.03125 reconstruction mse 72281.234375 imputation mse 1.0071372985839844\n",
      "Train Epoch 366.1 var loss 72251.984375 reconstruction mse 72249.15625 imputation mse 1.006690263748169\n",
      "Train Epoch 366.2 var loss 72270.9375 reconstruction mse 72268.015625 imputation mse 1.0069531202316284\n",
      "Train Epoch 366.3 var loss 72266.046875 reconstruction mse 72263.1796875 imputation mse 1.0068856477737427\n",
      "Train Epoch 366.4 var loss 72264.7890625 reconstruction mse 72262.0625 imputation mse 1.006870150566101\n",
      "Train Epoch 366.5 var loss 72266.6953125 reconstruction mse 72264.1015625 imputation mse 1.0068985223770142\n",
      "Train Epoch 366.6 var loss 72295.375 reconstruction mse 72292.875 imputation mse 1.0072994232177734\n",
      "Train Epoch 366.7 var loss 72292.015625 reconstruction mse 72289.5703125 imputation mse 1.0072534084320068\n",
      "Train Epoch 366.8 var loss 72267.640625 reconstruction mse 72265.171875 imputation mse 1.006913423538208\n",
      "Train Epoch 366.9 var loss 72230.9453125 reconstruction mse 72228.4140625 imputation mse 1.0064013004302979\n",
      "Train Epoch 367.0 var loss 71031.453125 reconstruction mse 71028.6640625 imputation mse 0.9997559785842896\n",
      "Train Epoch 367.1 var loss 71008.984375 reconstruction mse 71006.2265625 imputation mse 0.9994401931762695\n",
      "Train Epoch 367.2 var loss 71007.5703125 reconstruction mse 71004.71875 imputation mse 0.9994189739227295\n",
      "Train Epoch 367.3 var loss 70988.421875 reconstruction mse 70985.59375 imputation mse 0.999149739742279\n",
      "Train Epoch 367.4 var loss 70977.9453125 reconstruction mse 70975.1875 imputation mse 0.9990032911300659\n",
      "Train Epoch 367.5 var loss 70982.9453125 reconstruction mse 70980.3046875 imputation mse 0.9990752935409546\n",
      "Train Epoch 367.6 var loss 70997.3359375 reconstruction mse 70994.7734375 imputation mse 0.9992789626121521\n",
      "Train Epoch 367.7 var loss 71011.5546875 reconstruction mse 71009.0 imputation mse 0.9994792342185974\n",
      "Train Epoch 367.8 var loss 71012.6875 reconstruction mse 71010.125 imputation mse 0.9994950294494629\n",
      "Train Epoch 367.9 var loss 70984.5546875 reconstruction mse 70981.984375 imputation mse 0.9990989565849304\n",
      "Train Epoch 368.0 var loss 72077.953125 reconstruction mse 72075.15625 imputation mse 1.0069456100463867\n",
      "Train Epoch 368.1 var loss 72097.2890625 reconstruction mse 72094.5546875 imputation mse 1.0072166919708252\n",
      "Train Epoch 368.2 var loss 72100.8125 reconstruction mse 72098.03125 imputation mse 1.0072652101516724\n",
      "Train Epoch 368.3 var loss 72092.875 reconstruction mse 72090.109375 imputation mse 1.0071545839309692\n",
      "Train Epoch 368.4 var loss 72093.5546875 reconstruction mse 72090.8828125 imputation mse 1.0071653127670288\n",
      "Train Epoch 368.5 var loss 72089.9296875 reconstruction mse 72087.34375 imputation mse 1.0071159601211548\n",
      "Train Epoch 368.6 var loss 72087.9921875 reconstruction mse 72085.46875 imputation mse 1.0070897340774536\n",
      "Train Epoch 368.7 var loss 72109.828125 reconstruction mse 72107.3359375 imputation mse 1.0073952674865723\n",
      "Train Epoch 368.8 var loss 72087.7421875 reconstruction mse 72085.2578125 imputation mse 1.0070867538452148\n",
      "Train Epoch 368.9 var loss 72091.390625 reconstruction mse 72088.890625 imputation mse 1.0071375370025635\n",
      "Train Epoch 369.0 var loss 71592.921875 reconstruction mse 71590.171875 imputation mse 1.0001840591430664\n",
      "Train Epoch 369.1 var loss 71587.3671875 reconstruction mse 71584.6875 imputation mse 1.0001074075698853\n",
      "Train Epoch 369.2 var loss 71566.9609375 reconstruction mse 71564.1875 imputation mse 0.9998210072517395\n",
      "Train Epoch 369.3 var loss 71560.875 reconstruction mse 71558.1015625 imputation mse 0.999735951423645\n",
      "Train Epoch 369.4 var loss 71531.4296875 reconstruction mse 71528.7109375 imputation mse 0.9993253350257874\n",
      "Train Epoch 369.5 var loss 71574.9375 reconstruction mse 71572.3203125 imputation mse 0.9999346137046814\n",
      "Train Epoch 369.6 var loss 71541.5234375 reconstruction mse 71539.0078125 imputation mse 0.9994692206382751\n",
      "Train Epoch 369.7 var loss 71527.5 reconstruction mse 71525.0546875 imputation mse 0.9992742538452148\n",
      "Train Epoch 369.8 var loss 71542.28125 reconstruction mse 71539.8359375 imputation mse 0.9994807839393616\n",
      "Train Epoch 369.9 var loss 71559.1953125 reconstruction mse 71556.7109375 imputation mse 0.9997165203094482\n",
      "Train Epoch 370.0 var loss 72279.4609375 reconstruction mse 72276.7109375 imputation mse 1.009296178817749\n",
      "Train Epoch 370.1 var loss 72292.0390625 reconstruction mse 72289.296875 imputation mse 1.0094720125198364\n",
      "Train Epoch 370.2 var loss 72324.1640625 reconstruction mse 72321.328125 imputation mse 1.009919285774231\n",
      "Train Epoch 370.3 var loss 72287.5625 reconstruction mse 72284.78125 imputation mse 1.009408950805664\n",
      "Train Epoch 370.4 var loss 72273.3359375 reconstruction mse 72270.671875 imputation mse 1.0092118978500366\n",
      "Train Epoch 370.5 var loss 72274.578125 reconstruction mse 72272.0234375 imputation mse 1.0092307329177856\n",
      "Train Epoch 370.6 var loss 72262.6796875 reconstruction mse 72260.1953125 imputation mse 1.0090656280517578\n",
      "Train Epoch 370.7 var loss 72295.1640625 reconstruction mse 72292.7109375 imputation mse 1.0095196962356567\n",
      "Train Epoch 370.8 var loss 72272.0234375 reconstruction mse 72269.5703125 imputation mse 1.0091965198516846\n",
      "Train Epoch 370.9 var loss 72322.3125 reconstruction mse 72319.8359375 imputation mse 1.0098984241485596\n",
      "====> Test imputation mse: 0.99650705\n",
      "====> Test imputation mse: 1.00241792\n",
      "====> Test imputation mse: 1.00972712\n",
      "Train Epoch 371.0 var loss 71012.046875 reconstruction mse 71009.3125 imputation mse 0.9939852356910706\n",
      "Train Epoch 371.1 var loss 70995.3515625 reconstruction mse 70992.6484375 imputation mse 0.9937520027160645\n",
      "Train Epoch 371.2 var loss 71038.6328125 reconstruction mse 71035.859375 imputation mse 0.9943568706512451\n",
      "Train Epoch 371.3 var loss 71023.8203125 reconstruction mse 71021.09375 imputation mse 0.9941501617431641\n",
      "Train Epoch 371.4 var loss 71039.3515625 reconstruction mse 71036.6953125 imputation mse 0.9943685531616211\n",
      "Train Epoch 371.5 var loss 71029.3984375 reconstruction mse 71026.8203125 imputation mse 0.994230329990387\n",
      "Train Epoch 371.6 var loss 71013.9140625 reconstruction mse 71011.421875 imputation mse 0.9940147995948792\n",
      "Train Epoch 371.7 var loss 71030.7421875 reconstruction mse 71028.3046875 imputation mse 0.9942511320114136\n",
      "Train Epoch 371.8 var loss 70994.9921875 reconstruction mse 70992.5546875 imputation mse 0.9937506914138794\n",
      "Train Epoch 371.9 var loss 71025.2109375 reconstruction mse 71022.7109375 imputation mse 0.9941728115081787\n",
      "Train Epoch 372.0 var loss 71900.9296875 reconstruction mse 71898.1875 imputation mse 1.011055588722229\n",
      "Train Epoch 372.1 var loss 71878.3125 reconstruction mse 71875.5859375 imputation mse 1.0107377767562866\n",
      "Train Epoch 372.2 var loss 71883.7421875 reconstruction mse 71880.9609375 imputation mse 1.0108133554458618\n",
      "Train Epoch 372.3 var loss 71875.5859375 reconstruction mse 71872.8203125 imputation mse 1.010698914527893\n",
      "Train Epoch 372.4 var loss 71886.28125 reconstruction mse 71883.6015625 imputation mse 1.0108505487442017\n",
      "Train Epoch 372.5 var loss 71864.1171875 reconstruction mse 71861.5546875 imputation mse 1.01054048538208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 372.6 var loss 71818.4375 reconstruction mse 71815.9609375 imputation mse 1.009899377822876\n",
      "Train Epoch 372.7 var loss 71854.6171875 reconstruction mse 71852.1796875 imputation mse 1.010408639907837\n",
      "Train Epoch 372.8 var loss 71910.8515625 reconstruction mse 71908.3828125 imputation mse 1.0111989974975586\n",
      "Train Epoch 372.9 var loss 71919.390625 reconstruction mse 71916.890625 imputation mse 1.0113186836242676\n",
      "Train Epoch 373.0 var loss 71492.2421875 reconstruction mse 71489.5 imputation mse 0.997370183467865\n",
      "Train Epoch 373.1 var loss 71542.7265625 reconstruction mse 71540.0 imputation mse 0.9980747103691101\n",
      "Train Epoch 373.2 var loss 71571.0625 reconstruction mse 71568.2109375 imputation mse 0.998468279838562\n",
      "Train Epoch 373.3 var loss 71499.328125 reconstruction mse 71496.4765625 imputation mse 0.9974675178527832\n",
      "Train Epoch 373.4 var loss 71523.6015625 reconstruction mse 71520.828125 imputation mse 0.9978072643280029\n",
      "Train Epoch 373.5 var loss 71509.6015625 reconstruction mse 71506.9609375 imputation mse 0.997613787651062\n",
      "Train Epoch 373.6 var loss 71527.046875 reconstruction mse 71524.53125 imputation mse 0.9978589415550232\n",
      "Train Epoch 373.7 var loss 71530.421875 reconstruction mse 71527.9765625 imputation mse 0.9979069828987122\n",
      "Train Epoch 373.8 var loss 71550.640625 reconstruction mse 71548.203125 imputation mse 0.9981891512870789\n",
      "Train Epoch 373.9 var loss 71524.9453125 reconstruction mse 71522.46875 imputation mse 0.9978301525115967\n",
      "Train Epoch 374.0 var loss 71904.2578125 reconstruction mse 71901.515625 imputation mse 1.000814437866211\n",
      "Train Epoch 374.1 var loss 71891.8671875 reconstruction mse 71889.1796875 imputation mse 1.0006427764892578\n",
      "Train Epoch 374.2 var loss 71884.765625 reconstruction mse 71882.015625 imputation mse 1.0005431175231934\n",
      "Train Epoch 374.3 var loss 71898.8203125 reconstruction mse 71896.0859375 imputation mse 1.0007388591766357\n",
      "Train Epoch 374.4 var loss 71880.703125 reconstruction mse 71878.03125 imputation mse 1.0004875659942627\n",
      "Train Epoch 374.5 var loss 71890.6953125 reconstruction mse 71888.09375 imputation mse 1.0006276369094849\n",
      "Train Epoch 374.6 var loss 71917.140625 reconstruction mse 71914.6328125 imputation mse 1.0009970664978027\n",
      "Train Epoch 374.7 var loss 71911.2890625 reconstruction mse 71908.8203125 imputation mse 1.0009161233901978\n",
      "Train Epoch 374.8 var loss 71907.46875 reconstruction mse 71905.015625 imputation mse 1.0008631944656372\n",
      "Train Epoch 374.9 var loss 71914.9140625 reconstruction mse 71912.46875 imputation mse 1.0009669065475464\n",
      "Train Epoch 375.0 var loss 72516.4375 reconstruction mse 72513.7421875 imputation mse 1.0137953758239746\n",
      "Train Epoch 375.1 var loss 72560.671875 reconstruction mse 72558.03125 imputation mse 1.0144145488739014\n",
      "Train Epoch 375.2 var loss 72597.546875 reconstruction mse 72594.8046875 imputation mse 1.0149286985397339\n",
      "Train Epoch 375.3 var loss 72535.6328125 reconstruction mse 72532.890625 imputation mse 1.0140631198883057\n",
      "Train Epoch 375.4 var loss 72537.1640625 reconstruction mse 72534.515625 imputation mse 1.0140857696533203\n",
      "Train Epoch 375.5 var loss 72495.953125 reconstruction mse 72493.4140625 imputation mse 1.0135111808776855\n",
      "Train Epoch 375.6 var loss 72538.15625 reconstruction mse 72535.6796875 imputation mse 1.0141021013259888\n",
      "Train Epoch 375.7 var loss 72517.3828125 reconstruction mse 72514.953125 imputation mse 1.0138123035430908\n",
      "Train Epoch 375.8 var loss 72544.9921875 reconstruction mse 72542.5546875 imputation mse 1.0141981840133667\n",
      "Train Epoch 375.9 var loss 72494.0859375 reconstruction mse 72491.609375 imputation mse 1.0134859085083008\n",
      "Train Epoch 376.0 var loss 71896.46875 reconstruction mse 71893.78125 imputation mse 1.005563735961914\n",
      "Train Epoch 376.1 var loss 71885.96875 reconstruction mse 71883.3203125 imputation mse 1.0054173469543457\n",
      "Train Epoch 376.2 var loss 71881.0390625 reconstruction mse 71878.3359375 imputation mse 1.0053476095199585\n",
      "Train Epoch 376.3 var loss 71904.59375 reconstruction mse 71901.9140625 imputation mse 1.0056774616241455\n",
      "Train Epoch 376.4 var loss 71874.0234375 reconstruction mse 71871.4140625 imputation mse 1.0052508115768433\n",
      "Train Epoch 376.5 var loss 71850.09375 reconstruction mse 71847.5390625 imputation mse 1.0049169063568115\n",
      "Train Epoch 376.6 var loss 71861.3046875 reconstruction mse 71858.8046875 imputation mse 1.0050745010375977\n",
      "Train Epoch 376.7 var loss 71871.5234375 reconstruction mse 71869.03125 imputation mse 1.0052175521850586\n",
      "Train Epoch 376.8 var loss 71887.2734375 reconstruction mse 71884.7890625 imputation mse 1.005437970161438\n",
      "Train Epoch 376.9 var loss 71898.1171875 reconstruction mse 71895.625 imputation mse 1.005589485168457\n",
      "Train Epoch 377.0 var loss 71076.7109375 reconstruction mse 71074.0 imputation mse 0.9942644238471985\n",
      "Train Epoch 377.1 var loss 71072.2734375 reconstruction mse 71069.6015625 imputation mse 0.9942029118537903\n",
      "Train Epoch 377.2 var loss 71095.2265625 reconstruction mse 71092.4765625 imputation mse 0.9945229291915894\n",
      "Train Epoch 377.3 var loss 71054.8828125 reconstruction mse 71052.140625 imputation mse 0.9939586520195007\n",
      "Train Epoch 377.4 var loss 71063.2109375 reconstruction mse 71060.546875 imputation mse 0.9940762519836426\n",
      "Train Epoch 377.5 var loss 71087.359375 reconstruction mse 71084.8046875 imputation mse 0.9944155812263489\n",
      "Train Epoch 377.6 var loss 71044.9375 reconstruction mse 71042.46875 imputation mse 0.9938233494758606\n",
      "Train Epoch 377.7 var loss 71062.703125 reconstruction mse 71060.2734375 imputation mse 0.994072437286377\n",
      "Train Epoch 377.8 var loss 71067.515625 reconstruction mse 71065.1171875 imputation mse 0.9941402077674866\n",
      "Train Epoch 377.9 var loss 71073.0078125 reconstruction mse 71070.59375 imputation mse 0.994216799736023\n",
      "Train Epoch 378.0 var loss 71587.390625 reconstruction mse 71584.7109375 imputation mse 1.0000518560409546\n",
      "Train Epoch 378.1 var loss 71588.140625 reconstruction mse 71585.5390625 imputation mse 1.000063419342041\n",
      "Train Epoch 378.2 var loss 71600.0234375 reconstruction mse 71597.328125 imputation mse 1.0002280473709106\n",
      "Train Epoch 378.3 var loss 71636.125 reconstruction mse 71633.4375 imputation mse 1.0007325410842896\n",
      "Train Epoch 378.4 var loss 71580.8046875 reconstruction mse 71578.203125 imputation mse 0.9999608993530273\n",
      "Train Epoch 378.5 var loss 71620.9453125 reconstruction mse 71618.4453125 imputation mse 1.0005230903625488\n",
      "Train Epoch 378.6 var loss 71626.2578125 reconstruction mse 71623.828125 imputation mse 1.0005983114242554\n",
      "Train Epoch 378.7 var loss 71609.046875 reconstruction mse 71606.6328125 imputation mse 1.0003581047058105\n",
      "Train Epoch 378.8 var loss 71602.1953125 reconstruction mse 71599.765625 imputation mse 1.0002621412277222\n",
      "Train Epoch 378.9 var loss 71634.1875 reconstruction mse 71631.7265625 imputation mse 1.0007086992263794\n",
      "Train Epoch 379.0 var loss 71599.2265625 reconstruction mse 71596.53125 imputation mse 1.0000213384628296\n",
      "Train Epoch 379.1 var loss 71583.796875 reconstruction mse 71581.140625 imputation mse 0.9998064041137695\n",
      "Train Epoch 379.2 var loss 71603.2578125 reconstruction mse 71600.515625 imputation mse 1.0000770092010498\n",
      "Train Epoch 379.3 var loss 71610.3671875 reconstruction mse 71607.65625 imputation mse 1.0001767873764038\n",
      "Train Epoch 379.4 var loss 71611.265625 reconstruction mse 71608.609375 imputation mse 1.0001901388168335\n",
      "Train Epoch 379.5 var loss 71605.09375 reconstruction mse 71602.5390625 imputation mse 1.0001052618026733\n",
      "Train Epoch 379.6 var loss 71600.2734375 reconstruction mse 71597.765625 imputation mse 1.0000386238098145\n",
      "Train Epoch 379.7 var loss 71635.2109375 reconstruction mse 71632.734375 imputation mse 1.000527024269104\n",
      "Train Epoch 379.8 var loss 71582.9140625 reconstruction mse 71580.4375 imputation mse 0.9997965693473816\n",
      "Train Epoch 379.9 var loss 71601.1875 reconstruction mse 71598.7109375 imputation mse 1.0000518560409546\n",
      "Train Epoch 380.0 var loss 71335.171875 reconstruction mse 71332.4921875 imputation mse 0.9970157742500305\n",
      "Train Epoch 380.1 var loss 71309.09375 reconstruction mse 71306.421875 imputation mse 0.9966514110565186\n",
      "Train Epoch 380.2 var loss 71336.390625 reconstruction mse 71333.6328125 imputation mse 0.9970317482948303\n",
      "Train Epoch 380.3 var loss 71377.625 reconstruction mse 71374.8671875 imputation mse 0.9976080656051636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 380.4 var loss 71343.375 reconstruction mse 71340.6953125 imputation mse 0.9971304535865784\n",
      "Train Epoch 380.5 var loss 71339.609375 reconstruction mse 71337.0390625 imputation mse 0.9970793724060059\n",
      "Train Epoch 380.6 var loss 71320.875 reconstruction mse 71318.390625 imputation mse 0.9968187212944031\n",
      "Train Epoch 380.7 var loss 71305.3828125 reconstruction mse 71302.9296875 imputation mse 0.9966025948524475\n",
      "Train Epoch 380.8 var loss 71334.6328125 reconstruction mse 71332.1640625 imputation mse 0.9970111846923828\n",
      "Train Epoch 380.9 var loss 71296.0859375 reconstruction mse 71293.609375 imputation mse 0.9964723587036133\n",
      "====> Test imputation mse: 1.00242054\n",
      "====> Test imputation mse: 0.99903017\n",
      "====> Test imputation mse: 1.00588822\n",
      "Train Epoch 381.0 var loss 71640.8828125 reconstruction mse 71638.1484375 imputation mse 0.9996532201766968\n",
      "Train Epoch 381.1 var loss 71655.375 reconstruction mse 71652.6953125 imputation mse 0.9998562335968018\n",
      "Train Epoch 381.2 var loss 71607.25 reconstruction mse 71604.4765625 imputation mse 0.9991833567619324\n",
      "Train Epoch 381.3 var loss 71618.921875 reconstruction mse 71616.1484375 imputation mse 0.9993461966514587\n",
      "Train Epoch 381.4 var loss 71669.3984375 reconstruction mse 71666.7265625 imputation mse 1.0000519752502441\n",
      "Train Epoch 381.5 var loss 71628.3359375 reconstruction mse 71625.7734375 imputation mse 0.9994805455207825\n",
      "Train Epoch 381.6 var loss 71648.1640625 reconstruction mse 71645.6953125 imputation mse 0.9997585415840149\n",
      "Train Epoch 381.7 var loss 71645.8125 reconstruction mse 71643.421875 imputation mse 0.9997268319129944\n",
      "Train Epoch 381.8 var loss 71631.703125 reconstruction mse 71629.296875 imputation mse 0.9995297193527222\n",
      "Train Epoch 381.9 var loss 71645.8984375 reconstruction mse 71643.4375 imputation mse 0.9997270107269287\n",
      "Train Epoch 382.0 var loss 72021.875 reconstruction mse 72019.140625 imputation mse 1.0061490535736084\n",
      "Train Epoch 382.1 var loss 72029.875 reconstruction mse 72027.171875 imputation mse 1.0062612295150757\n",
      "Train Epoch 382.2 var loss 72084.0546875 reconstruction mse 72081.2421875 imputation mse 1.007016658782959\n",
      "Train Epoch 382.3 var loss 72020.546875 reconstruction mse 72017.75 imputation mse 1.0061296224594116\n",
      "Train Epoch 382.4 var loss 72032.8359375 reconstruction mse 72030.1328125 imputation mse 1.0063025951385498\n",
      "Train Epoch 382.5 var loss 72039.0625 reconstruction mse 72036.4765625 imputation mse 1.006391167640686\n",
      "Train Epoch 382.6 var loss 72047.3828125 reconstruction mse 72044.90625 imputation mse 1.0065089464187622\n",
      "Train Epoch 382.7 var loss 72047.1953125 reconstruction mse 72044.7421875 imputation mse 1.0065066814422607\n",
      "Train Epoch 382.8 var loss 72043.5390625 reconstruction mse 72041.078125 imputation mse 1.0064555406570435\n",
      "Train Epoch 382.9 var loss 72039.9765625 reconstruction mse 72037.4765625 imputation mse 1.006405234336853\n",
      "Train Epoch 383.0 var loss 72359.0546875 reconstruction mse 72356.359375 imputation mse 1.0116658210754395\n",
      "Train Epoch 383.1 var loss 72387.171875 reconstruction mse 72384.46875 imputation mse 1.0120587348937988\n",
      "Train Epoch 383.2 var loss 72423.84375 reconstruction mse 72421.0390625 imputation mse 1.0125701427459717\n",
      "Train Epoch 383.3 var loss 72399.4609375 reconstruction mse 72396.6640625 imputation mse 1.012229323387146\n",
      "Train Epoch 383.4 var loss 72381.796875 reconstruction mse 72379.0546875 imputation mse 1.011983036994934\n",
      "Train Epoch 383.5 var loss 72360.6328125 reconstruction mse 72358.0 imputation mse 1.0116887092590332\n",
      "Train Epoch 383.6 var loss 72407.203125 reconstruction mse 72404.6484375 imputation mse 1.0123409032821655\n",
      "Train Epoch 383.7 var loss 72394.34375 reconstruction mse 72391.84375 imputation mse 1.0121618509292603\n",
      "Train Epoch 383.8 var loss 72400.7109375 reconstruction mse 72398.2265625 imputation mse 1.0122511386871338\n",
      "Train Epoch 383.9 var loss 72417.15625 reconstruction mse 72414.65625 imputation mse 1.0124808549880981\n",
      "Train Epoch 384.0 var loss 71535.1640625 reconstruction mse 71532.4453125 imputation mse 0.9995171427726746\n",
      "Train Epoch 384.1 var loss 71512.7578125 reconstruction mse 71510.0234375 imputation mse 0.9992038607597351\n",
      "Train Epoch 384.2 var loss 71534.15625 reconstruction mse 71531.328125 imputation mse 0.9995015859603882\n",
      "Train Epoch 384.3 var loss 71514.9609375 reconstruction mse 71512.140625 imputation mse 0.9992334246635437\n",
      "Train Epoch 384.4 var loss 71535.1328125 reconstruction mse 71532.3984375 imputation mse 0.999516487121582\n",
      "Train Epoch 384.5 var loss 71513.1953125 reconstruction mse 71510.5859375 imputation mse 0.9992117285728455\n",
      "Train Epoch 384.6 var loss 71548.2890625 reconstruction mse 71545.796875 imputation mse 0.9997037053108215\n",
      "Train Epoch 384.7 var loss 71517.359375 reconstruction mse 71514.9296875 imputation mse 0.9992724061012268\n",
      "Train Epoch 384.8 var loss 71565.890625 reconstruction mse 71563.4765625 imputation mse 0.9999507665634155\n",
      "Train Epoch 384.9 var loss 71515.4609375 reconstruction mse 71513.03125 imputation mse 0.9992458820343018\n",
      "Train Epoch 385.0 var loss 70758.609375 reconstruction mse 70755.9296875 imputation mse 0.9961555004119873\n",
      "Train Epoch 385.1 var loss 70768.984375 reconstruction mse 70766.34375 imputation mse 0.9963021278381348\n",
      "Train Epoch 385.2 var loss 70756.5625 reconstruction mse 70753.8125 imputation mse 0.9961256980895996\n",
      "Train Epoch 385.3 var loss 70780.4765625 reconstruction mse 70777.734375 imputation mse 0.9964624643325806\n",
      "Train Epoch 385.4 var loss 70791.140625 reconstruction mse 70788.4765625 imputation mse 0.9966137409210205\n",
      "Train Epoch 385.5 var loss 70734.1875 reconstruction mse 70731.625 imputation mse 0.9958133101463318\n",
      "Train Epoch 385.6 var loss 70784.0546875 reconstruction mse 70781.5859375 imputation mse 0.9965167045593262\n",
      "Train Epoch 385.7 var loss 70760.9375 reconstruction mse 70758.5078125 imputation mse 0.9961917996406555\n",
      "Train Epoch 385.8 var loss 70744.0 reconstruction mse 70741.5625 imputation mse 0.9959532618522644\n",
      "Train Epoch 385.9 var loss 70737.9140625 reconstruction mse 70735.46875 imputation mse 0.9958674311637878\n",
      "Train Epoch 386.0 var loss 71839.546875 reconstruction mse 71836.890625 imputation mse 1.0072616338729858\n",
      "Train Epoch 386.1 var loss 71875.890625 reconstruction mse 71873.2734375 imputation mse 1.0077717304229736\n",
      "Train Epoch 386.2 var loss 71833.2421875 reconstruction mse 71830.5703125 imputation mse 1.00717294216156\n",
      "Train Epoch 386.3 var loss 71854.0234375 reconstruction mse 71851.375 imputation mse 1.0074646472930908\n",
      "Train Epoch 386.4 var loss 71893.8671875 reconstruction mse 71891.3046875 imputation mse 1.0080245733261108\n",
      "Train Epoch 386.5 var loss 71838.4609375 reconstruction mse 71835.9921875 imputation mse 1.0072489976882935\n",
      "Train Epoch 386.6 var loss 71849.2421875 reconstruction mse 71846.8203125 imputation mse 1.0074008703231812\n",
      "Train Epoch 386.7 var loss 71851.71875 reconstruction mse 71849.3125 imputation mse 1.0074357986450195\n",
      "Train Epoch 386.8 var loss 71821.3984375 reconstruction mse 71818.96875 imputation mse 1.0070103406906128\n",
      "Train Epoch 386.9 var loss 71850.40625 reconstruction mse 71847.9609375 imputation mse 1.007416844367981\n",
      "Train Epoch 387.0 var loss 71327.09375 reconstruction mse 71324.421875 imputation mse 0.9956088662147522\n",
      "Train Epoch 387.1 var loss 71323.3203125 reconstruction mse 71320.71875 imputation mse 0.9955571293830872\n",
      "Train Epoch 387.2 var loss 71299.9921875 reconstruction mse 71297.3125 imputation mse 0.9952304363250732\n",
      "Train Epoch 387.3 var loss 71358.4375 reconstruction mse 71355.7734375 imputation mse 0.9960464835166931\n",
      "Train Epoch 387.4 var loss 71363.3203125 reconstruction mse 71360.7265625 imputation mse 0.9961156249046326\n",
      "Train Epoch 387.5 var loss 71342.5859375 reconstruction mse 71340.0625 imputation mse 0.9958271384239197\n",
      "Train Epoch 387.6 var loss 71354.3828125 reconstruction mse 71351.9375 imputation mse 0.9959929585456848\n",
      "Train Epoch 387.7 var loss 71347.84375 reconstruction mse 71345.4453125 imputation mse 0.9959022998809814\n",
      "Train Epoch 387.8 var loss 71339.0703125 reconstruction mse 71336.6796875 imputation mse 0.9957799315452576\n",
      "Train Epoch 387.9 var loss 71314.1328125 reconstruction mse 71311.75 imputation mse 0.9954319596290588\n",
      "Train Epoch 388.0 var loss 72471.5234375 reconstruction mse 72468.8515625 imputation mse 1.0100610256195068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 388.1 var loss 72453.5625 reconstruction mse 72451.015625 imputation mse 1.0098124742507935\n",
      "Train Epoch 388.2 var loss 72486.4453125 reconstruction mse 72483.8125 imputation mse 1.0102696418762207\n",
      "Train Epoch 388.3 var loss 72462.9140625 reconstruction mse 72460.265625 imputation mse 1.0099414587020874\n",
      "Train Epoch 388.4 var loss 72478.4453125 reconstruction mse 72475.84375 imputation mse 1.0101585388183594\n",
      "Train Epoch 388.5 var loss 72496.6640625 reconstruction mse 72494.125 imputation mse 1.0104132890701294\n",
      "Train Epoch 388.6 var loss 72469.96875 reconstruction mse 72467.5 imputation mse 1.0100421905517578\n",
      "Train Epoch 388.7 var loss 72465.921875 reconstruction mse 72463.4609375 imputation mse 1.0099859237670898\n",
      "Train Epoch 388.8 var loss 72468.234375 reconstruction mse 72465.7734375 imputation mse 1.0100181102752686\n",
      "Train Epoch 388.9 var loss 72444.078125 reconstruction mse 72441.59375 imputation mse 1.0096811056137085\n",
      "Train Epoch 389.0 var loss 72093.890625 reconstruction mse 72091.1875 imputation mse 1.0108697414398193\n",
      "Train Epoch 389.1 var loss 72073.9609375 reconstruction mse 72071.3125 imputation mse 1.0105910301208496\n",
      "Train Epoch 389.2 var loss 72092.0234375 reconstruction mse 72089.3203125 imputation mse 1.0108435153961182\n",
      "Train Epoch 389.3 var loss 72097.140625 reconstruction mse 72094.4765625 imputation mse 1.0109158754348755\n",
      "Train Epoch 389.4 var loss 72081.953125 reconstruction mse 72079.4140625 imputation mse 1.0107046365737915\n",
      "Train Epoch 389.5 var loss 72079.78125 reconstruction mse 72077.3359375 imputation mse 1.0106755495071411\n",
      "Train Epoch 389.6 var loss 72087.03125 reconstruction mse 72084.6640625 imputation mse 1.0107783079147339\n",
      "Train Epoch 389.7 var loss 72099.734375 reconstruction mse 72097.3671875 imputation mse 1.0109564065933228\n",
      "Train Epoch 389.8 var loss 72105.1875 reconstruction mse 72102.8125 imputation mse 1.0110328197479248\n",
      "Train Epoch 389.9 var loss 72071.25 reconstruction mse 72068.828125 imputation mse 1.0105562210083008\n",
      "Train Epoch 390.0 var loss 71454.546875 reconstruction mse 71451.90625 imputation mse 0.9988663196563721\n",
      "Train Epoch 390.1 var loss 71512.53125 reconstruction mse 71509.875 imputation mse 0.9996767044067383\n",
      "Train Epoch 390.2 var loss 71514.7421875 reconstruction mse 71511.984375 imputation mse 0.9997062087059021\n",
      "Train Epoch 390.3 var loss 71512.046875 reconstruction mse 71509.2890625 imputation mse 0.999668538570404\n",
      "Train Epoch 390.4 var loss 71483.015625 reconstruction mse 71480.3359375 imputation mse 0.9992637634277344\n",
      "Train Epoch 390.5 var loss 71511.4609375 reconstruction mse 71508.8828125 imputation mse 0.9996628761291504\n",
      "Train Epoch 390.6 var loss 71481.8046875 reconstruction mse 71479.328125 imputation mse 0.9992496967315674\n",
      "Train Epoch 390.7 var loss 71494.328125 reconstruction mse 71491.8984375 imputation mse 0.9994254112243652\n",
      "Train Epoch 390.8 var loss 71530.9296875 reconstruction mse 71528.515625 imputation mse 0.9999372959136963\n",
      "Train Epoch 390.9 var loss 71522.4375 reconstruction mse 71520.0078125 imputation mse 0.9998183846473694\n",
      "====> Test imputation mse: 1.00708210\n",
      "====> Test imputation mse: 1.00586677\n",
      "====> Test imputation mse: 1.01141727\n",
      "Train Epoch 391.0 var loss 71927.2890625 reconstruction mse 71924.609375 imputation mse 1.0021960735321045\n",
      "Train Epoch 391.1 var loss 71917.3046875 reconstruction mse 71914.6640625 imputation mse 1.0020575523376465\n",
      "Train Epoch 391.2 var loss 71941.7109375 reconstruction mse 71939.0078125 imputation mse 1.0023967027664185\n",
      "Train Epoch 391.3 var loss 71922.125 reconstruction mse 71919.421875 imputation mse 1.0021238327026367\n",
      "Train Epoch 391.4 var loss 71924.59375 reconstruction mse 71921.96875 imputation mse 1.0021593570709229\n",
      "Train Epoch 391.5 var loss 71955.9609375 reconstruction mse 71953.4375 imputation mse 1.0025978088378906\n",
      "Train Epoch 391.6 var loss 71903.84375 reconstruction mse 71901.4375 imputation mse 1.001873254776001\n",
      "Train Epoch 391.7 var loss 71894.171875 reconstruction mse 71891.8046875 imputation mse 1.0017390251159668\n",
      "Train Epoch 391.8 var loss 71926.8828125 reconstruction mse 71924.515625 imputation mse 1.0021947622299194\n",
      "Train Epoch 391.9 var loss 71949.0546875 reconstruction mse 71946.6640625 imputation mse 1.0025033950805664\n",
      "Train Epoch 392.0 var loss 71607.8515625 reconstruction mse 71605.171875 imputation mse 1.0045759677886963\n",
      "Train Epoch 392.1 var loss 71628.6484375 reconstruction mse 71626.0 imputation mse 1.0048681497573853\n",
      "Train Epoch 392.2 var loss 71631.8828125 reconstruction mse 71629.1328125 imputation mse 1.0049121379852295\n",
      "Train Epoch 392.3 var loss 71624.1953125 reconstruction mse 71621.421875 imputation mse 1.004804015159607\n",
      "Train Epoch 392.4 var loss 71635.53125 reconstruction mse 71632.8359375 imputation mse 1.0049641132354736\n",
      "Train Epoch 392.5 var loss 71649.109375 reconstruction mse 71646.5390625 imputation mse 1.005156397819519\n",
      "Train Epoch 392.6 var loss 71621.3515625 reconstruction mse 71618.8828125 imputation mse 1.0047683715820312\n",
      "Train Epoch 392.7 var loss 71642.34375 reconstruction mse 71639.921875 imputation mse 1.005063533782959\n",
      "Train Epoch 392.8 var loss 71607.015625 reconstruction mse 71604.578125 imputation mse 1.0045676231384277\n",
      "Train Epoch 392.9 var loss 71652.5390625 reconstruction mse 71650.1015625 imputation mse 1.0052063465118408\n",
      "Train Epoch 393.0 var loss 71154.3359375 reconstruction mse 71151.6640625 imputation mse 0.995114266872406\n",
      "Train Epoch 393.1 var loss 71172.625 reconstruction mse 71170.0078125 imputation mse 0.9953708052635193\n",
      "Train Epoch 393.2 var loss 71145.859375 reconstruction mse 71143.1484375 imputation mse 0.9949951767921448\n",
      "Train Epoch 393.3 var loss 71158.7890625 reconstruction mse 71156.078125 imputation mse 0.9951759576797485\n",
      "Train Epoch 393.4 var loss 71200.0546875 reconstruction mse 71197.4375 imputation mse 0.9957544207572937\n",
      "Train Epoch 393.5 var loss 71178.9375 reconstruction mse 71176.4453125 imputation mse 0.9954608082771301\n",
      "Train Epoch 393.6 var loss 71185.3125 reconstruction mse 71182.921875 imputation mse 0.9955514073371887\n",
      "Train Epoch 393.7 var loss 71147.6875 reconstruction mse 71145.3359375 imputation mse 0.9950257539749146\n",
      "Train Epoch 393.8 var loss 71157.7578125 reconstruction mse 71155.390625 imputation mse 0.9951663613319397\n",
      "Train Epoch 393.9 var loss 71195.046875 reconstruction mse 71192.6328125 imputation mse 0.9956872463226318\n",
      "Train Epoch 394.0 var loss 72106.59375 reconstruction mse 72103.9453125 imputation mse 1.007347822189331\n",
      "Train Epoch 394.1 var loss 72150.3046875 reconstruction mse 72147.6640625 imputation mse 1.0079586505889893\n",
      "Train Epoch 394.2 var loss 72104.46875 reconstruction mse 72101.7578125 imputation mse 1.007317304611206\n",
      "Train Epoch 394.3 var loss 72129.3828125 reconstruction mse 72126.6875 imputation mse 1.0076656341552734\n",
      "Train Epoch 394.4 var loss 72127.0390625 reconstruction mse 72124.4140625 imputation mse 1.0076338052749634\n",
      "Train Epoch 394.5 var loss 72133.6640625 reconstruction mse 72131.140625 imputation mse 1.007727861404419\n",
      "Train Epoch 394.6 var loss 72125.734375 reconstruction mse 72123.3046875 imputation mse 1.0076183080673218\n",
      "Train Epoch 394.7 var loss 72118.8125 reconstruction mse 72116.4375 imputation mse 1.0075223445892334\n",
      "Train Epoch 394.8 var loss 72100.3046875 reconstruction mse 72097.90625 imputation mse 1.0072635412216187\n",
      "Train Epoch 394.9 var loss 72117.625 reconstruction mse 72115.1953125 imputation mse 1.0075050592422485\n",
      "Train Epoch 395.0 var loss 71448.1796875 reconstruction mse 71445.515625 imputation mse 1.0010019540786743\n",
      "Train Epoch 395.1 var loss 71420.8125 reconstruction mse 71418.171875 imputation mse 1.0006189346313477\n",
      "Train Epoch 395.2 var loss 71458.3359375 reconstruction mse 71455.609375 imputation mse 1.001143455505371\n",
      "Train Epoch 395.3 var loss 71417.828125 reconstruction mse 71415.1015625 imputation mse 1.0005759000778198\n",
      "Train Epoch 395.4 var loss 71453.8671875 reconstruction mse 71451.25 imputation mse 1.0010823011398315\n",
      "Train Epoch 395.5 var loss 71393.6015625 reconstruction mse 71391.109375 imputation mse 1.0002397298812866\n",
      "Train Epoch 395.6 var loss 71393.6953125 reconstruction mse 71391.296875 imputation mse 1.0002423524856567\n",
      "Train Epoch 395.7 var loss 71427.0078125 reconstruction mse 71424.6796875 imputation mse 1.0007100105285645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 395.8 var loss 71458.9296875 reconstruction mse 71456.609375 imputation mse 1.0011574029922485\n",
      "Train Epoch 395.9 var loss 71453.015625 reconstruction mse 71450.6953125 imputation mse 1.0010745525360107\n",
      "Train Epoch 396.0 var loss 71728.4140625 reconstruction mse 71725.7890625 imputation mse 1.00600004196167\n",
      "Train Epoch 396.1 var loss 71725.953125 reconstruction mse 71723.359375 imputation mse 1.0059659481048584\n",
      "Train Epoch 396.2 var loss 71766.203125 reconstruction mse 71763.5 imputation mse 1.0065289735794067\n",
      "Train Epoch 396.3 var loss 71712.734375 reconstruction mse 71710.03125 imputation mse 1.0057790279388428\n",
      "Train Epoch 396.4 var loss 71715.203125 reconstruction mse 71712.5625 imputation mse 1.005814552307129\n",
      "Train Epoch 396.5 var loss 71744.7890625 reconstruction mse 71742.265625 imputation mse 1.0062310695648193\n",
      "Train Epoch 396.6 var loss 71730.0546875 reconstruction mse 71727.6328125 imputation mse 1.0060259103775024\n",
      "Train Epoch 396.7 var loss 71746.3671875 reconstruction mse 71743.9921875 imputation mse 1.0062552690505981\n",
      "Train Epoch 396.8 var loss 71741.9765625 reconstruction mse 71739.6015625 imputation mse 1.00619375705719\n",
      "Train Epoch 396.9 var loss 71740.421875 reconstruction mse 71738.015625 imputation mse 1.006171464920044\n",
      "Train Epoch 397.0 var loss 72503.25 reconstruction mse 72500.6484375 imputation mse 1.0074291229248047\n",
      "Train Epoch 397.1 var loss 72479.1875 reconstruction mse 72476.5390625 imputation mse 1.007094144821167\n",
      "Train Epoch 397.2 var loss 72462.8828125 reconstruction mse 72460.1484375 imputation mse 1.006866455078125\n",
      "Train Epoch 397.3 var loss 72460.7578125 reconstruction mse 72458.046875 imputation mse 1.006837248802185\n",
      "Train Epoch 397.4 var loss 72492.3125 reconstruction mse 72489.6875 imputation mse 1.0072768926620483\n",
      "Train Epoch 397.5 var loss 72470.78125 reconstruction mse 72468.265625 imputation mse 1.00697922706604\n",
      "Train Epoch 397.6 var loss 72510.671875 reconstruction mse 72508.25 imputation mse 1.0075348615646362\n",
      "Train Epoch 397.7 var loss 72523.34375 reconstruction mse 72520.9609375 imputation mse 1.007711410522461\n",
      "Train Epoch 397.8 var loss 72474.0 reconstruction mse 72471.6015625 imputation mse 1.0070255994796753\n",
      "Train Epoch 397.9 var loss 72515.6171875 reconstruction mse 72513.171875 imputation mse 1.0076031684875488\n",
      "Train Epoch 398.0 var loss 72237.2890625 reconstruction mse 72234.609375 imputation mse 1.009624719619751\n",
      "Train Epoch 398.1 var loss 72226.34375 reconstruction mse 72223.6796875 imputation mse 1.0094718933105469\n",
      "Train Epoch 398.2 var loss 72267.0703125 reconstruction mse 72264.3125 imputation mse 1.0100399255752563\n",
      "Train Epoch 398.3 var loss 72223.625 reconstruction mse 72220.921875 imputation mse 1.009433388710022\n",
      "Train Epoch 398.4 var loss 72213.203125 reconstruction mse 72210.6171875 imputation mse 1.0092893838882446\n",
      "Train Epoch 398.5 var loss 72212.890625 reconstruction mse 72210.4375 imputation mse 1.009286880493164\n",
      "Train Epoch 398.6 var loss 72201.2421875 reconstruction mse 72198.875 imputation mse 1.0091252326965332\n",
      "Train Epoch 398.7 var loss 72199.171875 reconstruction mse 72196.84375 imputation mse 1.0090968608856201\n",
      "Train Epoch 398.8 var loss 72201.5703125 reconstruction mse 72199.2265625 imputation mse 1.0091301202774048\n",
      "Train Epoch 398.9 var loss 72194.7578125 reconstruction mse 72192.375 imputation mse 1.0090343952178955\n",
      "Train Epoch 399.0 var loss 71565.0546875 reconstruction mse 71562.46875 imputation mse 1.000943660736084\n",
      "Train Epoch 399.1 var loss 71553.703125 reconstruction mse 71551.1484375 imputation mse 1.0007853507995605\n",
      "Train Epoch 399.2 var loss 71544.171875 reconstruction mse 71541.515625 imputation mse 1.0006506443023682\n",
      "Train Epoch 399.3 var loss 71558.09375 reconstruction mse 71555.4609375 imputation mse 1.0008456707000732\n",
      "Train Epoch 399.4 var loss 71574.0625 reconstruction mse 71571.53125 imputation mse 1.001070499420166\n",
      "Train Epoch 399.5 var loss 71536.1484375 reconstruction mse 71533.75 imputation mse 1.0005420446395874\n",
      "Train Epoch 399.6 var loss 71511.3828125 reconstruction mse 71509.078125 imputation mse 1.000196933746338\n",
      "Train Epoch 399.7 var loss 71514.3359375 reconstruction mse 71512.0703125 imputation mse 1.0002387762069702\n",
      "Train Epoch 399.8 var loss 71570.1875 reconstruction mse 71567.890625 imputation mse 1.0010194778442383\n",
      "Train Epoch 399.9 var loss 71515.53125 reconstruction mse 71513.171875 imputation mse 1.0002541542053223\n",
      "Train Epoch 400.0 var loss 71685.5234375 reconstruction mse 71682.953125 imputation mse 1.001690149307251\n",
      "Train Epoch 400.1 var loss 71666.515625 reconstruction mse 71663.9140625 imputation mse 1.0014241933822632\n",
      "Train Epoch 400.2 var loss 71658.2734375 reconstruction mse 71655.609375 imputation mse 1.0013080835342407\n",
      "Train Epoch 400.3 var loss 71707.9765625 reconstruction mse 71705.3515625 imputation mse 1.0020031929016113\n",
      "Train Epoch 400.4 var loss 71678.5 reconstruction mse 71675.9921875 imputation mse 1.0015928745269775\n",
      "Train Epoch 400.5 var loss 71657.515625 reconstruction mse 71655.1328125 imputation mse 1.0013014078140259\n",
      "Train Epoch 400.6 var loss 71680.1328125 reconstruction mse 71677.828125 imputation mse 1.0016186237335205\n",
      "Train Epoch 400.7 var loss 71676.7109375 reconstruction mse 71674.40625 imputation mse 1.001570701599121\n",
      "Train Epoch 400.8 var loss 71688.3125 reconstruction mse 71685.96875 imputation mse 1.001732349395752\n",
      "Train Epoch 400.9 var loss 71673.3671875 reconstruction mse 71670.96875 imputation mse 1.0015226602554321\n",
      "====> Test imputation mse: 0.99343473\n",
      "====> Test imputation mse: 1.00428891\n",
      "====> Test imputation mse: 1.01325095\n",
      "Train Epoch 401.0 var loss 72300.2578125 reconstruction mse 72297.6640625 imputation mse 1.005223274230957\n",
      "Train Epoch 401.1 var loss 72270.9609375 reconstruction mse 72268.328125 imputation mse 1.0048153400421143\n",
      "Train Epoch 401.2 var loss 72326.25 reconstruction mse 72323.5703125 imputation mse 1.00558340549469\n",
      "Train Epoch 401.3 var loss 72273.1484375 reconstruction mse 72270.5078125 imputation mse 1.0048456192016602\n",
      "Train Epoch 401.4 var loss 72287.3125 reconstruction mse 72284.78125 imputation mse 1.0050441026687622\n",
      "Train Epoch 401.5 var loss 72331.6953125 reconstruction mse 72329.296875 imputation mse 1.0056630373001099\n",
      "Train Epoch 401.6 var loss 72250.359375 reconstruction mse 72248.0390625 imputation mse 1.004533290863037\n",
      "Train Epoch 401.7 var loss 72266.53125 reconstruction mse 72264.2421875 imputation mse 1.0047584772109985\n",
      "Train Epoch 401.8 var loss 72260.046875 reconstruction mse 72257.7265625 imputation mse 1.00466787815094\n",
      "Train Epoch 401.9 var loss 72289.265625 reconstruction mse 72286.90625 imputation mse 1.0050736665725708\n",
      "Train Epoch 402.0 var loss 71371.171875 reconstruction mse 71368.5546875 imputation mse 1.0007930994033813\n",
      "Train Epoch 402.1 var loss 71377.7890625 reconstruction mse 71375.1875 imputation mse 1.000886082649231\n",
      "Train Epoch 402.2 var loss 71344.4453125 reconstruction mse 71341.7578125 imputation mse 1.0004172325134277\n",
      "Train Epoch 402.3 var loss 71379.4453125 reconstruction mse 71376.8125 imputation mse 1.0009088516235352\n",
      "Train Epoch 402.4 var loss 71359.1953125 reconstruction mse 71356.6484375 imputation mse 1.0006260871887207\n",
      "Train Epoch 402.5 var loss 71346.5 reconstruction mse 71344.0546875 imputation mse 1.000449538230896\n",
      "Train Epoch 402.6 var loss 71368.2109375 reconstruction mse 71365.84375 imputation mse 1.0007550716400146\n",
      "Train Epoch 402.7 var loss 71340.46875 reconstruction mse 71338.1328125 imputation mse 1.000366449356079\n",
      "Train Epoch 402.8 var loss 71392.3046875 reconstruction mse 71389.9609375 imputation mse 1.0010932683944702\n",
      "Train Epoch 402.9 var loss 71349.171875 reconstruction mse 71346.8203125 imputation mse 1.00048828125\n",
      "Train Epoch 403.0 var loss 71526.3203125 reconstruction mse 71523.765625 imputation mse 0.9988934397697449\n",
      "Train Epoch 403.1 var loss 71529.484375 reconstruction mse 71526.984375 imputation mse 0.9989383816719055\n",
      "Train Epoch 403.2 var loss 71530.3828125 reconstruction mse 71527.78125 imputation mse 0.9989495277404785\n",
      "Train Epoch 403.3 var loss 71518.5546875 reconstruction mse 71515.9921875 imputation mse 0.9987848401069641\n",
      "Train Epoch 403.4 var loss 71506.296875 reconstruction mse 71503.8125 imputation mse 0.9986147284507751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 403.5 var loss 71529.1953125 reconstruction mse 71526.8046875 imputation mse 0.998935878276825\n",
      "Train Epoch 403.6 var loss 71555.5625 reconstruction mse 71553.25 imputation mse 0.9993051886558533\n",
      "Train Epoch 403.7 var loss 71519.4453125 reconstruction mse 71517.171875 imputation mse 0.9988013505935669\n",
      "Train Epoch 403.8 var loss 71543.4453125 reconstruction mse 71541.1640625 imputation mse 0.9991363883018494\n",
      "Train Epoch 403.9 var loss 71516.2421875 reconstruction mse 71513.8984375 imputation mse 0.9987556338310242\n",
      "Train Epoch 404.0 var loss 71347.6328125 reconstruction mse 71345.0078125 imputation mse 0.9966195821762085\n",
      "Train Epoch 404.1 var loss 71384.4296875 reconstruction mse 71381.859375 imputation mse 0.9971343874931335\n",
      "Train Epoch 404.2 var loss 71398.203125 reconstruction mse 71395.5546875 imputation mse 0.9973257184028625\n",
      "Train Epoch 404.3 var loss 71347.25 reconstruction mse 71344.625 imputation mse 0.9966142773628235\n",
      "Train Epoch 404.4 var loss 71352.9375 reconstruction mse 71350.4140625 imputation mse 0.9966951012611389\n",
      "Train Epoch 404.5 var loss 71388.8671875 reconstruction mse 71386.484375 imputation mse 0.9971989989280701\n",
      "Train Epoch 404.6 var loss 71341.046875 reconstruction mse 71338.7578125 imputation mse 0.9965323209762573\n",
      "Train Epoch 404.7 var loss 71389.15625 reconstruction mse 71386.921875 imputation mse 0.9972050786018372\n",
      "Train Epoch 404.8 var loss 71363.578125 reconstruction mse 71361.3125 imputation mse 0.99684739112854\n",
      "Train Epoch 404.9 var loss 71347.6171875 reconstruction mse 71345.3046875 imputation mse 0.9966237545013428\n",
      "Train Epoch 405.0 var loss 71109.46875 reconstruction mse 71106.8515625 imputation mse 0.9923917055130005\n",
      "Train Epoch 405.1 var loss 71115.84375 reconstruction mse 71113.2265625 imputation mse 0.9924806952476501\n",
      "Train Epoch 405.2 var loss 71095.9609375 reconstruction mse 71093.25 imputation mse 0.9922018647193909\n",
      "Train Epoch 405.3 var loss 71073.9296875 reconstruction mse 71071.2421875 imputation mse 0.9918947219848633\n",
      "Train Epoch 405.4 var loss 71123.4609375 reconstruction mse 71120.90625 imputation mse 0.9925878643989563\n",
      "Train Epoch 405.5 var loss 71102.03125 reconstruction mse 71099.6171875 imputation mse 0.992290735244751\n",
      "Train Epoch 405.6 var loss 71101.1875 reconstruction mse 71098.8984375 imputation mse 0.9922807216644287\n",
      "Train Epoch 405.7 var loss 71085.8359375 reconstruction mse 71083.5859375 imputation mse 0.9920670390129089\n",
      "Train Epoch 405.8 var loss 71098.3984375 reconstruction mse 71096.125 imputation mse 0.9922420382499695\n",
      "Train Epoch 405.9 var loss 71099.828125 reconstruction mse 71097.484375 imputation mse 0.9922609925270081\n",
      "Train Epoch 406.0 var loss 71873.8515625 reconstruction mse 71871.2265625 imputation mse 1.0091580152511597\n",
      "Train Epoch 406.1 var loss 71926.3828125 reconstruction mse 71923.7890625 imputation mse 1.0098960399627686\n",
      "Train Epoch 406.2 var loss 71896.953125 reconstruction mse 71894.2734375 imputation mse 1.00948166847229\n",
      "Train Epoch 406.3 var loss 71898.2578125 reconstruction mse 71895.59375 imputation mse 1.0095001459121704\n",
      "Train Epoch 406.4 var loss 71874.828125 reconstruction mse 71872.28125 imputation mse 1.009172797203064\n",
      "Train Epoch 406.5 var loss 71872.6875 reconstruction mse 71870.25 imputation mse 1.0091443061828613\n",
      "Train Epoch 406.6 var loss 71883.7578125 reconstruction mse 71881.3984375 imputation mse 1.0093008279800415\n",
      "Train Epoch 406.7 var loss 71891.9453125 reconstruction mse 71889.609375 imputation mse 1.009416103363037\n",
      "Train Epoch 406.8 var loss 71854.5546875 reconstruction mse 71852.2109375 imputation mse 1.008890986442566\n",
      "Train Epoch 406.9 var loss 71912.453125 reconstruction mse 71910.0625 imputation mse 1.0097033977508545\n",
      "Train Epoch 407.0 var loss 70911.046875 reconstruction mse 70908.453125 imputation mse 0.993519127368927\n",
      "Train Epoch 407.1 var loss 70853.6171875 reconstruction mse 70851.0234375 imputation mse 0.9927144646644592\n",
      "Train Epoch 407.2 var loss 70902.390625 reconstruction mse 70899.734375 imputation mse 0.9933969378471375\n",
      "Train Epoch 407.3 var loss 70895.4375 reconstruction mse 70892.828125 imputation mse 0.993300199508667\n",
      "Train Epoch 407.4 var loss 70906.296875 reconstruction mse 70903.7734375 imputation mse 0.9934535622596741\n",
      "Train Epoch 407.5 var loss 70893.40625 reconstruction mse 70890.984375 imputation mse 0.9932743310928345\n",
      "Train Epoch 407.6 var loss 70898.875 reconstruction mse 70896.5 imputation mse 0.9933516383171082\n",
      "Train Epoch 407.7 var loss 70900.3046875 reconstruction mse 70897.9375 imputation mse 0.9933717846870422\n",
      "Train Epoch 407.8 var loss 70907.3046875 reconstruction mse 70904.9453125 imputation mse 0.9934699535369873\n",
      "Train Epoch 407.9 var loss 70884.296875 reconstruction mse 70881.90625 imputation mse 0.9931471347808838\n",
      "Train Epoch 408.0 var loss 71636.0546875 reconstruction mse 71633.4296875 imputation mse 1.0040146112442017\n",
      "Train Epoch 408.1 var loss 71660.2421875 reconstruction mse 71657.75 imputation mse 1.0043554306030273\n",
      "Train Epoch 408.2 var loss 71666.421875 reconstruction mse 71663.8359375 imputation mse 1.0044407844543457\n",
      "Train Epoch 408.3 var loss 71629.8046875 reconstruction mse 71627.25 imputation mse 1.0039279460906982\n",
      "Train Epoch 408.4 var loss 71643.4375 reconstruction mse 71640.953125 imputation mse 1.0041199922561646\n",
      "Train Epoch 408.5 var loss 71607.4453125 reconstruction mse 71605.0625 imputation mse 1.0036170482635498\n",
      "Train Epoch 408.6 var loss 71638.15625 reconstruction mse 71635.8359375 imputation mse 1.0040483474731445\n",
      "Train Epoch 408.7 var loss 71685.0703125 reconstruction mse 71682.7734375 imputation mse 1.0047061443328857\n",
      "Train Epoch 408.8 var loss 71645.984375 reconstruction mse 71643.703125 imputation mse 1.004158616065979\n",
      "Train Epoch 408.9 var loss 71629.1328125 reconstruction mse 71626.8125 imputation mse 1.0039218664169312\n",
      "Train Epoch 409.0 var loss 71616.5390625 reconstruction mse 71613.96875 imputation mse 1.0030248165130615\n",
      "Train Epoch 409.1 var loss 71641.5078125 reconstruction mse 71638.984375 imputation mse 1.0033751726150513\n",
      "Train Epoch 409.2 var loss 71632.671875 reconstruction mse 71630.0703125 imputation mse 1.0032503604888916\n",
      "Train Epoch 409.3 var loss 71622.90625 reconstruction mse 71620.3046875 imputation mse 1.0031136274337769\n",
      "Train Epoch 409.4 var loss 71636.46875 reconstruction mse 71633.9140625 imputation mse 1.0033042430877686\n",
      "Train Epoch 409.5 var loss 71621.421875 reconstruction mse 71618.984375 imputation mse 1.0030951499938965\n",
      "Train Epoch 409.6 var loss 71626.3671875 reconstruction mse 71623.984375 imputation mse 1.0031651258468628\n",
      "Train Epoch 409.7 var loss 71601.9921875 reconstruction mse 71599.65625 imputation mse 1.0028244256973267\n",
      "Train Epoch 409.8 var loss 71602.8515625 reconstruction mse 71600.5078125 imputation mse 1.0028363466262817\n",
      "Train Epoch 409.9 var loss 71620.0 reconstruction mse 71617.625 imputation mse 1.0030760765075684\n",
      "Train Epoch 410.0 var loss 70987.0859375 reconstruction mse 70984.53125 imputation mse 0.9898557066917419\n",
      "Train Epoch 410.1 var loss 71032.6640625 reconstruction mse 71030.15625 imputation mse 0.9904919266700745\n",
      "Train Epoch 410.2 var loss 71017.359375 reconstruction mse 71014.796875 imputation mse 0.9902777075767517\n",
      "Train Epoch 410.3 var loss 70999.140625 reconstruction mse 70996.6171875 imputation mse 0.990024209022522\n",
      "Train Epoch 410.4 var loss 70991.3828125 reconstruction mse 70988.9453125 imputation mse 0.9899172186851501\n",
      "Train Epoch 410.5 var loss 71011.328125 reconstruction mse 71008.984375 imputation mse 0.990196704864502\n",
      "Train Epoch 410.6 var loss 71027.75 reconstruction mse 71025.4609375 imputation mse 0.9904264211654663\n",
      "Train Epoch 410.7 var loss 71001.3125 reconstruction mse 70999.0 imputation mse 0.9900574684143066\n",
      "Train Epoch 410.8 var loss 70972.8359375 reconstruction mse 70970.4921875 imputation mse 0.9896599054336548\n",
      "Train Epoch 410.9 var loss 70952.8828125 reconstruction mse 70950.515625 imputation mse 0.9893813729286194\n",
      "====> Test imputation mse: 1.00193906\n",
      "====> Test imputation mse: 0.99644476\n",
      "====> Test imputation mse: 0.99532723\n",
      "Train Epoch 411.0 var loss 72212.9609375 reconstruction mse 72210.3984375 imputation mse 1.005113959312439\n",
      "Train Epoch 411.1 var loss 72223.4921875 reconstruction mse 72220.9609375 imputation mse 1.005260944366455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 411.2 var loss 72204.453125 reconstruction mse 72201.859375 imputation mse 1.0049951076507568\n",
      "Train Epoch 411.3 var loss 72218.2421875 reconstruction mse 72215.6796875 imputation mse 1.0051873922348022\n",
      "Train Epoch 411.4 var loss 72223.609375 reconstruction mse 72221.1484375 imputation mse 1.0052635669708252\n",
      "Train Epoch 411.5 var loss 72210.5625 reconstruction mse 72208.2265625 imputation mse 1.005083680152893\n",
      "Train Epoch 411.6 var loss 72226.03125 reconstruction mse 72223.75 imputation mse 1.0052998065948486\n",
      "Train Epoch 411.7 var loss 72172.671875 reconstruction mse 72170.390625 imputation mse 1.0045570135116577\n",
      "Train Epoch 411.8 var loss 72179.6796875 reconstruction mse 72177.359375 imputation mse 1.004654049873352\n",
      "Train Epoch 411.9 var loss 72197.265625 reconstruction mse 72194.859375 imputation mse 1.0048975944519043\n",
      "Train Epoch 412.0 var loss 70781.40625 reconstruction mse 70778.84375 imputation mse 0.9895678758621216\n",
      "Train Epoch 412.1 var loss 70771.4453125 reconstruction mse 70768.828125 imputation mse 0.9894278645515442\n",
      "Train Epoch 412.2 var loss 70758.515625 reconstruction mse 70755.8203125 imputation mse 0.9892460107803345\n",
      "Train Epoch 412.3 var loss 70777.8046875 reconstruction mse 70775.1484375 imputation mse 0.9895162582397461\n",
      "Train Epoch 412.4 var loss 70750.234375 reconstruction mse 70747.6953125 imputation mse 0.9891324043273926\n",
      "Train Epoch 412.5 var loss 70809.6484375 reconstruction mse 70807.21875 imputation mse 0.9899646043777466\n",
      "Train Epoch 412.6 var loss 70761.1640625 reconstruction mse 70758.828125 imputation mse 0.9892880320549011\n",
      "Train Epoch 412.7 var loss 70752.46875 reconstruction mse 70750.15625 imputation mse 0.989166796207428\n",
      "Train Epoch 412.8 var loss 70780.6875 reconstruction mse 70778.375 imputation mse 0.9895613193511963\n",
      "Train Epoch 412.9 var loss 70802.578125 reconstruction mse 70800.2421875 imputation mse 0.989867091178894\n",
      "Train Epoch 413.0 var loss 71794.875 reconstruction mse 71792.328125 imputation mse 1.009098768234253\n",
      "Train Epoch 413.1 var loss 71786.140625 reconstruction mse 71783.6015625 imputation mse 1.0089761018753052\n",
      "Train Epoch 413.2 var loss 71796.796875 reconstruction mse 71794.1640625 imputation mse 1.009124517440796\n",
      "Train Epoch 413.3 var loss 71771.203125 reconstruction mse 71768.6015625 imputation mse 1.0087652206420898\n",
      "Train Epoch 413.4 var loss 71788.0625 reconstruction mse 71785.546875 imputation mse 1.0090034008026123\n",
      "Train Epoch 413.5 var loss 71783.390625 reconstruction mse 71780.984375 imputation mse 1.008939266204834\n",
      "Train Epoch 413.6 var loss 71809.84375 reconstruction mse 71807.5390625 imputation mse 1.0093125104904175\n",
      "Train Epoch 413.7 var loss 71785.9140625 reconstruction mse 71783.640625 imputation mse 1.0089765787124634\n",
      "Train Epoch 413.8 var loss 71779.09375 reconstruction mse 71776.8046875 imputation mse 1.0088804960250854\n",
      "Train Epoch 413.9 var loss 71774.296875 reconstruction mse 71771.9921875 imputation mse 1.0088129043579102\n",
      "Train Epoch 414.0 var loss 71253.6875 reconstruction mse 71251.1484375 imputation mse 0.9975659847259521\n",
      "Train Epoch 414.1 var loss 71267.359375 reconstruction mse 71264.8203125 imputation mse 0.9977573752403259\n",
      "Train Epoch 414.2 var loss 71256.7578125 reconstruction mse 71254.1484375 imputation mse 0.997607946395874\n",
      "Train Epoch 414.3 var loss 71274.2734375 reconstruction mse 71271.6875 imputation mse 0.9978535175323486\n",
      "Train Epoch 414.4 var loss 71266.703125 reconstruction mse 71264.2109375 imputation mse 0.997748851776123\n",
      "Train Epoch 414.5 var loss 71253.9609375 reconstruction mse 71251.5703125 imputation mse 0.9975718855857849\n",
      "Train Epoch 414.6 var loss 71256.171875 reconstruction mse 71253.8828125 imputation mse 0.997604250907898\n",
      "Train Epoch 414.7 var loss 71287.859375 reconstruction mse 71285.5859375 imputation mse 0.9980481266975403\n",
      "Train Epoch 414.8 var loss 71296.4609375 reconstruction mse 71294.15625 imputation mse 0.9981681108474731\n",
      "Train Epoch 414.9 var loss 71251.6484375 reconstruction mse 71249.2734375 imputation mse 0.9975396990776062\n",
      "Train Epoch 415.0 var loss 72024.9921875 reconstruction mse 72022.375 imputation mse 1.0083637237548828\n",
      "Train Epoch 415.1 var loss 72032.6484375 reconstruction mse 72029.9453125 imputation mse 1.0084697008132935\n",
      "Train Epoch 415.2 var loss 72053.5859375 reconstruction mse 72050.7734375 imputation mse 1.0087612867355347\n",
      "Train Epoch 415.3 var loss 72029.65625 reconstruction mse 72026.8984375 imputation mse 1.0084270238876343\n",
      "Train Epoch 415.4 var loss 72071.515625 reconstruction mse 72068.8515625 imputation mse 1.009014368057251\n",
      "Train Epoch 415.5 var loss 72048.375 reconstruction mse 72045.859375 imputation mse 1.0086925029754639\n",
      "Train Epoch 415.6 var loss 72034.953125 reconstruction mse 72032.5625 imputation mse 1.0085062980651855\n",
      "Train Epoch 415.7 var loss 72028.765625 reconstruction mse 72026.4375 imputation mse 1.0084205865859985\n",
      "Train Epoch 415.8 var loss 72069.9296875 reconstruction mse 72067.609375 imputation mse 1.0089969635009766\n",
      "Train Epoch 415.9 var loss 72046.5078125 reconstruction mse 72044.1796875 imputation mse 1.0086688995361328\n",
      "Train Epoch 416.0 var loss 72369.5234375 reconstruction mse 72366.9375 imputation mse 1.0122240781784058\n",
      "Train Epoch 416.1 var loss 72318.3359375 reconstruction mse 72315.7578125 imputation mse 1.0115082263946533\n",
      "Train Epoch 416.2 var loss 72314.75 reconstruction mse 72312.0390625 imputation mse 1.0114562511444092\n",
      "Train Epoch 416.3 var loss 72318.65625 reconstruction mse 72315.9375 imputation mse 1.0115107297897339\n",
      "Train Epoch 416.4 var loss 72338.421875 reconstruction mse 72335.8046875 imputation mse 1.0117886066436768\n",
      "Train Epoch 416.5 var loss 72326.34375 reconstruction mse 72323.8359375 imputation mse 1.0116212368011475\n",
      "Train Epoch 416.6 var loss 72306.7890625 reconstruction mse 72304.375 imputation mse 1.0113489627838135\n",
      "Train Epoch 416.7 var loss 72320.6796875 reconstruction mse 72318.3359375 imputation mse 1.0115443468093872\n",
      "Train Epoch 416.8 var loss 72320.96875 reconstruction mse 72318.6171875 imputation mse 1.0115482807159424\n",
      "Train Epoch 416.9 var loss 72364.078125 reconstruction mse 72361.6953125 imputation mse 1.012150764465332\n",
      "Train Epoch 417.0 var loss 70886.7421875 reconstruction mse 70884.1328125 imputation mse 0.9899880290031433\n",
      "Train Epoch 417.1 var loss 70899.546875 reconstruction mse 70896.921875 imputation mse 0.9901666641235352\n",
      "Train Epoch 417.2 var loss 70875.5234375 reconstruction mse 70872.7734375 imputation mse 0.9898293614387512\n",
      "Train Epoch 417.3 var loss 70911.2578125 reconstruction mse 70908.53125 imputation mse 0.9903287887573242\n",
      "Train Epoch 417.4 var loss 70906.03125 reconstruction mse 70903.421875 imputation mse 0.9902574419975281\n",
      "Train Epoch 417.5 var loss 70876.9296875 reconstruction mse 70874.46875 imputation mse 0.9898530840873718\n",
      "Train Epoch 417.6 var loss 70878.875 reconstruction mse 70876.515625 imputation mse 0.9898816347122192\n",
      "Train Epoch 417.7 var loss 70885.0390625 reconstruction mse 70882.71875 imputation mse 0.9899682998657227\n",
      "Train Epoch 417.8 var loss 70851.2890625 reconstruction mse 70848.96875 imputation mse 0.9894969463348389\n",
      "Train Epoch 417.9 var loss 70885.875 reconstruction mse 70883.515625 imputation mse 0.9899793863296509\n",
      "Train Epoch 418.0 var loss 71959.9375 reconstruction mse 71957.3828125 imputation mse 1.0059045553207397\n",
      "Train Epoch 418.1 var loss 71948.4609375 reconstruction mse 71945.8828125 imputation mse 1.0057437419891357\n",
      "Train Epoch 418.2 var loss 71967.7109375 reconstruction mse 71965.1015625 imputation mse 1.0060124397277832\n",
      "Train Epoch 418.3 var loss 71982.5546875 reconstruction mse 71979.984375 imputation mse 1.0062204599380493\n",
      "Train Epoch 418.4 var loss 71935.46875 reconstruction mse 71933.0 imputation mse 1.005563735961914\n",
      "Train Epoch 418.5 var loss 71998.578125 reconstruction mse 71996.21875 imputation mse 1.006447434425354\n",
      "Train Epoch 418.6 var loss 71958.109375 reconstruction mse 71955.828125 imputation mse 1.0058828592300415\n",
      "Train Epoch 418.7 var loss 71945.53125 reconstruction mse 71943.28125 imputation mse 1.0057073831558228\n",
      "Train Epoch 418.8 var loss 71962.015625 reconstruction mse 71959.75 imputation mse 1.0059376955032349\n",
      "Train Epoch 418.9 var loss 71928.5234375 reconstruction mse 71926.21875 imputation mse 1.0054689645767212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 419.0 var loss 71329.4375 reconstruction mse 71326.8671875 imputation mse 0.9969093203544617\n",
      "Train Epoch 419.1 var loss 71303.421875 reconstruction mse 71300.8984375 imputation mse 0.9965463280677795\n",
      "Train Epoch 419.2 var loss 71343.890625 reconstruction mse 71341.2890625 imputation mse 0.997110903263092\n",
      "Train Epoch 419.3 var loss 71326.9609375 reconstruction mse 71324.3671875 imputation mse 0.9968743920326233\n",
      "Train Epoch 419.4 var loss 71326.953125 reconstruction mse 71324.4296875 imputation mse 0.9968752264976501\n",
      "Train Epoch 419.5 var loss 71324.3046875 reconstruction mse 71321.8828125 imputation mse 0.9968396425247192\n",
      "Train Epoch 419.6 var loss 71330.0546875 reconstruction mse 71327.703125 imputation mse 0.9969210028648376\n",
      "Train Epoch 419.7 var loss 71320.8046875 reconstruction mse 71318.5078125 imputation mse 0.9967924952507019\n",
      "Train Epoch 419.8 var loss 71352.34375 reconstruction mse 71350.046875 imputation mse 0.9972332715988159\n",
      "Train Epoch 419.9 var loss 71313.1796875 reconstruction mse 71310.84375 imputation mse 0.9966853260993958\n",
      "Train Epoch 420.0 var loss 72751.6796875 reconstruction mse 72749.109375 imputation mse 1.008219838142395\n",
      "Train Epoch 420.1 var loss 72808.2734375 reconstruction mse 72805.6875 imputation mse 1.0090038776397705\n",
      "Train Epoch 420.2 var loss 72803.7578125 reconstruction mse 72801.046875 imputation mse 1.0089396238327026\n",
      "Train Epoch 420.3 var loss 72792.671875 reconstruction mse 72789.9609375 imputation mse 1.0087859630584717\n",
      "Train Epoch 420.4 var loss 72784.3828125 reconstruction mse 72781.7734375 imputation mse 1.0086724758148193\n",
      "Train Epoch 420.5 var loss 72778.3046875 reconstruction mse 72775.8515625 imputation mse 1.0085904598236084\n",
      "Train Epoch 420.6 var loss 72730.28125 reconstruction mse 72727.9453125 imputation mse 1.0079264640808105\n",
      "Train Epoch 420.7 var loss 72756.3046875 reconstruction mse 72754.015625 imputation mse 1.008287787437439\n",
      "Train Epoch 420.8 var loss 72764.484375 reconstruction mse 72762.1796875 imputation mse 1.0084009170532227\n",
      "Train Epoch 420.9 var loss 72728.671875 reconstruction mse 72726.3359375 imputation mse 1.0079041719436646\n",
      "====> Test imputation mse: 1.00436544\n",
      "====> Test imputation mse: 0.99586481\n",
      "====> Test imputation mse: 0.99905431\n",
      "Train Epoch 421.0 var loss 71911.0 reconstruction mse 71908.453125 imputation mse 1.005768895149231\n",
      "Train Epoch 421.1 var loss 71905.578125 reconstruction mse 71903.015625 imputation mse 1.0056928396224976\n",
      "Train Epoch 421.2 var loss 71927.71875 reconstruction mse 71925.078125 imputation mse 1.0060014724731445\n",
      "Train Epoch 421.3 var loss 71922.6875 reconstruction mse 71920.0703125 imputation mse 1.0059313774108887\n",
      "Train Epoch 421.4 var loss 71908.1171875 reconstruction mse 71905.609375 imputation mse 1.005729079246521\n",
      "Train Epoch 421.5 var loss 71935.6015625 reconstruction mse 71933.1875 imputation mse 1.0061148405075073\n",
      "Train Epoch 421.6 var loss 71942.109375 reconstruction mse 71939.7734375 imputation mse 1.00620698928833\n",
      "Train Epoch 421.7 var loss 71940.3515625 reconstruction mse 71938.0625 imputation mse 1.0061830282211304\n",
      "Train Epoch 421.8 var loss 71913.3828125 reconstruction mse 71911.0859375 imputation mse 1.0058057308197021\n",
      "Train Epoch 421.9 var loss 71924.09375 reconstruction mse 71921.78125 imputation mse 1.0059553384780884\n",
      "Train Epoch 422.0 var loss 70834.71875 reconstruction mse 70832.1796875 imputation mse 0.9931043982505798\n",
      "Train Epoch 422.1 var loss 70862.2421875 reconstruction mse 70859.75 imputation mse 0.993490993976593\n",
      "Train Epoch 422.2 var loss 70827.0859375 reconstruction mse 70824.5234375 imputation mse 0.9929970502853394\n",
      "Train Epoch 422.3 var loss 70882.265625 reconstruction mse 70879.71875 imputation mse 0.993770956993103\n",
      "Train Epoch 422.4 var loss 70804.5234375 reconstruction mse 70802.0703125 imputation mse 0.9926822781562805\n",
      "Train Epoch 422.5 var loss 70821.765625 reconstruction mse 70819.4140625 imputation mse 0.9929254651069641\n",
      "Train Epoch 422.6 var loss 70837.65625 reconstruction mse 70835.3828125 imputation mse 0.9931493401527405\n",
      "Train Epoch 422.7 var loss 70794.71875 reconstruction mse 70792.484375 imputation mse 0.992547869682312\n",
      "Train Epoch 422.8 var loss 70835.671875 reconstruction mse 70833.3984375 imputation mse 0.9931215047836304\n",
      "Train Epoch 422.9 var loss 70866.7890625 reconstruction mse 70864.46875 imputation mse 0.9935571551322937\n",
      "Train Epoch 423.0 var loss 71216.5859375 reconstruction mse 71213.984375 imputation mse 0.9986395239830017\n",
      "Train Epoch 423.1 var loss 71232.1796875 reconstruction mse 71229.609375 imputation mse 0.998858630657196\n",
      "Train Epoch 423.2 var loss 71239.4296875 reconstruction mse 71236.7578125 imputation mse 0.9989588856697083\n",
      "Train Epoch 423.3 var loss 71233.3671875 reconstruction mse 71230.703125 imputation mse 0.9988740086555481\n",
      "Train Epoch 423.4 var loss 71240.875 reconstruction mse 71238.296875 imputation mse 0.9989804625511169\n",
      "Train Epoch 423.5 var loss 71214.625 reconstruction mse 71212.1953125 imputation mse 0.9986144304275513\n",
      "Train Epoch 423.6 var loss 71187.328125 reconstruction mse 71185.0234375 imputation mse 0.998233437538147\n",
      "Train Epoch 423.7 var loss 71262.328125 reconstruction mse 71260.078125 imputation mse 0.9992859363555908\n",
      "Train Epoch 423.8 var loss 71239.484375 reconstruction mse 71237.2578125 imputation mse 0.9989659190177917\n",
      "Train Epoch 423.9 var loss 71216.265625 reconstruction mse 71213.9921875 imputation mse 0.9986396431922913\n",
      "Train Epoch 424.0 var loss 71361.96875 reconstruction mse 71359.453125 imputation mse 1.001508116722107\n",
      "Train Epoch 424.1 var loss 71334.3828125 reconstruction mse 71331.8984375 imputation mse 1.0011214017868042\n",
      "Train Epoch 424.2 var loss 71357.3046875 reconstruction mse 71354.7421875 imputation mse 1.0014419555664062\n",
      "Train Epoch 424.3 var loss 71356.859375 reconstruction mse 71354.3125 imputation mse 1.0014358758926392\n",
      "Train Epoch 424.4 var loss 71357.8046875 reconstruction mse 71355.3515625 imputation mse 1.001450538635254\n",
      "Train Epoch 424.5 var loss 71334.15625 reconstruction mse 71331.8046875 imputation mse 1.0011200904846191\n",
      "Train Epoch 424.6 var loss 71348.734375 reconstruction mse 71346.4296875 imputation mse 1.001325249671936\n",
      "Train Epoch 424.7 var loss 71347.9453125 reconstruction mse 71345.65625 imputation mse 1.001314401626587\n",
      "Train Epoch 424.8 var loss 71338.96875 reconstruction mse 71336.6640625 imputation mse 1.0011882781982422\n",
      "Train Epoch 424.9 var loss 71347.953125 reconstruction mse 71345.6171875 imputation mse 1.0013139247894287\n",
      "Train Epoch 425.0 var loss 72551.3359375 reconstruction mse 72548.75 imputation mse 1.006698727607727\n",
      "Train Epoch 425.1 var loss 72548.96875 reconstruction mse 72546.421875 imputation mse 1.0066664218902588\n",
      "Train Epoch 425.2 var loss 72570.703125 reconstruction mse 72568.0546875 imputation mse 1.0069665908813477\n",
      "Train Epoch 425.3 var loss 72535.3671875 reconstruction mse 72532.7109375 imputation mse 1.0064761638641357\n",
      "Train Epoch 425.4 var loss 72549.421875 reconstruction mse 72546.8828125 imputation mse 1.0066728591918945\n",
      "Train Epoch 425.5 var loss 72550.2890625 reconstruction mse 72547.84375 imputation mse 1.0066860914230347\n",
      "Train Epoch 425.6 var loss 72563.28125 reconstruction mse 72560.90625 imputation mse 1.0068674087524414\n",
      "Train Epoch 425.7 var loss 72545.40625 reconstruction mse 72543.0859375 imputation mse 1.006620168685913\n",
      "Train Epoch 425.8 var loss 72565.21875 reconstruction mse 72562.90625 imputation mse 1.0068951845169067\n",
      "Train Epoch 425.9 var loss 72559.484375 reconstruction mse 72557.15625 imputation mse 1.0068153142929077\n",
      "Train Epoch 426.0 var loss 71612.0546875 reconstruction mse 71609.515625 imputation mse 1.0029765367507935\n",
      "Train Epoch 426.1 var loss 71584.390625 reconstruction mse 71581.875 imputation mse 1.0025893449783325\n",
      "Train Epoch 426.2 var loss 71639.25 reconstruction mse 71636.640625 imputation mse 1.0033564567565918\n",
      "Train Epoch 426.3 var loss 71596.1171875 reconstruction mse 71593.5078125 imputation mse 1.0027523040771484\n",
      "Train Epoch 426.4 var loss 71612.828125 reconstruction mse 71610.28125 imputation mse 1.002987265586853\n",
      "Train Epoch 426.5 var loss 71584.1171875 reconstruction mse 71581.6796875 imputation mse 1.0025866031646729\n",
      "Train Epoch 426.6 var loss 71590.828125 reconstruction mse 71588.4609375 imputation mse 1.0026816129684448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 426.7 var loss 71579.3671875 reconstruction mse 71577.0703125 imputation mse 1.0025221109390259\n",
      "Train Epoch 426.8 var loss 71576.2265625 reconstruction mse 71573.9375 imputation mse 1.0024782419204712\n",
      "Train Epoch 426.9 var loss 71598.203125 reconstruction mse 71595.890625 imputation mse 1.0027856826782227\n",
      "Train Epoch 427.0 var loss 71022.515625 reconstruction mse 71019.9453125 imputation mse 0.9964495301246643\n",
      "Train Epoch 427.1 var loss 71059.6171875 reconstruction mse 71057.1015625 imputation mse 0.9969708323478699\n",
      "Train Epoch 427.2 var loss 71038.859375 reconstruction mse 71036.25 imputation mse 0.9966782927513123\n",
      "Train Epoch 427.3 var loss 71042.6640625 reconstruction mse 71040.0703125 imputation mse 0.9967318773269653\n",
      "Train Epoch 427.4 var loss 71038.8515625 reconstruction mse 71036.3359375 imputation mse 0.9966794848442078\n",
      "Train Epoch 427.5 var loss 70990.4453125 reconstruction mse 70988.0546875 imputation mse 0.9960020780563354\n",
      "Train Epoch 427.6 var loss 71000.1640625 reconstruction mse 70997.8359375 imputation mse 0.9961392879486084\n",
      "Train Epoch 427.7 var loss 71023.3828125 reconstruction mse 71021.109375 imputation mse 0.9964658617973328\n",
      "Train Epoch 427.8 var loss 71015.03125 reconstruction mse 71012.7578125 imputation mse 0.9963486790657043\n",
      "Train Epoch 427.9 var loss 71029.6484375 reconstruction mse 71027.3359375 imputation mse 0.9965531826019287\n",
      "Train Epoch 428.0 var loss 71462.796875 reconstruction mse 71460.203125 imputation mse 1.000871181488037\n",
      "Train Epoch 428.1 var loss 71439.6640625 reconstruction mse 71437.1328125 imputation mse 1.0005481243133545\n",
      "Train Epoch 428.2 var loss 71466.84375 reconstruction mse 71464.2109375 imputation mse 1.0009273290634155\n",
      "Train Epoch 428.3 var loss 71451.1875 reconstruction mse 71448.578125 imputation mse 1.0007083415985107\n",
      "Train Epoch 428.4 var loss 71449.5 reconstruction mse 71447.0 imputation mse 1.0006862878799438\n",
      "Train Epoch 428.5 var loss 71464.03125 reconstruction mse 71461.6640625 imputation mse 1.0008916854858398\n",
      "Train Epoch 428.6 var loss 71462.3828125 reconstruction mse 71460.109375 imputation mse 1.000869870185852\n",
      "Train Epoch 428.7 var loss 71481.2734375 reconstruction mse 71478.9921875 imputation mse 1.0011343955993652\n",
      "Train Epoch 428.8 var loss 71461.71875 reconstruction mse 71459.390625 imputation mse 1.0008598566055298\n",
      "Train Epoch 428.9 var loss 71450.2890625 reconstruction mse 71447.8828125 imputation mse 1.0006986856460571\n",
      "Train Epoch 429.0 var loss 71247.4375 reconstruction mse 71244.8671875 imputation mse 0.998960554599762\n",
      "Train Epoch 429.1 var loss 71257.0234375 reconstruction mse 71254.4296875 imputation mse 0.9990946054458618\n",
      "Train Epoch 429.2 var loss 71287.3359375 reconstruction mse 71284.703125 imputation mse 0.9995191097259521\n",
      "Train Epoch 429.3 var loss 71276.3359375 reconstruction mse 71273.7578125 imputation mse 0.9993656277656555\n",
      "Train Epoch 429.4 var loss 71253.1796875 reconstruction mse 71250.7109375 imputation mse 0.9990425109863281\n",
      "Train Epoch 429.5 var loss 71293.1640625 reconstruction mse 71290.8046875 imputation mse 0.9996046423912048\n",
      "Train Epoch 429.6 var loss 71283.4375 reconstruction mse 71281.171875 imputation mse 0.9994695782661438\n",
      "Train Epoch 429.7 var loss 71270.546875 reconstruction mse 71268.2890625 imputation mse 0.9992889761924744\n",
      "Train Epoch 429.8 var loss 71261.4765625 reconstruction mse 71259.203125 imputation mse 0.9991615414619446\n",
      "Train Epoch 429.9 var loss 71245.0625 reconstruction mse 71242.7421875 imputation mse 0.9989307522773743\n",
      "Train Epoch 430.0 var loss 71713.75 reconstruction mse 71711.2265625 imputation mse 1.0002403259277344\n",
      "Train Epoch 430.1 var loss 71731.0625 reconstruction mse 71728.5234375 imputation mse 1.0004814863204956\n",
      "Train Epoch 430.2 var loss 71727.59375 reconstruction mse 71724.984375 imputation mse 1.0004321336746216\n",
      "Train Epoch 430.3 var loss 71714.84375 reconstruction mse 71712.2578125 imputation mse 1.0002546310424805\n",
      "Train Epoch 430.4 var loss 71719.65625 reconstruction mse 71717.15625 imputation mse 1.000322937965393\n",
      "Train Epoch 430.5 var loss 71703.7265625 reconstruction mse 71701.328125 imputation mse 1.000102162361145\n",
      "Train Epoch 430.6 var loss 71709.734375 reconstruction mse 71707.421875 imputation mse 1.0001871585845947\n",
      "Train Epoch 430.7 var loss 71702.828125 reconstruction mse 71700.546875 imputation mse 1.000091314315796\n",
      "Train Epoch 430.8 var loss 71698.671875 reconstruction mse 71696.375 imputation mse 1.0000331401824951\n",
      "Train Epoch 430.9 var loss 71702.2109375 reconstruction mse 71699.90625 imputation mse 1.0000823736190796\n",
      "====> Test imputation mse: 1.02990663\n",
      "====> Test imputation mse: 1.00553727\n",
      "====> Test imputation mse: 1.00826323\n",
      "Train Epoch 431.0 var loss 71774.921875 reconstruction mse 71772.4296875 imputation mse 1.0077425241470337\n",
      "Train Epoch 431.1 var loss 71762.5234375 reconstruction mse 71760.03125 imputation mse 1.0075684785842896\n",
      "Train Epoch 431.2 var loss 71773.15625 reconstruction mse 71770.59375 imputation mse 1.0077167749404907\n",
      "Train Epoch 431.3 var loss 71786.453125 reconstruction mse 71783.90625 imputation mse 1.0079036951065063\n",
      "Train Epoch 431.4 var loss 71779.0546875 reconstruction mse 71776.6171875 imputation mse 1.0078012943267822\n",
      "Train Epoch 431.5 var loss 71765.765625 reconstruction mse 71763.421875 imputation mse 1.0076160430908203\n",
      "Train Epoch 431.6 var loss 71777.8203125 reconstruction mse 71775.5703125 imputation mse 1.0077866315841675\n",
      "Train Epoch 431.7 var loss 71780.1875 reconstruction mse 71777.984375 imputation mse 1.0078204870224\n",
      "Train Epoch 431.8 var loss 71751.203125 reconstruction mse 71748.9765625 imputation mse 1.0074132680892944\n",
      "Train Epoch 431.9 var loss 71731.203125 reconstruction mse 71728.96875 imputation mse 1.0071322917938232\n",
      "Train Epoch 432.0 var loss 71757.7734375 reconstruction mse 71755.3046875 imputation mse 1.0062446594238281\n",
      "Train Epoch 432.1 var loss 71779.765625 reconstruction mse 71777.3125 imputation mse 1.006553292274475\n",
      "Train Epoch 432.2 var loss 71753.21875 reconstruction mse 71750.671875 imputation mse 1.006179690361023\n",
      "Train Epoch 432.3 var loss 71742.2578125 reconstruction mse 71739.71875 imputation mse 1.006026029586792\n",
      "Train Epoch 432.4 var loss 71741.1875 reconstruction mse 71738.734375 imputation mse 1.0060123205184937\n",
      "Train Epoch 432.5 var loss 71756.8828125 reconstruction mse 71754.5234375 imputation mse 1.0062336921691895\n",
      "Train Epoch 432.6 var loss 71761.015625 reconstruction mse 71758.7421875 imputation mse 1.0062928199768066\n",
      "Train Epoch 432.7 var loss 71752.0390625 reconstruction mse 71749.8125 imputation mse 1.0061676502227783\n",
      "Train Epoch 432.8 var loss 71766.1640625 reconstruction mse 71763.8984375 imputation mse 1.006365180015564\n",
      "Train Epoch 432.9 var loss 71761.8046875 reconstruction mse 71759.4921875 imputation mse 1.006303310394287\n",
      "Train Epoch 433.0 var loss 70885.484375 reconstruction mse 70882.9453125 imputation mse 1.0004225969314575\n",
      "Train Epoch 433.1 var loss 70896.796875 reconstruction mse 70894.34375 imputation mse 1.000583529472351\n",
      "Train Epoch 433.2 var loss 70863.9453125 reconstruction mse 70861.4453125 imputation mse 1.0001192092895508\n",
      "Train Epoch 433.3 var loss 70932.8046875 reconstruction mse 70930.328125 imputation mse 1.0010913610458374\n",
      "Train Epoch 433.4 var loss 70894.3671875 reconstruction mse 70891.953125 imputation mse 1.0005497932434082\n",
      "Train Epoch 433.5 var loss 70916.15625 reconstruction mse 70913.8046875 imputation mse 1.000858187675476\n",
      "Train Epoch 433.6 var loss 70919.421875 reconstruction mse 70917.125 imputation mse 1.0009050369262695\n",
      "Train Epoch 433.7 var loss 70893.859375 reconstruction mse 70891.609375 imputation mse 1.0005449056625366\n",
      "Train Epoch 433.8 var loss 70874.328125 reconstruction mse 70872.0625 imputation mse 1.0002690553665161\n",
      "Train Epoch 433.9 var loss 70925.0859375 reconstruction mse 70922.8046875 imputation mse 1.0009851455688477\n",
      "Train Epoch 434.0 var loss 71802.8671875 reconstruction mse 71800.34375 imputation mse 1.002364158630371\n",
      "Train Epoch 434.1 var loss 71781.171875 reconstruction mse 71778.7109375 imputation mse 1.0020620822906494\n",
      "Train Epoch 434.2 var loss 71810.953125 reconstruction mse 71808.4140625 imputation mse 1.0024768114089966\n",
      "Train Epoch 434.3 var loss 71810.15625 reconstruction mse 71807.671875 imputation mse 1.0024664402008057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 434.4 var loss 71781.0390625 reconstruction mse 71778.6640625 imputation mse 1.0020614862442017\n",
      "Train Epoch 434.5 var loss 71829.0703125 reconstruction mse 71826.8046875 imputation mse 1.0027334690093994\n",
      "Train Epoch 434.6 var loss 71809.2109375 reconstruction mse 71807.0078125 imputation mse 1.0024571418762207\n",
      "Train Epoch 434.7 var loss 71799.625 reconstruction mse 71797.4375 imputation mse 1.0023235082626343\n",
      "Train Epoch 434.8 var loss 71774.2578125 reconstruction mse 71772.046875 imputation mse 1.0019690990447998\n",
      "Train Epoch 434.9 var loss 71817.28125 reconstruction mse 71815.0390625 imputation mse 1.002569317817688\n",
      "Train Epoch 435.0 var loss 71294.109375 reconstruction mse 71291.6015625 imputation mse 0.9989855289459229\n",
      "Train Epoch 435.1 var loss 71290.59375 reconstruction mse 71288.125 imputation mse 0.9989367723464966\n",
      "Train Epoch 435.2 var loss 71253.2109375 reconstruction mse 71250.671875 imputation mse 0.9984119534492493\n",
      "Train Epoch 435.3 var loss 71266.1875 reconstruction mse 71263.6640625 imputation mse 0.9985940456390381\n",
      "Train Epoch 435.4 var loss 71251.6328125 reconstruction mse 71249.21875 imputation mse 0.9983916282653809\n",
      "Train Epoch 435.5 var loss 71277.078125 reconstruction mse 71274.7734375 imputation mse 0.9987496733665466\n",
      "Train Epoch 435.6 var loss 71265.21875 reconstruction mse 71262.9921875 imputation mse 0.9985846281051636\n",
      "Train Epoch 435.7 var loss 71244.078125 reconstruction mse 71241.859375 imputation mse 0.9982885122299194\n",
      "Train Epoch 435.8 var loss 71266.640625 reconstruction mse 71264.3828125 imputation mse 0.9986041188240051\n",
      "Train Epoch 435.9 var loss 71223.9375 reconstruction mse 71221.6171875 imputation mse 0.9980048537254333\n",
      "Train Epoch 436.0 var loss 71710.4765625 reconstruction mse 71707.96875 imputation mse 1.0000553131103516\n",
      "Train Epoch 436.1 var loss 71690.2578125 reconstruction mse 71687.7265625 imputation mse 0.9997730255126953\n",
      "Train Epoch 436.2 var loss 71689.453125 reconstruction mse 71686.8671875 imputation mse 0.9997610449790955\n",
      "Train Epoch 436.3 var loss 71671.7265625 reconstruction mse 71669.1640625 imputation mse 0.9995141625404358\n",
      "Train Epoch 436.4 var loss 71697.0625 reconstruction mse 71694.6015625 imputation mse 0.9998689293861389\n",
      "Train Epoch 436.5 var loss 71709.46875 reconstruction mse 71707.125 imputation mse 1.0000436305999756\n",
      "Train Epoch 436.6 var loss 71711.671875 reconstruction mse 71709.3984375 imputation mse 1.000075340270996\n",
      "Train Epoch 436.7 var loss 71672.484375 reconstruction mse 71670.25 imputation mse 0.9995293021202087\n",
      "Train Epoch 436.8 var loss 71689.515625 reconstruction mse 71687.2734375 imputation mse 0.9997667074203491\n",
      "Train Epoch 436.9 var loss 71691.4296875 reconstruction mse 71689.15625 imputation mse 0.9997929930686951\n",
      "Train Epoch 437.0 var loss 71845.484375 reconstruction mse 71843.0234375 imputation mse 1.0036044120788574\n",
      "Train Epoch 437.1 var loss 71837.6953125 reconstruction mse 71835.25 imputation mse 1.0034958124160767\n",
      "Train Epoch 437.2 var loss 71827.53125 reconstruction mse 71825.0078125 imputation mse 1.0033527612686157\n",
      "Train Epoch 437.3 var loss 71816.859375 reconstruction mse 71814.3515625 imputation mse 1.0032038688659668\n",
      "Train Epoch 437.4 var loss 71833.8046875 reconstruction mse 71831.3828125 imputation mse 1.0034418106079102\n",
      "Train Epoch 437.5 var loss 71840.921875 reconstruction mse 71838.5859375 imputation mse 1.003542423248291\n",
      "Train Epoch 437.6 var loss 71818.4375 reconstruction mse 71816.1953125 imputation mse 1.0032296180725098\n",
      "Train Epoch 437.7 var loss 71823.8046875 reconstruction mse 71821.609375 imputation mse 1.0033053159713745\n",
      "Train Epoch 437.8 var loss 71815.8125 reconstruction mse 71813.609375 imputation mse 1.0031934976577759\n",
      "Train Epoch 437.9 var loss 71853.0859375 reconstruction mse 71850.8359375 imputation mse 1.003713607788086\n",
      "Train Epoch 438.0 var loss 72035.6953125 reconstruction mse 72033.2109375 imputation mse 1.0038492679595947\n",
      "Train Epoch 438.1 var loss 72028.375 reconstruction mse 72025.9296875 imputation mse 1.003747820854187\n",
      "Train Epoch 438.2 var loss 72029.4375 reconstruction mse 72026.890625 imputation mse 1.0037611722946167\n",
      "Train Epoch 438.3 var loss 72035.171875 reconstruction mse 72032.65625 imputation mse 1.003841519355774\n",
      "Train Epoch 438.4 var loss 72023.1328125 reconstruction mse 72020.703125 imputation mse 1.0036749839782715\n",
      "Train Epoch 438.5 var loss 72050.953125 reconstruction mse 72048.6328125 imputation mse 1.0040642023086548\n",
      "Train Epoch 438.6 var loss 72035.484375 reconstruction mse 72033.25 imputation mse 1.003849744796753\n",
      "Train Epoch 438.7 var loss 72009.890625 reconstruction mse 72007.7109375 imputation mse 1.0034939050674438\n",
      "Train Epoch 438.8 var loss 72045.3984375 reconstruction mse 72043.1875 imputation mse 1.003988265991211\n",
      "Train Epoch 438.9 var loss 72059.3671875 reconstruction mse 72057.1171875 imputation mse 1.0041824579238892\n",
      "Train Epoch 439.0 var loss 71314.09375 reconstruction mse 71311.640625 imputation mse 0.9950831532478333\n",
      "Train Epoch 439.1 var loss 71354.3671875 reconstruction mse 71351.8828125 imputation mse 0.9956446886062622\n",
      "Train Epoch 439.2 var loss 71296.390625 reconstruction mse 71293.8125 imputation mse 0.9948344230651855\n",
      "Train Epoch 439.3 var loss 71291.8984375 reconstruction mse 71289.3828125 imputation mse 0.9947726130485535\n",
      "Train Epoch 439.4 var loss 71321.34375 reconstruction mse 71318.9453125 imputation mse 0.9951850771903992\n",
      "Train Epoch 439.5 var loss 71326.0546875 reconstruction mse 71323.78125 imputation mse 0.9952526092529297\n",
      "Train Epoch 439.6 var loss 71317.7109375 reconstruction mse 71315.4921875 imputation mse 0.9951369166374207\n",
      "Train Epoch 439.7 var loss 71347.984375 reconstruction mse 71345.7734375 imputation mse 0.9955594539642334\n",
      "Train Epoch 439.8 var loss 71303.78125 reconstruction mse 71301.5546875 imputation mse 0.9949424266815186\n",
      "Train Epoch 439.9 var loss 71300.03125 reconstruction mse 71297.7421875 imputation mse 0.9948892593383789\n",
      "Train Epoch 440.0 var loss 71277.0546875 reconstruction mse 71274.59375 imputation mse 0.9983274936676025\n",
      "Train Epoch 440.1 var loss 71260.0 reconstruction mse 71257.5234375 imputation mse 0.9980884194374084\n",
      "Train Epoch 440.2 var loss 71310.9609375 reconstruction mse 71308.4140625 imputation mse 0.9988012313842773\n",
      "Train Epoch 440.3 var loss 71280.3203125 reconstruction mse 71277.8359375 imputation mse 0.9983729124069214\n",
      "Train Epoch 440.4 var loss 71270.4765625 reconstruction mse 71268.09375 imputation mse 0.9982364773750305\n",
      "Train Epoch 440.5 var loss 71245.6796875 reconstruction mse 71243.421875 imputation mse 0.9978908896446228\n",
      "Train Epoch 440.6 var loss 71284.359375 reconstruction mse 71282.15625 imputation mse 0.9984334111213684\n",
      "Train Epoch 440.7 var loss 71270.7578125 reconstruction mse 71268.5546875 imputation mse 0.9982429146766663\n",
      "Train Epoch 440.8 var loss 71257.0859375 reconstruction mse 71254.8671875 imputation mse 0.9980512261390686\n",
      "Train Epoch 440.9 var loss 71280.4921875 reconstruction mse 71278.2578125 imputation mse 0.9983788132667542\n",
      "====> Test imputation mse: 0.98048782\n",
      "====> Test imputation mse: 0.99582022\n",
      "====> Test imputation mse: 0.98668152\n",
      "Train Epoch 441.0 var loss 71673.9609375 reconstruction mse 71671.515625 imputation mse 1.0000489950180054\n",
      "Train Epoch 441.1 var loss 71674.1015625 reconstruction mse 71671.7109375 imputation mse 1.000051736831665\n",
      "Train Epoch 441.2 var loss 71665.5546875 reconstruction mse 71663.09375 imputation mse 0.9999315142631531\n",
      "Train Epoch 441.3 var loss 71694.671875 reconstruction mse 71692.21875 imputation mse 1.0003379583358765\n",
      "Train Epoch 441.4 var loss 71663.0234375 reconstruction mse 71660.640625 imputation mse 0.999897301197052\n",
      "Train Epoch 441.5 var loss 71692.0 reconstruction mse 71689.703125 imputation mse 1.000302791595459\n",
      "Train Epoch 441.6 var loss 71728.0859375 reconstruction mse 71725.8515625 imputation mse 1.0008071660995483\n",
      "Train Epoch 441.7 var loss 71654.359375 reconstruction mse 71652.171875 imputation mse 0.9997791647911072\n",
      "Train Epoch 441.8 var loss 71699.2578125 reconstruction mse 71697.0625 imputation mse 1.0004055500030518\n",
      "Train Epoch 441.9 var loss 71678.4296875 reconstruction mse 71676.203125 imputation mse 1.0001144409179688\n",
      "Train Epoch 442.0 var loss 72178.109375 reconstruction mse 72175.6953125 imputation mse 1.0085898637771606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 442.1 var loss 72215.390625 reconstruction mse 72212.9375 imputation mse 1.0091102123260498\n",
      "Train Epoch 442.2 var loss 72170.4609375 reconstruction mse 72167.953125 imputation mse 1.0084816217422485\n",
      "Train Epoch 442.3 var loss 72197.0234375 reconstruction mse 72194.515625 imputation mse 1.0088528394699097\n",
      "Train Epoch 442.4 var loss 72182.4375 reconstruction mse 72180.0234375 imputation mse 1.008650302886963\n",
      "Train Epoch 442.5 var loss 72192.5546875 reconstruction mse 72190.2578125 imputation mse 1.0087933540344238\n",
      "Train Epoch 442.6 var loss 72201.71875 reconstruction mse 72199.484375 imputation mse 1.0089222192764282\n",
      "Train Epoch 442.7 var loss 72156.7890625 reconstruction mse 72154.5859375 imputation mse 1.0082948207855225\n",
      "Train Epoch 442.8 var loss 72197.3046875 reconstruction mse 72195.09375 imputation mse 1.0088608264923096\n",
      "Train Epoch 442.9 var loss 72200.3046875 reconstruction mse 72198.0546875 imputation mse 1.0089023113250732\n",
      "Train Epoch 443.0 var loss 70796.6953125 reconstruction mse 70794.25 imputation mse 0.9880151748657227\n",
      "Train Epoch 443.1 var loss 70834.6953125 reconstruction mse 70832.2265625 imputation mse 0.9885451793670654\n",
      "Train Epoch 443.2 var loss 70822.3984375 reconstruction mse 70819.8671875 imputation mse 0.9883726835250854\n",
      "Train Epoch 443.3 var loss 70870.3125 reconstruction mse 70867.796875 imputation mse 0.9890415668487549\n",
      "Train Epoch 443.4 var loss 70836.484375 reconstruction mse 70834.0546875 imputation mse 0.9885706901550293\n",
      "Train Epoch 443.5 var loss 70833.5546875 reconstruction mse 70831.2265625 imputation mse 0.988531231880188\n",
      "Train Epoch 443.6 var loss 70799.8828125 reconstruction mse 70797.65625 imputation mse 0.9880626797676086\n",
      "Train Epoch 443.7 var loss 70811.6875 reconstruction mse 70809.5234375 imputation mse 0.9882283210754395\n",
      "Train Epoch 443.8 var loss 70789.203125 reconstruction mse 70787.0390625 imputation mse 0.987914502620697\n",
      "Train Epoch 443.9 var loss 70816.578125 reconstruction mse 70814.3984375 imputation mse 0.9882963299751282\n",
      "Train Epoch 444.0 var loss 71258.6953125 reconstruction mse 71256.2734375 imputation mse 0.9970514178276062\n",
      "Train Epoch 444.1 var loss 71227.640625 reconstruction mse 71225.2734375 imputation mse 0.9966176748275757\n",
      "Train Epoch 444.2 var loss 71266.4765625 reconstruction mse 71264.0390625 imputation mse 0.9971600770950317\n",
      "Train Epoch 444.3 var loss 71293.859375 reconstruction mse 71291.421875 imputation mse 0.997543215751648\n",
      "Train Epoch 444.4 var loss 71277.890625 reconstruction mse 71275.546875 imputation mse 0.9973210692405701\n",
      "Train Epoch 444.5 var loss 71250.578125 reconstruction mse 71248.3125 imputation mse 0.996940016746521\n",
      "Train Epoch 444.6 var loss 71257.5 reconstruction mse 71255.328125 imputation mse 0.9970381855964661\n",
      "Train Epoch 444.7 var loss 71215.0078125 reconstruction mse 71212.859375 imputation mse 0.9964439272880554\n",
      "Train Epoch 444.8 var loss 71227.7578125 reconstruction mse 71225.5859375 imputation mse 0.9966220259666443\n",
      "Train Epoch 444.9 var loss 71271.625 reconstruction mse 71269.4296875 imputation mse 0.9972354769706726\n",
      "Train Epoch 445.0 var loss 71101.78125 reconstruction mse 71099.359375 imputation mse 0.9962776899337769\n",
      "Train Epoch 445.1 var loss 71052.7421875 reconstruction mse 71050.3515625 imputation mse 0.9955909848213196\n",
      "Train Epoch 445.2 var loss 71057.75 reconstruction mse 71055.3046875 imputation mse 0.9956604242324829\n",
      "Train Epoch 445.3 var loss 71090.609375 reconstruction mse 71088.1640625 imputation mse 0.9961208701133728\n",
      "Train Epoch 445.4 var loss 71060.8828125 reconstruction mse 71058.515625 imputation mse 0.9957054257392883\n",
      "Train Epoch 445.5 var loss 71064.921875 reconstruction mse 71062.6484375 imputation mse 0.9957633018493652\n",
      "Train Epoch 445.6 var loss 71061.8125 reconstruction mse 71059.6171875 imputation mse 0.9957208037376404\n",
      "Train Epoch 445.7 var loss 71065.5625 reconstruction mse 71063.3828125 imputation mse 0.9957736134529114\n",
      "Train Epoch 445.8 var loss 71066.1796875 reconstruction mse 71063.9921875 imputation mse 0.9957821369171143\n",
      "Train Epoch 445.9 var loss 71045.5703125 reconstruction mse 71043.3671875 imputation mse 0.9954931139945984\n",
      "Train Epoch 446.0 var loss 71577.046875 reconstruction mse 71574.65625 imputation mse 1.0056151151657104\n",
      "Train Epoch 446.1 var loss 71580.046875 reconstruction mse 71577.71875 imputation mse 1.0056581497192383\n",
      "Train Epoch 446.2 var loss 71579.90625 reconstruction mse 71577.5 imputation mse 1.00565505027771\n",
      "Train Epoch 446.3 var loss 71567.7578125 reconstruction mse 71565.375 imputation mse 1.005484700202942\n",
      "Train Epoch 446.4 var loss 71593.484375 reconstruction mse 71591.171875 imputation mse 1.0058472156524658\n",
      "Train Epoch 446.5 var loss 71579.234375 reconstruction mse 71576.9609375 imputation mse 1.0056475400924683\n",
      "Train Epoch 446.6 var loss 71590.6796875 reconstruction mse 71588.4609375 imputation mse 1.0058090686798096\n",
      "Train Epoch 446.7 var loss 71599.515625 reconstruction mse 71597.3125 imputation mse 1.005933403968811\n",
      "Train Epoch 446.8 var loss 71578.0625 reconstruction mse 71575.8671875 imputation mse 1.0056321620941162\n",
      "Train Epoch 446.9 var loss 71591.7421875 reconstruction mse 71589.5390625 imputation mse 1.0058242082595825\n",
      "Train Epoch 447.0 var loss 71481.15625 reconstruction mse 71478.765625 imputation mse 0.9982649683952332\n",
      "Train Epoch 447.1 var loss 71460.203125 reconstruction mse 71457.796875 imputation mse 0.9979721307754517\n",
      "Train Epoch 447.2 var loss 71478.9765625 reconstruction mse 71476.4921875 imputation mse 0.9982331991195679\n",
      "Train Epoch 447.3 var loss 71482.8046875 reconstruction mse 71480.359375 imputation mse 0.9982872009277344\n",
      "Train Epoch 447.4 var loss 71494.6953125 reconstruction mse 71492.3359375 imputation mse 0.9984544515609741\n",
      "Train Epoch 447.5 var loss 71506.6171875 reconstruction mse 71504.34375 imputation mse 0.9986221790313721\n",
      "Train Epoch 447.6 var loss 71489.8359375 reconstruction mse 71487.6171875 imputation mse 0.9983885884284973\n",
      "Train Epoch 447.7 var loss 71459.6953125 reconstruction mse 71457.5078125 imputation mse 0.9979680776596069\n",
      "Train Epoch 447.8 var loss 71452.84375 reconstruction mse 71450.640625 imputation mse 0.9978721737861633\n",
      "Train Epoch 447.9 var loss 71480.53125 reconstruction mse 71478.2890625 imputation mse 0.9982582926750183\n",
      "Train Epoch 448.0 var loss 71596.640625 reconstruction mse 71594.21875 imputation mse 1.0017380714416504\n",
      "Train Epoch 448.1 var loss 71598.0703125 reconstruction mse 71595.6484375 imputation mse 1.001758098602295\n",
      "Train Epoch 448.2 var loss 71538.4765625 reconstruction mse 71536.0078125 imputation mse 1.00092351436615\n",
      "Train Epoch 448.3 var loss 71591.3046875 reconstruction mse 71588.8671875 imputation mse 1.0016632080078125\n",
      "Train Epoch 448.4 var loss 71599.8828125 reconstruction mse 71597.5234375 imputation mse 1.001784324645996\n",
      "Train Epoch 448.5 var loss 71531.3828125 reconstruction mse 71529.1015625 imputation mse 1.0008269548416138\n",
      "Train Epoch 448.6 var loss 71576.828125 reconstruction mse 71574.6171875 imputation mse 1.001463770866394\n",
      "Train Epoch 448.7 var loss 71583.1484375 reconstruction mse 71580.9453125 imputation mse 1.0015523433685303\n",
      "Train Epoch 448.8 var loss 71575.5859375 reconstruction mse 71573.3671875 imputation mse 1.00144624710083\n",
      "Train Epoch 448.9 var loss 71593.0703125 reconstruction mse 71590.84375 imputation mse 1.0016908645629883\n",
      "Train Epoch 449.0 var loss 71249.5703125 reconstruction mse 71247.140625 imputation mse 0.9979150295257568\n",
      "Train Epoch 449.1 var loss 71228.109375 reconstruction mse 71225.7109375 imputation mse 0.997614860534668\n",
      "Train Epoch 449.2 var loss 71238.984375 reconstruction mse 71236.515625 imputation mse 0.9977661967277527\n",
      "Train Epoch 449.3 var loss 71258.484375 reconstruction mse 71256.015625 imputation mse 0.9980393052101135\n",
      "Train Epoch 449.4 var loss 71271.328125 reconstruction mse 71268.921875 imputation mse 0.9982200860977173\n",
      "Train Epoch 449.5 var loss 71269.171875 reconstruction mse 71266.875 imputation mse 0.9981914162635803\n",
      "Train Epoch 449.6 var loss 71261.4765625 reconstruction mse 71259.28125 imputation mse 0.998085081577301\n",
      "Train Epoch 449.7 var loss 71253.71875 reconstruction mse 71251.5703125 imputation mse 0.997977077960968\n",
      "Train Epoch 449.8 var loss 71233.6953125 reconstruction mse 71231.5390625 imputation mse 0.9976965188980103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 449.9 var loss 71229.265625 reconstruction mse 71227.0859375 imputation mse 0.9976341128349304\n",
      "Train Epoch 450.0 var loss 71975.4765625 reconstruction mse 71973.0703125 imputation mse 1.0044108629226685\n",
      "Train Epoch 450.1 var loss 71972.3125 reconstruction mse 71969.8828125 imputation mse 1.004366397857666\n",
      "Train Epoch 450.2 var loss 71977.0859375 reconstruction mse 71974.5625 imputation mse 1.0044317245483398\n",
      "Train Epoch 450.3 var loss 71958.0859375 reconstruction mse 71955.578125 imputation mse 1.0041667222976685\n",
      "Train Epoch 450.4 var loss 71977.859375 reconstruction mse 71975.4453125 imputation mse 1.0044440031051636\n",
      "Train Epoch 450.5 var loss 71972.1640625 reconstruction mse 71969.8671875 imputation mse 1.004366159439087\n",
      "Train Epoch 450.6 var loss 71952.5546875 reconstruction mse 71950.34375 imputation mse 1.0040937662124634\n",
      "Train Epoch 450.7 var loss 71931.96875 reconstruction mse 71929.796875 imputation mse 1.0038069486618042\n",
      "Train Epoch 450.8 var loss 71946.0703125 reconstruction mse 71943.9140625 imputation mse 1.0040040016174316\n",
      "Train Epoch 450.9 var loss 71935.3984375 reconstruction mse 71933.234375 imputation mse 1.0038549900054932\n",
      "====> Test imputation mse: 1.01025748\n",
      "====> Test imputation mse: 1.00538170\n",
      "====> Test imputation mse: 0.98285049\n",
      "Train Epoch 451.0 var loss 72477.765625 reconstruction mse 72475.3359375 imputation mse 1.0103204250335693\n",
      "Train Epoch 451.1 var loss 72430.1328125 reconstruction mse 72427.78125 imputation mse 1.0096575021743774\n",
      "Train Epoch 451.2 var loss 72385.265625 reconstruction mse 72382.828125 imputation mse 1.009030818939209\n",
      "Train Epoch 451.3 var loss 72426.5625 reconstruction mse 72424.125 imputation mse 1.0096064805984497\n",
      "Train Epoch 451.4 var loss 72420.8828125 reconstruction mse 72418.5078125 imputation mse 1.0095282793045044\n",
      "Train Epoch 451.5 var loss 72419.90625 reconstruction mse 72417.59375 imputation mse 1.0095155239105225\n",
      "Train Epoch 451.6 var loss 72387.4921875 reconstruction mse 72385.21875 imputation mse 1.0090641975402832\n",
      "Train Epoch 451.7 var loss 72442.1015625 reconstruction mse 72439.8515625 imputation mse 1.0098258256912231\n",
      "Train Epoch 451.8 var loss 72397.328125 reconstruction mse 72395.1015625 imputation mse 1.009202003479004\n",
      "Train Epoch 451.9 var loss 72406.15625 reconstruction mse 72403.921875 imputation mse 1.0093249082565308\n",
      "Train Epoch 452.0 var loss 72380.796875 reconstruction mse 72378.34375 imputation mse 1.0146117210388184\n",
      "Train Epoch 452.1 var loss 72385.1171875 reconstruction mse 72382.703125 imputation mse 1.014672875404358\n",
      "Train Epoch 452.2 var loss 72377.4296875 reconstruction mse 72374.9453125 imputation mse 1.0145641565322876\n",
      "Train Epoch 452.3 var loss 72350.0 reconstruction mse 72347.5234375 imputation mse 1.0141797065734863\n",
      "Train Epoch 452.4 var loss 72401.5859375 reconstruction mse 72399.1796875 imputation mse 1.0149037837982178\n",
      "Train Epoch 452.5 var loss 72401.9765625 reconstruction mse 72399.65625 imputation mse 1.0149104595184326\n",
      "Train Epoch 452.6 var loss 72399.203125 reconstruction mse 72396.9609375 imputation mse 1.014872670173645\n",
      "Train Epoch 452.7 var loss 72411.7421875 reconstruction mse 72409.5390625 imputation mse 1.0150490999221802\n",
      "Train Epoch 452.8 var loss 72388.921875 reconstruction mse 72386.7265625 imputation mse 1.0147292613983154\n",
      "Train Epoch 452.9 var loss 72369.859375 reconstruction mse 72367.65625 imputation mse 1.014461874961853\n",
      "Train Epoch 453.0 var loss 71531.34375 reconstruction mse 71528.890625 imputation mse 1.0049580335617065\n",
      "Train Epoch 453.1 var loss 71495.3125 reconstruction mse 71492.8984375 imputation mse 1.0044523477554321\n",
      "Train Epoch 453.2 var loss 71504.5078125 reconstruction mse 71502.0078125 imputation mse 1.0045802593231201\n",
      "Train Epoch 453.3 var loss 71495.46875 reconstruction mse 71492.9765625 imputation mse 1.004453420639038\n",
      "Train Epoch 453.4 var loss 71514.75 reconstruction mse 71512.3515625 imputation mse 1.0047255754470825\n",
      "Train Epoch 453.5 var loss 71489.1953125 reconstruction mse 71486.8984375 imputation mse 1.0043680667877197\n",
      "Train Epoch 453.6 var loss 71506.140625 reconstruction mse 71503.90625 imputation mse 1.0046069622039795\n",
      "Train Epoch 453.7 var loss 71520.1171875 reconstruction mse 71517.8984375 imputation mse 1.0048035383224487\n",
      "Train Epoch 453.8 var loss 71499.78125 reconstruction mse 71497.5546875 imputation mse 1.0045177936553955\n",
      "Train Epoch 453.9 var loss 71522.5625 reconstruction mse 71520.2890625 imputation mse 1.004837155342102\n",
      "Train Epoch 454.0 var loss 71551.828125 reconstruction mse 71549.3828125 imputation mse 1.0017554759979248\n",
      "Train Epoch 454.1 var loss 71530.375 reconstruction mse 71527.90625 imputation mse 1.0014548301696777\n",
      "Train Epoch 454.2 var loss 71527.046875 reconstruction mse 71524.484375 imputation mse 1.0014069080352783\n",
      "Train Epoch 454.3 var loss 71497.2734375 reconstruction mse 71494.7578125 imputation mse 1.000990629196167\n",
      "Train Epoch 454.4 var loss 71521.4921875 reconstruction mse 71519.0859375 imputation mse 1.0013313293457031\n",
      "Train Epoch 454.5 var loss 71523.96875 reconstruction mse 71521.65625 imputation mse 1.0013673305511475\n",
      "Train Epoch 454.6 var loss 71514.7734375 reconstruction mse 71512.515625 imputation mse 1.00123929977417\n",
      "Train Epoch 454.7 var loss 71501.0703125 reconstruction mse 71498.84375 imputation mse 1.0010478496551514\n",
      "Train Epoch 454.8 var loss 71524.484375 reconstruction mse 71522.265625 imputation mse 1.0013757944107056\n",
      "Train Epoch 454.9 var loss 71481.203125 reconstruction mse 71478.9921875 imputation mse 1.0007699728012085\n",
      "Train Epoch 455.0 var loss 72464.8828125 reconstruction mse 72462.4453125 imputation mse 1.0100703239440918\n",
      "Train Epoch 455.1 var loss 72458.390625 reconstruction mse 72456.0078125 imputation mse 1.00998055934906\n",
      "Train Epoch 455.2 var loss 72474.1328125 reconstruction mse 72471.6484375 imputation mse 1.0101985931396484\n",
      "Train Epoch 455.3 var loss 72457.7421875 reconstruction mse 72455.2578125 imputation mse 1.0099701881408691\n",
      "Train Epoch 455.4 var loss 72483.828125 reconstruction mse 72481.4296875 imputation mse 1.0103349685668945\n",
      "Train Epoch 455.5 var loss 72500.859375 reconstruction mse 72498.5546875 imputation mse 1.0105736255645752\n",
      "Train Epoch 455.6 var loss 72447.703125 reconstruction mse 72445.5 imputation mse 1.0098341703414917\n",
      "Train Epoch 455.7 var loss 72439.5390625 reconstruction mse 72437.359375 imputation mse 1.0097206830978394\n",
      "Train Epoch 455.8 var loss 72453.265625 reconstruction mse 72451.0703125 imputation mse 1.0099117755889893\n",
      "Train Epoch 455.9 var loss 72432.078125 reconstruction mse 72429.8828125 imputation mse 1.0096163749694824\n",
      "Train Epoch 456.0 var loss 71764.4375 reconstruction mse 71762.0 imputation mse 1.0053657293319702\n",
      "Train Epoch 456.1 var loss 71762.3125 reconstruction mse 71759.890625 imputation mse 1.0053361654281616\n",
      "Train Epoch 456.2 var loss 71796.046875 reconstruction mse 71793.515625 imputation mse 1.0058072805404663\n",
      "Train Epoch 456.3 var loss 71806.9453125 reconstruction mse 71804.4609375 imputation mse 1.0059605836868286\n",
      "Train Epoch 456.4 var loss 71788.828125 reconstruction mse 71786.4296875 imputation mse 1.0057079792022705\n",
      "Train Epoch 456.5 var loss 71767.1015625 reconstruction mse 71764.8203125 imputation mse 1.0054051876068115\n",
      "Train Epoch 456.6 var loss 71768.6015625 reconstruction mse 71766.3828125 imputation mse 1.0054271221160889\n",
      "Train Epoch 456.7 var loss 71805.765625 reconstruction mse 71803.578125 imputation mse 1.0059481859207153\n",
      "Train Epoch 456.8 var loss 71794.25 reconstruction mse 71792.046875 imputation mse 1.005786657333374\n",
      "Train Epoch 456.9 var loss 71763.6875 reconstruction mse 71761.4765625 imputation mse 1.005358338356018\n",
      "Train Epoch 457.0 var loss 72200.7734375 reconstruction mse 72198.3515625 imputation mse 1.0097812414169312\n",
      "Train Epoch 457.1 var loss 72211.3046875 reconstruction mse 72208.8984375 imputation mse 1.009928822517395\n",
      "Train Epoch 457.2 var loss 72218.703125 reconstruction mse 72216.2109375 imputation mse 1.0100311040878296\n",
      "Train Epoch 457.3 var loss 72189.4609375 reconstruction mse 72186.984375 imputation mse 1.00962233543396\n",
      "Train Epoch 457.4 var loss 72214.9765625 reconstruction mse 72212.5859375 imputation mse 1.009980320930481\n",
      "Train Epoch 457.5 var loss 72203.7109375 reconstruction mse 72201.40625 imputation mse 1.0098240375518799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 457.6 var loss 72168.1796875 reconstruction mse 72165.96875 imputation mse 1.0093283653259277\n",
      "Train Epoch 457.7 var loss 72202.75 reconstruction mse 72200.5390625 imputation mse 1.0098118782043457\n",
      "Train Epoch 457.8 var loss 72219.015625 reconstruction mse 72216.796875 imputation mse 1.010039210319519\n",
      "Train Epoch 457.9 var loss 72207.3046875 reconstruction mse 72205.0390625 imputation mse 1.0098748207092285\n",
      "Train Epoch 458.0 var loss 72232.8359375 reconstruction mse 72230.390625 imputation mse 1.0066813230514526\n",
      "Train Epoch 458.1 var loss 72266.6328125 reconstruction mse 72264.1328125 imputation mse 1.0071516036987305\n",
      "Train Epoch 458.2 var loss 72210.8125 reconstruction mse 72208.234375 imputation mse 1.0063725709915161\n",
      "Train Epoch 458.3 var loss 72241.7734375 reconstruction mse 72239.2109375 imputation mse 1.0068042278289795\n",
      "Train Epoch 458.4 var loss 72225.9921875 reconstruction mse 72223.546875 imputation mse 1.006585955619812\n",
      "Train Epoch 458.5 var loss 72236.9296875 reconstruction mse 72234.6015625 imputation mse 1.0067399740219116\n",
      "Train Epoch 458.6 var loss 72252.3828125 reconstruction mse 72250.140625 imputation mse 1.0069565773010254\n",
      "Train Epoch 458.7 var loss 72240.1171875 reconstruction mse 72237.9140625 imputation mse 1.0067861080169678\n",
      "Train Epoch 458.8 var loss 72215.2578125 reconstruction mse 72213.0390625 imputation mse 1.006439447402954\n",
      "Train Epoch 458.9 var loss 72232.8671875 reconstruction mse 72230.578125 imputation mse 1.0066839456558228\n",
      "Train Epoch 459.0 var loss 70390.4296875 reconstruction mse 70387.921875 imputation mse 0.988997220993042\n",
      "Train Epoch 459.1 var loss 70373.015625 reconstruction mse 70370.484375 imputation mse 0.9887522459030151\n",
      "Train Epoch 459.2 var loss 70358.671875 reconstruction mse 70356.0546875 imputation mse 0.9885494709014893\n",
      "Train Epoch 459.3 var loss 70387.5078125 reconstruction mse 70384.9375 imputation mse 0.9889553189277649\n",
      "Train Epoch 459.4 var loss 70370.3359375 reconstruction mse 70367.8515625 imputation mse 0.9887152314186096\n",
      "Train Epoch 459.5 var loss 70352.0390625 reconstruction mse 70349.703125 imputation mse 0.9884602427482605\n",
      "Train Epoch 459.6 var loss 70402.1328125 reconstruction mse 70399.8828125 imputation mse 0.9891653060913086\n",
      "Train Epoch 459.7 var loss 70357.4609375 reconstruction mse 70355.2578125 imputation mse 0.9885382652282715\n",
      "Train Epoch 459.8 var loss 70351.609375 reconstruction mse 70349.390625 imputation mse 0.9884558320045471\n",
      "Train Epoch 459.9 var loss 70394.421875 reconstruction mse 70392.1875 imputation mse 0.989057183265686\n",
      "Train Epoch 460.0 var loss 71719.953125 reconstruction mse 71717.5078125 imputation mse 1.0025092363357544\n",
      "Train Epoch 460.1 var loss 71724.359375 reconstruction mse 71721.8984375 imputation mse 1.002570629119873\n",
      "Train Epoch 460.2 var loss 71749.2109375 reconstruction mse 71746.671875 imputation mse 1.002916932106018\n",
      "Train Epoch 460.3 var loss 71717.0625 reconstruction mse 71714.5546875 imputation mse 1.0024679899215698\n",
      "Train Epoch 460.4 var loss 71709.171875 reconstruction mse 71706.765625 imputation mse 1.00235915184021\n",
      "Train Epoch 460.5 var loss 71706.0234375 reconstruction mse 71703.7578125 imputation mse 1.0023170709609985\n",
      "Train Epoch 460.6 var loss 71703.546875 reconstruction mse 71701.359375 imputation mse 1.0022835731506348\n",
      "Train Epoch 460.7 var loss 71708.4140625 reconstruction mse 71706.2265625 imputation mse 1.0023515224456787\n",
      "Train Epoch 460.8 var loss 71708.3671875 reconstruction mse 71706.15625 imputation mse 1.0023505687713623\n",
      "Train Epoch 460.9 var loss 71720.3671875 reconstruction mse 71718.140625 imputation mse 1.0025180578231812\n",
      "====> Test imputation mse: 0.99281317\n",
      "====> Test imputation mse: 1.01206017\n",
      "====> Test imputation mse: 0.99824733\n",
      "Train Epoch 461.0 var loss 71910.1640625 reconstruction mse 71907.75 imputation mse 1.006364345550537\n",
      "Train Epoch 461.1 var loss 71925.3203125 reconstruction mse 71922.875 imputation mse 1.0065759420394897\n",
      "Train Epoch 461.2 var loss 71915.546875 reconstruction mse 71913.015625 imputation mse 1.0064380168914795\n",
      "Train Epoch 461.3 var loss 71914.046875 reconstruction mse 71911.53125 imputation mse 1.0064172744750977\n",
      "Train Epoch 461.4 var loss 71921.1328125 reconstruction mse 71918.7109375 imputation mse 1.006517767906189\n",
      "Train Epoch 461.5 var loss 71902.640625 reconstruction mse 71900.34375 imputation mse 1.006260633468628\n",
      "Train Epoch 461.6 var loss 71902.71875 reconstruction mse 71900.515625 imputation mse 1.006263017654419\n",
      "Train Epoch 461.7 var loss 71895.3125 reconstruction mse 71893.1640625 imputation mse 1.0061601400375366\n",
      "Train Epoch 461.8 var loss 71901.671875 reconstruction mse 71899.53125 imputation mse 1.0062493085861206\n",
      "Train Epoch 461.9 var loss 71900.03125 reconstruction mse 71897.8515625 imputation mse 1.006225824356079\n",
      "Train Epoch 462.0 var loss 71028.578125 reconstruction mse 71026.1640625 imputation mse 0.9978808164596558\n",
      "Train Epoch 462.1 var loss 70999.6796875 reconstruction mse 70997.28125 imputation mse 0.9974750280380249\n",
      "Train Epoch 462.2 var loss 71050.140625 reconstruction mse 71047.6640625 imputation mse 0.9981828927993774\n",
      "Train Epoch 462.3 var loss 71047.4453125 reconstruction mse 71045.015625 imputation mse 0.9981456995010376\n",
      "Train Epoch 462.4 var loss 71040.90625 reconstruction mse 71038.59375 imputation mse 0.9980554580688477\n",
      "Train Epoch 462.5 var loss 71030.390625 reconstruction mse 71028.1875 imputation mse 0.9979092478752136\n",
      "Train Epoch 462.6 var loss 71031.890625 reconstruction mse 71029.765625 imputation mse 0.9979314208030701\n",
      "Train Epoch 462.7 var loss 71002.5234375 reconstruction mse 71000.4296875 imputation mse 0.9975192546844482\n",
      "Train Epoch 462.8 var loss 71028.359375 reconstruction mse 71026.2578125 imputation mse 0.9978821277618408\n",
      "Train Epoch 462.9 var loss 71028.3828125 reconstruction mse 71026.2421875 imputation mse 0.9978819489479065\n",
      "Train Epoch 463.0 var loss 71589.0703125 reconstruction mse 71586.71875 imputation mse 1.0011848211288452\n",
      "Train Epoch 463.1 var loss 71593.5546875 reconstruction mse 71591.21875 imputation mse 1.001247763633728\n",
      "Train Epoch 463.2 var loss 71627.46875 reconstruction mse 71625.0546875 imputation mse 1.0017210245132446\n",
      "Train Epoch 463.3 var loss 71607.1328125 reconstruction mse 71604.7265625 imputation mse 1.001436710357666\n",
      "Train Epoch 463.4 var loss 71615.9296875 reconstruction mse 71613.640625 imputation mse 1.0015614032745361\n",
      "Train Epoch 463.5 var loss 71605.03125 reconstruction mse 71602.8359375 imputation mse 1.0014102458953857\n",
      "Train Epoch 463.6 var loss 71590.5390625 reconstruction mse 71588.40625 imputation mse 1.0012084245681763\n",
      "Train Epoch 463.7 var loss 71595.3984375 reconstruction mse 71593.2734375 imputation mse 1.0012764930725098\n",
      "Train Epoch 463.8 var loss 71615.0234375 reconstruction mse 71612.8515625 imputation mse 1.001550316810608\n",
      "Train Epoch 463.9 var loss 71586.78125 reconstruction mse 71584.5546875 imputation mse 1.0011545419692993\n",
      "Train Epoch 464.0 var loss 70974.59375 reconstruction mse 70972.2109375 imputation mse 0.9912735223770142\n",
      "Train Epoch 464.1 var loss 70974.8515625 reconstruction mse 70972.4375 imputation mse 0.9912766814231873\n",
      "Train Epoch 464.2 var loss 71035.4296875 reconstruction mse 71032.9921875 imputation mse 0.99212247133255\n",
      "Train Epoch 464.3 var loss 70985.984375 reconstruction mse 70983.6015625 imputation mse 0.9914326071739197\n",
      "Train Epoch 464.4 var loss 71020.421875 reconstruction mse 71018.125 imputation mse 0.9919148087501526\n",
      "Train Epoch 464.5 var loss 71000.2265625 reconstruction mse 70998.03125 imputation mse 0.99163419008255\n",
      "Train Epoch 464.6 var loss 70989.4375 reconstruction mse 70987.296875 imputation mse 0.9914842247962952\n",
      "Train Epoch 464.7 var loss 70957.71875 reconstruction mse 70955.578125 imputation mse 0.9910412430763245\n",
      "Train Epoch 464.8 var loss 70987.2578125 reconstruction mse 70985.078125 imputation mse 0.991453230381012\n",
      "Train Epoch 464.9 var loss 71014.7421875 reconstruction mse 71012.5234375 imputation mse 0.9918365478515625\n",
      "Train Epoch 465.0 var loss 71906.7578125 reconstruction mse 71904.328125 imputation mse 1.0057533979415894\n",
      "Train Epoch 465.1 var loss 71911.78125 reconstruction mse 71909.375 imputation mse 1.0058239698410034\n",
      "Train Epoch 465.2 var loss 71894.9609375 reconstruction mse 71892.5234375 imputation mse 1.0055882930755615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 465.3 var loss 71921.328125 reconstruction mse 71918.921875 imputation mse 1.0059574842453003\n",
      "Train Epoch 465.4 var loss 71904.34375 reconstruction mse 71902.046875 imputation mse 1.0057214498519897\n",
      "Train Epoch 465.5 var loss 71943.7734375 reconstruction mse 71941.578125 imputation mse 1.0062744617462158\n",
      "Train Epoch 465.6 var loss 71901.953125 reconstruction mse 71899.828125 imputation mse 1.0056904554367065\n",
      "Train Epoch 465.7 var loss 71899.2734375 reconstruction mse 71897.171875 imputation mse 1.0056532621383667\n",
      "Train Epoch 465.8 var loss 71912.1796875 reconstruction mse 71910.0625 imputation mse 1.005833625793457\n",
      "Train Epoch 465.9 var loss 71923.1171875 reconstruction mse 71920.9296875 imputation mse 1.0059856176376343\n",
      "Train Epoch 466.0 var loss 71059.8359375 reconstruction mse 71057.4765625 imputation mse 0.9926862716674805\n",
      "Train Epoch 466.1 var loss 71060.09375 reconstruction mse 71057.703125 imputation mse 0.9926894307136536\n",
      "Train Epoch 466.2 var loss 71056.953125 reconstruction mse 71054.5078125 imputation mse 0.9926447868347168\n",
      "Train Epoch 466.3 var loss 71048.3046875 reconstruction mse 71045.921875 imputation mse 0.9925248622894287\n",
      "Train Epoch 466.4 var loss 71031.3046875 reconstruction mse 71029.0234375 imputation mse 0.9922887682914734\n",
      "Train Epoch 466.5 var loss 71068.53125 reconstruction mse 71066.3828125 imputation mse 0.9928107261657715\n",
      "Train Epoch 466.6 var loss 71051.5859375 reconstruction mse 71049.4921875 imputation mse 0.9925747513771057\n",
      "Train Epoch 466.7 var loss 71026.8828125 reconstruction mse 71024.8046875 imputation mse 0.9922298192977905\n",
      "Train Epoch 466.8 var loss 71048.9296875 reconstruction mse 71046.796875 imputation mse 0.9925370812416077\n",
      "Train Epoch 466.9 var loss 71057.5390625 reconstruction mse 71055.3359375 imputation mse 0.9926563501358032\n",
      "Train Epoch 467.0 var loss 71719.921875 reconstruction mse 71717.5078125 imputation mse 1.0053198337554932\n",
      "Train Epoch 467.1 var loss 71754.421875 reconstruction mse 71751.9453125 imputation mse 1.0058026313781738\n",
      "Train Epoch 467.2 var loss 71723.796875 reconstruction mse 71721.2578125 imputation mse 1.005372405052185\n",
      "Train Epoch 467.3 var loss 71690.390625 reconstruction mse 71687.90625 imputation mse 1.004904866218567\n",
      "Train Epoch 467.4 var loss 71732.453125 reconstruction mse 71730.046875 imputation mse 1.0054956674575806\n",
      "Train Epoch 467.5 var loss 71721.765625 reconstruction mse 71719.484375 imputation mse 1.0053476095199585\n",
      "Train Epoch 467.6 var loss 71756.9375 reconstruction mse 71754.734375 imputation mse 1.0058417320251465\n",
      "Train Epoch 467.7 var loss 71750.0078125 reconstruction mse 71747.8515625 imputation mse 1.0057451725006104\n",
      "Train Epoch 467.8 var loss 71697.96875 reconstruction mse 71695.796875 imputation mse 1.00501549243927\n",
      "Train Epoch 467.9 var loss 71707.6171875 reconstruction mse 71705.4140625 imputation mse 1.005150318145752\n",
      "Train Epoch 468.0 var loss 71296.765625 reconstruction mse 71294.3671875 imputation mse 1.0005946159362793\n",
      "Train Epoch 468.1 var loss 71333.1953125 reconstruction mse 71330.765625 imputation mse 1.0011054277420044\n",
      "Train Epoch 468.2 var loss 71300.640625 reconstruction mse 71298.15625 imputation mse 1.000647783279419\n",
      "Train Epoch 468.3 var loss 71278.71875 reconstruction mse 71276.265625 imputation mse 1.0003405809402466\n",
      "Train Epoch 468.4 var loss 71286.3203125 reconstruction mse 71283.9609375 imputation mse 1.0004485845565796\n",
      "Train Epoch 468.5 var loss 71333.234375 reconstruction mse 71330.9765625 imputation mse 1.0011084079742432\n",
      "Train Epoch 468.6 var loss 71296.28125 reconstruction mse 71294.1015625 imputation mse 1.0005909204483032\n",
      "Train Epoch 468.7 var loss 71312.5078125 reconstruction mse 71310.359375 imputation mse 1.0008190870285034\n",
      "Train Epoch 468.8 var loss 71305.9921875 reconstruction mse 71303.8203125 imputation mse 1.0007272958755493\n",
      "Train Epoch 468.9 var loss 71324.1171875 reconstruction mse 71321.9140625 imputation mse 1.0009812116622925\n",
      "Train Epoch 469.0 var loss 71360.4296875 reconstruction mse 71358.0546875 imputation mse 1.0013619661331177\n",
      "Train Epoch 469.1 var loss 71381.5859375 reconstruction mse 71379.1796875 imputation mse 1.0016584396362305\n",
      "Train Epoch 469.2 var loss 71394.1953125 reconstruction mse 71391.703125 imputation mse 1.0018341541290283\n",
      "Train Epoch 469.3 var loss 71408.09375 reconstruction mse 71405.640625 imputation mse 1.0020297765731812\n",
      "Train Epoch 469.4 var loss 71393.7734375 reconstruction mse 71391.421875 imputation mse 1.0018302202224731\n",
      "Train Epoch 469.5 var loss 71385.78125 reconstruction mse 71383.5234375 imputation mse 1.001719355583191\n",
      "Train Epoch 469.6 var loss 71367.5546875 reconstruction mse 71365.3671875 imputation mse 1.001464605331421\n",
      "Train Epoch 469.7 var loss 71356.078125 reconstruction mse 71353.8984375 imputation mse 1.0013036727905273\n",
      "Train Epoch 469.8 var loss 71358.4921875 reconstruction mse 71356.296875 imputation mse 1.0013372898101807\n",
      "Train Epoch 469.9 var loss 71387.4296875 reconstruction mse 71385.2265625 imputation mse 1.0017433166503906\n",
      "Train Epoch 470.0 var loss 72431.796875 reconstruction mse 72429.421875 imputation mse 1.0083309412002563\n",
      "Train Epoch 470.1 var loss 72462.546875 reconstruction mse 72460.1796875 imputation mse 1.0087591409683228\n",
      "Train Epoch 470.2 var loss 72434.84375 reconstruction mse 72432.4296875 imputation mse 1.0083727836608887\n",
      "Train Epoch 470.3 var loss 72459.1171875 reconstruction mse 72456.7421875 imputation mse 1.008711338043213\n",
      "Train Epoch 470.4 var loss 72466.5546875 reconstruction mse 72464.2890625 imputation mse 1.0088163614273071\n",
      "Train Epoch 470.5 var loss 72438.8203125 reconstruction mse 72436.640625 imputation mse 1.0084314346313477\n",
      "Train Epoch 470.6 var loss 72428.4609375 reconstruction mse 72426.359375 imputation mse 1.0082883834838867\n",
      "Train Epoch 470.7 var loss 72425.7734375 reconstruction mse 72423.6875 imputation mse 1.0082511901855469\n",
      "Train Epoch 470.8 var loss 72456.3203125 reconstruction mse 72454.21875 imputation mse 1.0086761713027954\n",
      "Train Epoch 470.9 var loss 72433.171875 reconstruction mse 72431.0390625 imputation mse 1.0083534717559814\n",
      "====> Test imputation mse: 1.00165701\n",
      "====> Test imputation mse: 1.00356174\n",
      "====> Test imputation mse: 1.01731098\n",
      "Train Epoch 471.0 var loss 71961.328125 reconstruction mse 71958.96875 imputation mse 1.0030522346496582\n",
      "Train Epoch 471.1 var loss 71971.0 reconstruction mse 71968.65625 imputation mse 1.0031872987747192\n",
      "Train Epoch 471.2 var loss 71944.40625 reconstruction mse 71941.953125 imputation mse 1.0028151273727417\n",
      "Train Epoch 471.3 var loss 71924.703125 reconstruction mse 71922.265625 imputation mse 1.0025405883789062\n",
      "Train Epoch 471.4 var loss 71941.2421875 reconstruction mse 71938.8984375 imputation mse 1.0027724504470825\n",
      "Train Epoch 471.5 var loss 71971.84375 reconstruction mse 71969.6015625 imputation mse 1.0032004117965698\n",
      "Train Epoch 471.6 var loss 71946.7890625 reconstruction mse 71944.625 imputation mse 1.0028523206710815\n",
      "Train Epoch 471.7 var loss 71923.28125 reconstruction mse 71921.171875 imputation mse 1.0025254487991333\n",
      "Train Epoch 471.8 var loss 71922.6875 reconstruction mse 71920.6015625 imputation mse 1.0025174617767334\n",
      "Train Epoch 471.9 var loss 71958.578125 reconstruction mse 71956.484375 imputation mse 1.0030176639556885\n",
      "Train Epoch 472.0 var loss 71453.1171875 reconstruction mse 71450.7890625 imputation mse 1.004255771636963\n",
      "Train Epoch 472.1 var loss 71465.7109375 reconstruction mse 71463.40625 imputation mse 1.0044331550598145\n",
      "Train Epoch 472.2 var loss 71466.2734375 reconstruction mse 71463.8984375 imputation mse 1.0044400691986084\n",
      "Train Epoch 472.3 var loss 71455.71875 reconstruction mse 71453.359375 imputation mse 1.0042918920516968\n",
      "Train Epoch 472.4 var loss 71471.2734375 reconstruction mse 71469.0 imputation mse 1.0045117139816284\n",
      "Train Epoch 472.5 var loss 71417.3984375 reconstruction mse 71415.2265625 imputation mse 1.0037559270858765\n",
      "Train Epoch 472.6 var loss 71467.1796875 reconstruction mse 71465.1171875 imputation mse 1.0044571161270142\n",
      "Train Epoch 472.7 var loss 71437.546875 reconstruction mse 71435.515625 imputation mse 1.004041075706482\n",
      "Train Epoch 472.8 var loss 71465.1953125 reconstruction mse 71463.15625 imputation mse 1.004429578781128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 472.9 var loss 71445.578125 reconstruction mse 71443.4921875 imputation mse 1.0041532516479492\n",
      "Train Epoch 473.0 var loss 71139.6484375 reconstruction mse 71137.328125 imputation mse 0.9995409250259399\n",
      "Train Epoch 473.1 var loss 71150.6484375 reconstruction mse 71148.3515625 imputation mse 0.9996958374977112\n",
      "Train Epoch 473.2 var loss 71182.7421875 reconstruction mse 71180.390625 imputation mse 1.0001460313796997\n",
      "Train Epoch 473.3 var loss 71171.0234375 reconstruction mse 71168.6953125 imputation mse 0.9999816417694092\n",
      "Train Epoch 473.4 var loss 71151.9765625 reconstruction mse 71149.7421875 imputation mse 0.9997153878211975\n",
      "Train Epoch 473.5 var loss 71157.9375 reconstruction mse 71155.8125 imputation mse 0.9998006820678711\n",
      "Train Epoch 473.6 var loss 71130.796875 reconstruction mse 71128.7421875 imputation mse 0.9994202852249146\n",
      "Train Epoch 473.7 var loss 71148.671875 reconstruction mse 71146.6484375 imputation mse 0.9996718764305115\n",
      "Train Epoch 473.8 var loss 71138.9453125 reconstruction mse 71136.9140625 imputation mse 0.9995351433753967\n",
      "Train Epoch 473.9 var loss 71150.2109375 reconstruction mse 71148.1640625 imputation mse 0.9996932148933411\n",
      "Train Epoch 474.0 var loss 71296.953125 reconstruction mse 71294.65625 imputation mse 0.9991823434829712\n",
      "Train Epoch 474.1 var loss 71311.7265625 reconstruction mse 71309.46875 imputation mse 0.9993899464607239\n",
      "Train Epoch 474.2 var loss 71317.984375 reconstruction mse 71315.671875 imputation mse 0.9994768500328064\n",
      "Train Epoch 474.3 var loss 71281.5625 reconstruction mse 71279.2890625 imputation mse 0.9989669322967529\n",
      "Train Epoch 474.4 var loss 71292.5703125 reconstruction mse 71290.375 imputation mse 0.9991223216056824\n",
      "Train Epoch 474.5 var loss 71293.1875 reconstruction mse 71291.1015625 imputation mse 0.999132513999939\n",
      "Train Epoch 474.6 var loss 71250.3828125 reconstruction mse 71248.34375 imputation mse 0.9985332489013672\n",
      "Train Epoch 474.7 var loss 71303.3984375 reconstruction mse 71301.3671875 imputation mse 0.9992763996124268\n",
      "Train Epoch 474.8 var loss 71286.78125 reconstruction mse 71284.71875 imputation mse 0.9990430474281311\n",
      "Train Epoch 474.9 var loss 71309.4140625 reconstruction mse 71307.296875 imputation mse 0.9993594884872437\n",
      "Train Epoch 475.0 var loss 71997.265625 reconstruction mse 71994.9765625 imputation mse 1.007387638092041\n",
      "Train Epoch 475.1 var loss 71967.546875 reconstruction mse 71965.21875 imputation mse 1.0069713592529297\n",
      "Train Epoch 475.2 var loss 71984.4296875 reconstruction mse 71982.03125 imputation mse 1.0072065591812134\n",
      "Train Epoch 475.3 var loss 71963.5625 reconstruction mse 71961.203125 imputation mse 1.0069150924682617\n",
      "Train Epoch 475.4 var loss 71952.2734375 reconstruction mse 71950.015625 imputation mse 1.0067585706710815\n",
      "Train Epoch 475.5 var loss 71982.921875 reconstruction mse 71980.7890625 imputation mse 1.007189154624939\n",
      "Train Epoch 475.6 var loss 71965.375 reconstruction mse 71963.3125 imputation mse 1.0069446563720703\n",
      "Train Epoch 475.7 var loss 71956.0 reconstruction mse 71953.9609375 imputation mse 1.0068137645721436\n",
      "Train Epoch 475.8 var loss 71960.5 reconstruction mse 71958.4375 imputation mse 1.0068764686584473\n",
      "Train Epoch 475.9 var loss 71979.0625 reconstruction mse 71976.9375 imputation mse 1.007135272026062\n",
      "Train Epoch 476.0 var loss 72150.2421875 reconstruction mse 72147.8828125 imputation mse 1.007075309753418\n",
      "Train Epoch 476.1 var loss 72112.8828125 reconstruction mse 72110.5703125 imputation mse 1.0065544843673706\n",
      "Train Epoch 476.2 var loss 72128.2734375 reconstruction mse 72125.9140625 imputation mse 1.0067687034606934\n",
      "Train Epoch 476.3 var loss 72113.96875 reconstruction mse 72111.6484375 imputation mse 1.006569504737854\n",
      "Train Epoch 476.4 var loss 72131.5078125 reconstruction mse 72129.28125 imputation mse 1.0068156719207764\n",
      "Train Epoch 476.5 var loss 72118.8125 reconstruction mse 72116.6875 imputation mse 1.006639838218689\n",
      "Train Epoch 476.6 var loss 72103.0 reconstruction mse 72100.9453125 imputation mse 1.0064201354980469\n",
      "Train Epoch 476.7 var loss 72157.0546875 reconstruction mse 72155.0078125 imputation mse 1.0071747303009033\n",
      "Train Epoch 476.8 var loss 72129.625 reconstruction mse 72127.5625 imputation mse 1.0067917108535767\n",
      "Train Epoch 476.9 var loss 72147.1015625 reconstruction mse 72144.9921875 imputation mse 1.0070350170135498\n",
      "Train Epoch 477.0 var loss 71653.875 reconstruction mse 71651.5390625 imputation mse 1.0048599243164062\n",
      "Train Epoch 477.1 var loss 71659.6171875 reconstruction mse 71657.296875 imputation mse 1.0049407482147217\n",
      "Train Epoch 477.2 var loss 71662.3984375 reconstruction mse 71660.0078125 imputation mse 1.0049787759780884\n",
      "Train Epoch 477.3 var loss 71651.09375 reconstruction mse 71648.7265625 imputation mse 1.004820466041565\n",
      "Train Epoch 477.4 var loss 71688.4296875 reconstruction mse 71686.1640625 imputation mse 1.0053455829620361\n",
      "Train Epoch 477.5 var loss 71653.3125 reconstruction mse 71651.1875 imputation mse 1.0048550367355347\n",
      "Train Epoch 477.6 var loss 71668.6015625 reconstruction mse 71666.5546875 imputation mse 1.0050705671310425\n",
      "Train Epoch 477.7 var loss 71629.5546875 reconstruction mse 71627.546875 imputation mse 1.004523515701294\n",
      "Train Epoch 477.8 var loss 71654.4375 reconstruction mse 71652.40625 imputation mse 1.0048720836639404\n",
      "Train Epoch 477.9 var loss 71671.7734375 reconstruction mse 71669.703125 imputation mse 1.0051146745681763\n",
      "Train Epoch 478.0 var loss 71153.703125 reconstruction mse 71151.390625 imputation mse 0.9943594336509705\n",
      "Train Epoch 478.1 var loss 71123.6796875 reconstruction mse 71121.3984375 imputation mse 0.9939402937889099\n",
      "Train Epoch 478.2 var loss 71180.8828125 reconstruction mse 71178.5 imputation mse 0.9947383403778076\n",
      "Train Epoch 478.3 var loss 71152.2734375 reconstruction mse 71149.890625 imputation mse 0.9943385124206543\n",
      "Train Epoch 478.4 var loss 71121.3203125 reconstruction mse 71119.0234375 imputation mse 0.99390709400177\n",
      "Train Epoch 478.5 var loss 71122.5625 reconstruction mse 71120.3984375 imputation mse 0.9939263463020325\n",
      "Train Epoch 478.6 var loss 71128.96875 reconstruction mse 71126.890625 imputation mse 0.9940170645713806\n",
      "Train Epoch 478.7 var loss 71136.328125 reconstruction mse 71134.2890625 imputation mse 0.9941204786300659\n",
      "Train Epoch 478.8 var loss 71128.328125 reconstruction mse 71126.28125 imputation mse 0.9940085411071777\n",
      "Train Epoch 478.9 var loss 71143.1875 reconstruction mse 71141.1171875 imputation mse 0.9942159056663513\n",
      "Train Epoch 479.0 var loss 71839.875 reconstruction mse 71837.5546875 imputation mse 1.003668189048767\n",
      "Train Epoch 479.1 var loss 71837.21875 reconstruction mse 71834.9453125 imputation mse 1.003631830215454\n",
      "Train Epoch 479.2 var loss 71851.3515625 reconstruction mse 71849.0234375 imputation mse 1.003828525543213\n",
      "Train Epoch 479.3 var loss 71816.6875 reconstruction mse 71814.40625 imputation mse 1.0033447742462158\n",
      "Train Epoch 479.4 var loss 71849.25 reconstruction mse 71847.0859375 imputation mse 1.0038014650344849\n",
      "Train Epoch 479.5 var loss 71818.1796875 reconstruction mse 71816.09375 imputation mse 1.0033683776855469\n",
      "Train Epoch 479.6 var loss 71807.4765625 reconstruction mse 71805.4375 imputation mse 1.003219485282898\n",
      "Train Epoch 479.7 var loss 71844.890625 reconstruction mse 71842.859375 imputation mse 1.0037423372268677\n",
      "Train Epoch 479.8 var loss 71855.984375 reconstruction mse 71853.8828125 imputation mse 1.0038963556289673\n",
      "Train Epoch 479.9 var loss 71849.9375 reconstruction mse 71847.7734375 imputation mse 1.003811001777649\n",
      "Train Epoch 480.0 var loss 71921.1484375 reconstruction mse 71918.7734375 imputation mse 1.00316321849823\n",
      "Train Epoch 480.1 var loss 71907.71875 reconstruction mse 71905.3203125 imputation mse 1.0029754638671875\n",
      "Train Epoch 480.2 var loss 71937.75 reconstruction mse 71935.2890625 imputation mse 1.003393530845642\n",
      "Train Epoch 480.3 var loss 71951.1796875 reconstruction mse 71948.78125 imputation mse 1.0035817623138428\n",
      "Train Epoch 480.4 var loss 71922.90625 reconstruction mse 71920.640625 imputation mse 1.003189206123352\n",
      "Train Epoch 480.5 var loss 71886.8828125 reconstruction mse 71884.7421875 imputation mse 1.0026885271072388\n",
      "Train Epoch 480.6 var loss 71935.2109375 reconstruction mse 71933.1875 imputation mse 1.0033642053604126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 480.7 var loss 71948.875 reconstruction mse 71946.8828125 imputation mse 1.0035552978515625\n",
      "Train Epoch 480.8 var loss 71930.1328125 reconstruction mse 71928.1015625 imputation mse 1.0032932758331299\n",
      "Train Epoch 480.9 var loss 71900.2890625 reconstruction mse 71898.203125 imputation mse 1.0028762817382812\n",
      "====> Test imputation mse: 0.99891359\n",
      "====> Test imputation mse: 0.97806549\n",
      "====> Test imputation mse: 1.00876081\n",
      "Train Epoch 481.0 var loss 71116.9140625 reconstruction mse 71114.578125 imputation mse 0.9958909153938293\n",
      "Train Epoch 481.1 var loss 71103.0859375 reconstruction mse 71100.78125 imputation mse 0.9956976771354675\n",
      "Train Epoch 481.2 var loss 71121.8671875 reconstruction mse 71119.5 imputation mse 0.9959598183631897\n",
      "Train Epoch 481.3 var loss 71091.4765625 reconstruction mse 71089.1484375 imputation mse 0.9955347776412964\n",
      "Train Epoch 481.4 var loss 71053.609375 reconstruction mse 71051.40625 imputation mse 0.995006263256073\n",
      "Train Epoch 481.5 var loss 71097.4140625 reconstruction mse 71095.3203125 imputation mse 0.9956212043762207\n",
      "Train Epoch 481.6 var loss 71121.0546875 reconstruction mse 71119.0078125 imputation mse 0.9959529638290405\n",
      "Train Epoch 481.7 var loss 71161.1953125 reconstruction mse 71159.1796875 imputation mse 0.9965155124664307\n",
      "Train Epoch 481.8 var loss 71089.0390625 reconstruction mse 71086.984375 imputation mse 0.9955044984817505\n",
      "Train Epoch 481.9 var loss 71087.9375 reconstruction mse 71085.8515625 imputation mse 0.9954886436462402\n",
      "Train Epoch 482.0 var loss 72753.328125 reconstruction mse 72751.0 imputation mse 1.0175961256027222\n",
      "Train Epoch 482.1 var loss 72802.0234375 reconstruction mse 72799.8125 imputation mse 1.0182788372039795\n",
      "Train Epoch 482.2 var loss 72751.515625 reconstruction mse 72749.25 imputation mse 1.0175716876983643\n",
      "Train Epoch 482.3 var loss 72749.2734375 reconstruction mse 72747.0234375 imputation mse 1.017540454864502\n",
      "Train Epoch 482.4 var loss 72781.3984375 reconstruction mse 72779.234375 imputation mse 1.017991065979004\n",
      "Train Epoch 482.5 var loss 72767.6328125 reconstruction mse 72765.53125 imputation mse 1.0177993774414062\n",
      "Train Epoch 482.6 var loss 72738.015625 reconstruction mse 72735.953125 imputation mse 1.017385721206665\n",
      "Train Epoch 482.7 var loss 72733.609375 reconstruction mse 72731.546875 imputation mse 1.0173239707946777\n",
      "Train Epoch 482.8 var loss 72721.4453125 reconstruction mse 72719.34375 imputation mse 1.0171533823013306\n",
      "Train Epoch 482.9 var loss 72757.484375 reconstruction mse 72755.359375 imputation mse 1.0176571607589722\n",
      "Train Epoch 483.0 var loss 71669.578125 reconstruction mse 71667.2421875 imputation mse 1.0003243684768677\n",
      "Train Epoch 483.1 var loss 71636.2578125 reconstruction mse 71633.9921875 imputation mse 0.9998602867126465\n",
      "Train Epoch 483.2 var loss 71631.2578125 reconstruction mse 71628.9296875 imputation mse 0.9997896552085876\n",
      "Train Epoch 483.3 var loss 71630.4140625 reconstruction mse 71628.0859375 imputation mse 0.9997778534889221\n",
      "Train Epoch 483.4 var loss 71650.1875 reconstruction mse 71647.9375 imputation mse 1.000054955482483\n",
      "Train Epoch 483.5 var loss 71593.90625 reconstruction mse 71591.734375 imputation mse 0.999270498752594\n",
      "Train Epoch 483.6 var loss 71682.0703125 reconstruction mse 71679.9609375 imputation mse 1.0005019903182983\n",
      "Train Epoch 483.7 var loss 71632.0234375 reconstruction mse 71629.9453125 imputation mse 0.9998038411140442\n",
      "Train Epoch 483.8 var loss 71667.1484375 reconstruction mse 71665.046875 imputation mse 1.0002937316894531\n",
      "Train Epoch 483.9 var loss 71664.2890625 reconstruction mse 71662.1640625 imputation mse 1.0002535581588745\n",
      "Train Epoch 484.0 var loss 71243.796875 reconstruction mse 71241.453125 imputation mse 0.9930921792984009\n",
      "Train Epoch 484.1 var loss 71201.5234375 reconstruction mse 71199.1953125 imputation mse 0.9925031065940857\n",
      "Train Epoch 484.2 var loss 71230.0625 reconstruction mse 71227.6953125 imputation mse 0.9929003715515137\n",
      "Train Epoch 484.3 var loss 71214.9453125 reconstruction mse 71212.671875 imputation mse 0.9926909804344177\n",
      "Train Epoch 484.4 var loss 71229.8828125 reconstruction mse 71227.7109375 imputation mse 0.9929006099700928\n",
      "Train Epoch 484.5 var loss 71231.765625 reconstruction mse 71229.6953125 imputation mse 0.9929282665252686\n",
      "Train Epoch 484.6 var loss 71225.1484375 reconstruction mse 71223.109375 imputation mse 0.9928364753723145\n",
      "Train Epoch 484.7 var loss 71234.6953125 reconstruction mse 71232.640625 imputation mse 0.9929693341255188\n",
      "Train Epoch 484.8 var loss 71191.515625 reconstruction mse 71189.40625 imputation mse 0.9923666715621948\n",
      "Train Epoch 484.9 var loss 71248.6015625 reconstruction mse 71246.453125 imputation mse 0.9931618571281433\n",
      "Train Epoch 485.0 var loss 70952.0 reconstruction mse 70949.6796875 imputation mse 0.9930810332298279\n",
      "Train Epoch 485.1 var loss 70983.3046875 reconstruction mse 70980.96875 imputation mse 0.9935189485549927\n",
      "Train Epoch 485.2 var loss 70972.1171875 reconstruction mse 70969.7109375 imputation mse 0.9933614134788513\n",
      "Train Epoch 485.3 var loss 70996.8046875 reconstruction mse 70994.46875 imputation mse 0.9937078952789307\n",
      "Train Epoch 485.4 var loss 70990.46875 reconstruction mse 70988.2421875 imputation mse 0.993620753288269\n",
      "Train Epoch 485.5 var loss 70961.9296875 reconstruction mse 70959.8046875 imputation mse 0.993222713470459\n",
      "Train Epoch 485.6 var loss 70962.296875 reconstruction mse 70960.2578125 imputation mse 0.99322909116745\n",
      "Train Epoch 485.7 var loss 70958.9453125 reconstruction mse 70956.90625 imputation mse 0.9931821823120117\n",
      "Train Epoch 485.8 var loss 70956.71875 reconstruction mse 70954.65625 imputation mse 0.9931506514549255\n",
      "Train Epoch 485.9 var loss 70941.0859375 reconstruction mse 70938.9609375 imputation mse 0.9929310083389282\n",
      "Train Epoch 486.0 var loss 71236.203125 reconstruction mse 71233.8828125 imputation mse 0.9967520833015442\n",
      "Train Epoch 486.1 var loss 71220.578125 reconstruction mse 71218.265625 imputation mse 0.9965335130691528\n",
      "Train Epoch 486.2 var loss 71276.25 reconstruction mse 71273.90625 imputation mse 0.997312068939209\n",
      "Train Epoch 486.3 var loss 71228.515625 reconstruction mse 71226.2109375 imputation mse 0.9966447353363037\n",
      "Train Epoch 486.4 var loss 71242.15625 reconstruction mse 71239.953125 imputation mse 0.9968370199203491\n",
      "Train Epoch 486.5 var loss 71256.546875 reconstruction mse 71254.40625 imputation mse 0.997039258480072\n",
      "Train Epoch 486.6 var loss 71228.4375 reconstruction mse 71226.3359375 imputation mse 0.9966464638710022\n",
      "Train Epoch 486.7 var loss 71245.1328125 reconstruction mse 71243.046875 imputation mse 0.996880292892456\n",
      "Train Epoch 486.8 var loss 71227.5703125 reconstruction mse 71225.4765625 imputation mse 0.9966344237327576\n",
      "Train Epoch 486.9 var loss 71266.09375 reconstruction mse 71264.0 imputation mse 0.9971734881401062\n",
      "Train Epoch 487.0 var loss 71189.1328125 reconstruction mse 71186.8046875 imputation mse 1.0057190656661987\n",
      "Train Epoch 487.1 var loss 71163.5078125 reconstruction mse 71161.265625 imputation mse 1.0053582191467285\n",
      "Train Epoch 487.2 var loss 71197.1640625 reconstruction mse 71194.8515625 imputation mse 1.0058326721191406\n",
      "Train Epoch 487.3 var loss 71155.171875 reconstruction mse 71152.859375 imputation mse 1.005239486694336\n",
      "Train Epoch 487.4 var loss 71195.671875 reconstruction mse 71193.4375 imputation mse 1.0058127641677856\n",
      "Train Epoch 487.5 var loss 71162.6015625 reconstruction mse 71160.4375 imputation mse 1.0053465366363525\n",
      "Train Epoch 487.6 var loss 71175.59375 reconstruction mse 71173.5 imputation mse 1.0055310726165771\n",
      "Train Epoch 487.7 var loss 71207.2734375 reconstruction mse 71205.21875 imputation mse 1.0059791803359985\n",
      "Train Epoch 487.8 var loss 71208.4140625 reconstruction mse 71206.3359375 imputation mse 1.0059949159622192\n",
      "Train Epoch 487.9 var loss 71185.9453125 reconstruction mse 71183.84375 imputation mse 1.0056772232055664\n",
      "Train Epoch 488.0 var loss 71525.9140625 reconstruction mse 71523.5703125 imputation mse 0.999518871307373\n",
      "Train Epoch 488.1 var loss 71534.1484375 reconstruction mse 71531.859375 imputation mse 0.9996346831321716\n",
      "Train Epoch 488.2 var loss 71497.90625 reconstruction mse 71495.5625 imputation mse 0.9991274476051331\n",
      "Train Epoch 488.3 var loss 71491.5390625 reconstruction mse 71489.2265625 imputation mse 0.9990389347076416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 488.4 var loss 71513.5703125 reconstruction mse 71511.375 imputation mse 0.9993484020233154\n",
      "Train Epoch 488.5 var loss 71514.53125 reconstruction mse 71512.453125 imputation mse 0.9993634819984436\n",
      "Train Epoch 488.6 var loss 71514.8046875 reconstruction mse 71512.8125 imputation mse 0.9993685483932495\n",
      "Train Epoch 488.7 var loss 71504.4453125 reconstruction mse 71502.46875 imputation mse 0.9992239475250244\n",
      "Train Epoch 488.8 var loss 71509.46875 reconstruction mse 71507.46875 imputation mse 0.999293863773346\n",
      "Train Epoch 488.9 var loss 71468.3359375 reconstruction mse 71466.265625 imputation mse 0.9987180233001709\n",
      "Train Epoch 489.0 var loss 71227.3671875 reconstruction mse 71225.046875 imputation mse 0.9997339844703674\n",
      "Train Epoch 489.1 var loss 71201.5859375 reconstruction mse 71199.3203125 imputation mse 0.9993728399276733\n",
      "Train Epoch 489.2 var loss 71238.6640625 reconstruction mse 71236.34375 imputation mse 0.99989253282547\n",
      "Train Epoch 489.3 var loss 71207.734375 reconstruction mse 71205.4375 imputation mse 0.9994587302207947\n",
      "Train Epoch 489.4 var loss 71220.1796875 reconstruction mse 71217.9765625 imputation mse 0.9996347427368164\n",
      "Train Epoch 489.5 var loss 71250.2421875 reconstruction mse 71248.125 imputation mse 1.0000579357147217\n",
      "Train Epoch 489.6 var loss 71201.53125 reconstruction mse 71199.4921875 imputation mse 0.9993752837181091\n",
      "Train Epoch 489.7 var loss 71215.7109375 reconstruction mse 71213.6875 imputation mse 0.9995745420455933\n",
      "Train Epoch 489.8 var loss 71191.7421875 reconstruction mse 71189.703125 imputation mse 0.9992378950119019\n",
      "Train Epoch 489.9 var loss 71183.7890625 reconstruction mse 71181.71875 imputation mse 0.9991257786750793\n",
      "Train Epoch 490.0 var loss 71493.453125 reconstruction mse 71491.15625 imputation mse 0.9993731379508972\n",
      "Train Epoch 490.1 var loss 71484.578125 reconstruction mse 71482.2734375 imputation mse 0.9992489814758301\n",
      "Train Epoch 490.2 var loss 71500.6171875 reconstruction mse 71498.25 imputation mse 0.9994723200798035\n",
      "Train Epoch 490.3 var loss 71512.4375 reconstruction mse 71510.125 imputation mse 0.9996383190155029\n",
      "Train Epoch 490.4 var loss 71468.671875 reconstruction mse 71466.4921875 imputation mse 0.9990283250808716\n",
      "Train Epoch 490.5 var loss 71447.0078125 reconstruction mse 71444.953125 imputation mse 0.9987272620201111\n",
      "Train Epoch 490.6 var loss 71475.1484375 reconstruction mse 71473.1640625 imputation mse 0.9991216063499451\n",
      "Train Epoch 490.7 var loss 71473.1171875 reconstruction mse 71471.171875 imputation mse 0.999093770980835\n",
      "Train Epoch 490.8 var loss 71483.90625 reconstruction mse 71481.9375 imputation mse 0.9992442727088928\n",
      "Train Epoch 490.9 var loss 71496.8828125 reconstruction mse 71494.8671875 imputation mse 0.9994249939918518\n",
      "====> Test imputation mse: 0.99625778\n",
      "====> Test imputation mse: 0.99508512\n",
      "====> Test imputation mse: 1.01487970\n",
      "Train Epoch 491.0 var loss 72585.8046875 reconstruction mse 72583.5234375 imputation mse 1.0091276168823242\n",
      "Train Epoch 491.1 var loss 72607.6796875 reconstruction mse 72605.4453125 imputation mse 1.0094324350357056\n",
      "Train Epoch 491.2 var loss 72562.5 reconstruction mse 72560.1875 imputation mse 1.0088032484054565\n",
      "Train Epoch 491.3 var loss 72591.4140625 reconstruction mse 72589.1171875 imputation mse 1.0092054605484009\n",
      "Train Epoch 491.4 var loss 72602.21875 reconstruction mse 72599.9765625 imputation mse 1.0093563795089722\n",
      "Train Epoch 491.5 var loss 72600.359375 reconstruction mse 72598.203125 imputation mse 1.0093317031860352\n",
      "Train Epoch 491.6 var loss 72584.28125 reconstruction mse 72582.171875 imputation mse 1.0091089010238647\n",
      "Train Epoch 491.7 var loss 72575.078125 reconstruction mse 72573.0 imputation mse 1.0089813470840454\n",
      "Train Epoch 491.8 var loss 72616.0 reconstruction mse 72613.90625 imputation mse 1.0095500946044922\n",
      "Train Epoch 491.9 var loss 72613.0703125 reconstruction mse 72610.9609375 imputation mse 1.0095090866088867\n",
      "Train Epoch 492.0 var loss 72531.0234375 reconstruction mse 72528.7109375 imputation mse 1.0063927173614502\n",
      "Train Epoch 492.1 var loss 72514.3125 reconstruction mse 72512.0546875 imputation mse 1.0061615705490112\n",
      "Train Epoch 492.2 var loss 72491.046875 reconstruction mse 72488.734375 imputation mse 1.0058380365371704\n",
      "Train Epoch 492.3 var loss 72521.75 reconstruction mse 72519.4765625 imputation mse 1.006264567375183\n",
      "Train Epoch 492.4 var loss 72510.125 reconstruction mse 72507.9296875 imputation mse 1.0061043500900269\n",
      "Train Epoch 492.5 var loss 72509.828125 reconstruction mse 72507.7109375 imputation mse 1.006101369857788\n",
      "Train Epoch 492.6 var loss 72516.7421875 reconstruction mse 72514.6640625 imputation mse 1.0061978101730347\n",
      "Train Epoch 492.7 var loss 72522.65625 reconstruction mse 72520.59375 imputation mse 1.0062800645828247\n",
      "Train Epoch 492.8 var loss 72544.8828125 reconstruction mse 72542.8046875 imputation mse 1.006588339805603\n",
      "Train Epoch 492.9 var loss 72526.296875 reconstruction mse 72524.1953125 imputation mse 1.0063300132751465\n",
      "Train Epoch 493.0 var loss 71542.765625 reconstruction mse 71540.453125 imputation mse 0.9999504089355469\n",
      "Train Epoch 493.1 var loss 71564.2578125 reconstruction mse 71561.96875 imputation mse 1.0002511739730835\n",
      "Train Epoch 493.2 var loss 71563.140625 reconstruction mse 71560.78125 imputation mse 1.000234603881836\n",
      "Train Epoch 493.3 var loss 71582.1953125 reconstruction mse 71579.859375 imputation mse 1.000501275062561\n",
      "Train Epoch 493.4 var loss 71553.6953125 reconstruction mse 71551.4453125 imputation mse 1.0001040697097778\n",
      "Train Epoch 493.5 var loss 71562.3828125 reconstruction mse 71560.2265625 imputation mse 1.0002268552780151\n",
      "Train Epoch 493.6 var loss 71551.3203125 reconstruction mse 71549.2265625 imputation mse 1.0000730752944946\n",
      "Train Epoch 493.7 var loss 71559.8515625 reconstruction mse 71557.7890625 imputation mse 1.0001927614212036\n",
      "Train Epoch 493.8 var loss 71575.6171875 reconstruction mse 71573.546875 imputation mse 1.000412940979004\n",
      "Train Epoch 493.9 var loss 71542.1953125 reconstruction mse 71540.125 imputation mse 0.9999458193778992\n",
      "Train Epoch 494.0 var loss 71013.5234375 reconstruction mse 71011.2421875 imputation mse 0.9912787079811096\n",
      "Train Epoch 494.1 var loss 70996.0703125 reconstruction mse 70993.875 imputation mse 0.9910362958908081\n",
      "Train Epoch 494.2 var loss 71020.9453125 reconstruction mse 71018.6953125 imputation mse 0.9913827776908875\n",
      "Train Epoch 494.3 var loss 71022.0703125 reconstruction mse 71019.828125 imputation mse 0.9913985729217529\n",
      "Train Epoch 494.4 var loss 71003.3359375 reconstruction mse 71001.1484375 imputation mse 0.9911378026008606\n",
      "Train Epoch 494.5 var loss 71015.9609375 reconstruction mse 71013.8359375 imputation mse 0.9913149476051331\n",
      "Train Epoch 494.6 var loss 71007.9921875 reconstruction mse 71005.921875 imputation mse 0.9912044405937195\n",
      "Train Epoch 494.7 var loss 70961.796875 reconstruction mse 70959.7421875 imputation mse 0.9905598163604736\n",
      "Train Epoch 494.8 var loss 70999.9609375 reconstruction mse 70997.921875 imputation mse 0.9910928010940552\n",
      "Train Epoch 494.9 var loss 71026.9140625 reconstruction mse 71024.8515625 imputation mse 0.9914686679840088\n",
      "Train Epoch 495.0 var loss 71666.765625 reconstruction mse 71664.4765625 imputation mse 1.0000485181808472\n",
      "Train Epoch 495.1 var loss 71675.90625 reconstruction mse 71673.640625 imputation mse 1.0001764297485352\n",
      "Train Epoch 495.2 var loss 71659.5546875 reconstruction mse 71657.1953125 imputation mse 0.9999468922615051\n",
      "Train Epoch 495.3 var loss 71692.0 reconstruction mse 71689.6484375 imputation mse 1.0003998279571533\n",
      "Train Epoch 495.4 var loss 71666.8359375 reconstruction mse 71664.5625 imputation mse 1.0000497102737427\n",
      "Train Epoch 495.5 var loss 71698.765625 reconstruction mse 71696.578125 imputation mse 1.000496506690979\n",
      "Train Epoch 495.6 var loss 71680.3984375 reconstruction mse 71678.296875 imputation mse 1.0002413988113403\n",
      "Train Epoch 495.7 var loss 71684.84375 reconstruction mse 71682.8046875 imputation mse 1.0003042221069336\n",
      "Train Epoch 495.8 var loss 71713.203125 reconstruction mse 71711.203125 imputation mse 1.00070059299469\n",
      "Train Epoch 495.9 var loss 71694.453125 reconstruction mse 71692.4375 imputation mse 1.0004386901855469\n",
      "Train Epoch 496.0 var loss 71581.71875 reconstruction mse 71579.4296875 imputation mse 1.0035250186920166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 496.1 var loss 71587.34375 reconstruction mse 71585.1328125 imputation mse 1.0036048889160156\n",
      "Train Epoch 496.2 var loss 71585.8828125 reconstruction mse 71583.59375 imputation mse 1.003583312034607\n",
      "Train Epoch 496.3 var loss 71566.2265625 reconstruction mse 71563.96875 imputation mse 1.0033081769943237\n",
      "Train Epoch 496.4 var loss 71575.6796875 reconstruction mse 71573.5 imputation mse 1.0034418106079102\n",
      "Train Epoch 496.5 var loss 71564.6953125 reconstruction mse 71562.609375 imputation mse 1.0032891035079956\n",
      "Train Epoch 496.6 var loss 71579.171875 reconstruction mse 71577.15625 imputation mse 1.003493070602417\n",
      "Train Epoch 496.7 var loss 71575.4765625 reconstruction mse 71573.4609375 imputation mse 1.003441333770752\n",
      "Train Epoch 496.8 var loss 71587.8125 reconstruction mse 71585.78125 imputation mse 1.003614068031311\n",
      "Train Epoch 496.9 var loss 71594.34375 reconstruction mse 71592.2890625 imputation mse 1.0037052631378174\n",
      "Train Epoch 497.0 var loss 71306.265625 reconstruction mse 71304.0 imputation mse 1.0019391775131226\n",
      "Train Epoch 497.1 var loss 71291.2890625 reconstruction mse 71289.0859375 imputation mse 1.0017296075820923\n",
      "Train Epoch 497.2 var loss 71285.7421875 reconstruction mse 71283.4765625 imputation mse 1.0016506910324097\n",
      "Train Epoch 497.3 var loss 71291.6953125 reconstruction mse 71289.421875 imputation mse 1.0017342567443848\n",
      "Train Epoch 497.4 var loss 71287.265625 reconstruction mse 71285.0546875 imputation mse 1.0016728639602661\n",
      "Train Epoch 497.5 var loss 71311.09375 reconstruction mse 71308.953125 imputation mse 1.0020086765289307\n",
      "Train Epoch 497.6 var loss 71265.421875 reconstruction mse 71263.34375 imputation mse 1.0013678073883057\n",
      "Train Epoch 497.7 var loss 71296.4296875 reconstruction mse 71294.390625 imputation mse 1.0018041133880615\n",
      "Train Epoch 497.8 var loss 71282.859375 reconstruction mse 71280.8203125 imputation mse 1.0016133785247803\n",
      "Train Epoch 497.9 var loss 71265.3203125 reconstruction mse 71263.2421875 imputation mse 1.001366376876831\n",
      "Train Epoch 498.0 var loss 71051.4296875 reconstruction mse 71049.1171875 imputation mse 0.9953226447105408\n",
      "Train Epoch 498.1 var loss 71071.9609375 reconstruction mse 71069.6640625 imputation mse 0.9956104755401611\n",
      "Train Epoch 498.2 var loss 71085.5625 reconstruction mse 71083.1953125 imputation mse 0.9958000779151917\n",
      "Train Epoch 498.3 var loss 71052.1484375 reconstruction mse 71049.8359375 imputation mse 0.9953327178955078\n",
      "Train Epoch 498.4 var loss 71041.90625 reconstruction mse 71039.6875 imputation mse 0.9951905608177185\n",
      "Train Epoch 498.5 var loss 71057.6484375 reconstruction mse 71055.546875 imputation mse 0.9954127073287964\n",
      "Train Epoch 498.6 var loss 71040.453125 reconstruction mse 71038.4296875 imputation mse 0.995172917842865\n",
      "Train Epoch 498.7 var loss 71029.046875 reconstruction mse 71027.0546875 imputation mse 0.9950135946273804\n",
      "Train Epoch 498.8 var loss 71043.5625 reconstruction mse 71041.546875 imputation mse 0.9952166080474854\n",
      "Train Epoch 498.9 var loss 71056.6953125 reconstruction mse 71054.6484375 imputation mse 0.9954001307487488\n",
      "Train Epoch 499.0 var loss 72167.7890625 reconstruction mse 72165.5234375 imputation mse 1.008053183555603\n",
      "Train Epoch 499.1 var loss 72148.828125 reconstruction mse 72146.5703125 imputation mse 1.0077885389328003\n",
      "Train Epoch 499.2 var loss 72161.109375 reconstruction mse 72158.75 imputation mse 1.0079586505889893\n",
      "Train Epoch 499.3 var loss 72151.7734375 reconstruction mse 72149.4453125 imputation mse 1.0078285932540894\n",
      "Train Epoch 499.4 var loss 72137.90625 reconstruction mse 72135.6796875 imputation mse 1.007636308670044\n",
      "Train Epoch 499.5 var loss 72159.625 reconstruction mse 72157.515625 imputation mse 1.0079413652420044\n",
      "Train Epoch 499.6 var loss 72132.2109375 reconstruction mse 72130.1953125 imputation mse 1.0075597763061523\n",
      "Train Epoch 499.7 var loss 72136.3203125 reconstruction mse 72134.3125 imputation mse 1.0076172351837158\n",
      "Train Epoch 499.8 var loss 72161.6484375 reconstruction mse 72159.625 imputation mse 1.0079708099365234\n",
      "Train Epoch 499.9 var loss 72151.359375 reconstruction mse 72149.2890625 imputation mse 1.0078264474868774\n",
      "Train Epoch 500.0 var loss 72288.484375 reconstruction mse 72286.171875 imputation mse 1.0115472078323364\n",
      "Train Epoch 500.1 var loss 72301.1953125 reconstruction mse 72298.9375 imputation mse 1.0117257833480835\n",
      "Train Epoch 500.2 var loss 72294.75 reconstruction mse 72292.4296875 imputation mse 1.0116347074508667\n",
      "Train Epoch 500.3 var loss 72270.1171875 reconstruction mse 72267.828125 imputation mse 1.011290431022644\n",
      "Train Epoch 500.4 var loss 72288.5 reconstruction mse 72286.2890625 imputation mse 1.0115487575531006\n",
      "Train Epoch 500.5 var loss 72284.578125 reconstruction mse 72282.453125 imputation mse 1.0114951133728027\n",
      "Train Epoch 500.6 var loss 72327.3359375 reconstruction mse 72325.265625 imputation mse 1.012094259262085\n",
      "Train Epoch 500.7 var loss 72278.3828125 reconstruction mse 72276.3359375 imputation mse 1.0114095211029053\n",
      "Train Epoch 500.8 var loss 72313.0625 reconstruction mse 72310.9921875 imputation mse 1.0118944644927979\n",
      "Train Epoch 500.9 var loss 72259.8359375 reconstruction mse 72257.765625 imputation mse 1.0111496448516846\n",
      "====> Test imputation mse: 1.00476873\n",
      "====> Test imputation mse: 1.01306212\n",
      "====> Test imputation mse: 0.99969077\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "test()\n",
    "test()\n",
    "for epoch in range(1, 501):\n",
    "    train(epoch)\n",
    "    if epoch%10==0:\n",
    "        test()\n",
    "        test()\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mono",
   "language": "python",
   "name": "mono"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
