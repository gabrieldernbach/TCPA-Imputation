{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tc\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "#from Classes import *\n",
    "#from functions import *\n",
    "#from Train_Env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net found, loading net\n",
      "0\n",
      "torch.Size([730, 189]) tensor(69202)\n",
      "tensor([0.1542, 0.1815, 0.1177, 0.2576, 0.2087, 0.2672, 0.3862, 0.1728, 0.3228,\n",
      "        0.1879, 0.2468, 0.8860, 0.2072, 1.2284, 0.1508, 0.2659, 0.3922, 0.1988,\n",
      "        0.2284, 0.1723, 0.2420, 0.1599, 0.2243, 0.2796, 0.2315, 0.2224, 0.4246,\n",
      "        0.4568, 0.1934, 0.5742, 0.2629, 0.1607, 0.2416, 0.1440, 0.1606, 0.2686,\n",
      "        0.1231, 0.2314, 0.1734, 0.5795, 0.3258, 0.3078, 0.5122, 0.2958, 0.2097,\n",
      "        0.3962, 0.1619, 0.2655, 0.2894, 0.3591, 0.1383, 0.2722, 0.2265, 0.1338,\n",
      "        0.7590, 0.1372, 0.2136, 0.2014, 0.1778, 0.3146, 0.1459, 0.2144, 0.1694,\n",
      "        0.4542, 0.3819, 0.3576, 0.1942, 0.1690, 0.1921, 0.1357, 0.1726, 0.4052,\n",
      "        0.1720, 0.2315, 0.1682, 0.2405, 0.4103, 0.1682, 0.2151, 0.4077, 0.1773,\n",
      "        0.2339, 0.3101, 0.1429, 0.1108, 0.2444, 0.1582, 0.1434, 0.2160, 0.1389,\n",
      "        0.3579, 0.4297, 0.4288, 0.2887, 0.3606, 0.1067, 0.1758, 0.1941, 0.2213,\n",
      "        0.3655, 0.3258, 0.3216, 0.2151, 0.1972, 0.1868, 0.4641, 0.2170, 0.2215,\n",
      "        0.1699, 0.4809, 0.4651, 0.2088, 0.1530, 0.3036, 0.1535, 0.2398, 0.4181,\n",
      "        0.2612, 0.4136, 0.4800, 0.1845, 0.1269, 0.2058, 0.2112, 0.0871, 0.3941,\n",
      "        0.1880, 0.2502, 0.2659, 0.2764, 0.3747, 0.2743, 0.1199, 0.6468, 0.4849,\n",
      "        0.2435, 0.3545, 0.2837, 0.4579, 0.1741, 0.1782, 0.5127, 0.2593, 0.2683,\n",
      "        0.2085, 0.4743, 0.1863, 0.1195, 0.1665, 0.2834, 0.1974, 0.1453, 0.2684,\n",
      "        0.1751, 0.2196, 0.4104, 0.4893, 0.4399, 0.1331, 0.2738, 0.2259, 0.5042,\n",
      "        0.3175, 0.1331, 0.1544, 0.3905, 0.5378, 0.1986, 0.1861, 0.2671, 0.3085,\n",
      "        0.5602, 0.3908, 0.5831, 0.1294, 0.2653, 0.3516, 0.3014, 0.2580, 0.1701,\n",
      "        0.2172, 0.3486, 0.3095, 0.1880, 0.2267, 0.2448, 0.1576, 0.1055, 0.1360,\n",
      "        0.2303, 0.1420, 0.3991, 0.3056, 0.1112, 0.1741, 0.1073, 0.1705, 0.1879,\n",
      "        0.3867, 0.1938, 0.3211, 0.3000, 0.1536, 0.3943, 0.2503, 0.4562, 0.3956,\n",
      "        0.1446, 0.1854, 0.2506, 0.1908, 0.2262, 0.2868, 0.3456, 0.2500, 0.2188,\n",
      "        0.2330, 0.2790, 0.2041, 0.1588, 0.2861, 0.4905, 0.9086, 0.3433, 0.1058,\n",
      "        0.2819, 0.5854, 0.1075, 0.1757, 0.1795, 0.4082, 0.6312, 0.6422, 0.4216,\n",
      "        0.1344, 0.0967, 0.2634, 0.2490, 0.2820, 0.2410, 0.1477, 0.3314, 0.5308,\n",
      "        0.3230, 0.4179, 0.2038, 0.3079, 0.2833, 0.5211, 0.4166, 0.5152, 0.2480,\n",
      "        0.1399, 0.4833, 0.3228, 0.4709, 0.1696, 0.4763, 0.2830, 0.3363, 0.2129,\n",
      "        0.1237, 0.3148, 0.4640, 0.3435, 0.1223, 0.2560, 0.2379, 0.2546, 0.5034,\n",
      "        0.1640, 0.1846, 0.2451, 0.1803, 0.5632, 0.5807, 0.3525, 0.3463, 0.3247,\n",
      "        0.3588, 0.2218, 0.3080, 0.3293, 0.1602, 0.2522, 0.2053, 0.1777, 0.1883,\n",
      "        0.2558, 0.2954, 0.4446, 0.1427, 0.1118, 0.2267, 0.2580, 0.6778, 0.1838,\n",
      "        0.2913, 0.3769, 0.2945, 0.1477, 0.1506, 0.1714, 0.1496, 0.2804, 0.1793,\n",
      "        0.1689, 0.1587, 0.4046, 0.2640, 0.2269, 0.1197, 0.0792, 0.1685, 0.2431,\n",
      "        0.2376, 0.3943, 0.2082, 0.2882, 0.3054, 0.1697, 0.6538, 0.2089, 0.4949,\n",
      "        0.1946, 0.2753, 0.2057, 0.1709, 0.3561, 0.1777, 0.2548, 0.1881, 0.4168,\n",
      "        0.3601, 0.3662, 0.2457, 0.1453, 0.3339, 0.1452, 0.3096, 0.1854, 0.1601,\n",
      "        0.2572, 0.2348, 0.5462, 0.2553, 0.3780, 0.3475, 0.3271, 0.2170, 0.1212,\n",
      "        0.2595, 0.1714, 0.2363, 0.2324, 0.1754, 0.1912, 0.3014, 0.1083, 0.3951,\n",
      "        0.1904, 0.1611, 0.1993, 0.1305, 0.5457, 0.3345, 0.2814, 0.3837, 0.1300,\n",
      "        0.5456, 0.3413, 0.1755, 0.1543, 0.1563, 0.1924, 0.1834, 0.2769, 0.3805,\n",
      "        0.2040, 0.2160, 0.2131, 0.2368, 0.2172, 0.2511, 0.4527, 0.3520, 0.1457,\n",
      "        0.1143, 0.1457, 0.1905, 0.1519, 0.2187, 0.2422, 0.2006, 0.2194, 0.1662,\n",
      "        0.5053, 0.2975, 0.1569, 0.1535, 0.1530, 0.1086, 0.2280, 0.2183, 0.1456,\n",
      "        0.3725, 0.3804, 0.1758, 0.2292, 0.4069, 0.1401, 0.3999, 0.3731, 0.2352,\n",
      "        0.1223, 0.6687, 0.2997, 0.1500, 0.3031, 0.2377, 0.1625, 0.2539, 0.1370,\n",
      "        0.1585, 0.6711, 1.1271, 0.4756, 0.1658, 0.1839, 0.5162, 0.1853, 0.2970,\n",
      "        0.2338, 0.1524, 0.2585, 0.0970, 0.1815, 0.2593, 0.3884, 0.4064, 0.3183,\n",
      "        0.6117, 0.1561, 0.1927, 0.2322, 0.6175, 0.2361, 0.3205, 0.1801, 0.2248,\n",
      "        0.6124, 0.4804, 0.1669, 0.1446, 0.3474, 0.2554, 0.2693, 0.0928, 0.6590,\n",
      "        0.2371, 0.2759, 0.1856, 0.2844, 0.2767, 0.2227, 0.3852, 0.1738, 0.1902,\n",
      "        0.7988, 0.1162, 0.2656, 0.2558, 0.2452, 0.1441, 0.1343, 0.2616, 0.2539,\n",
      "        0.2197, 0.3067, 0.2528, 0.3495, 0.3071, 0.1718, 0.2872, 0.1744, 0.2166,\n",
      "        0.0972, 0.2119, 0.2303, 0.3608, 0.2274, 0.2021, 0.2418, 0.2094, 0.2050,\n",
      "        0.2806, 0.1321, 0.2850, 0.1908, 0.2457, 0.3663, 0.3173, 0.2050, 0.2514,\n",
      "        0.2800, 0.1747, 0.2212, 0.1721, 0.1713, 0.4332, 0.2107, 0.3407, 0.2763,\n",
      "        0.2493, 0.5105, 0.2440, 0.1430, 0.3913, 0.1996, 0.2121, 0.2831, 0.2557,\n",
      "        0.2377, 0.2206, 0.4150, 0.2213, 0.2210, 0.3851, 0.2754, 0.4536, 0.1933,\n",
      "        0.3147, 0.3262, 0.2819, 0.3793, 0.2159, 0.2768, 0.2435, 0.2850, 0.1561,\n",
      "        0.1693, 0.3385, 0.2841, 0.3295, 0.1639, 0.1616, 0.2096, 0.4337, 0.2588,\n",
      "        0.2412, 0.4903, 0.1685, 0.2556, 0.2401, 0.1857, 0.2684, 0.1284, 0.2292,\n",
      "        0.2095, 0.2361, 0.1093, 0.1129, 0.1683, 0.1913, 0.3241, 0.1224, 0.1465,\n",
      "        0.2709, 0.1664, 0.2443, 0.2170, 0.1282, 0.1797, 0.3012, 0.1919, 0.2803,\n",
      "        0.1292, 0.1039, 0.3087, 0.4746, 0.1421, 0.1577, 0.1613, 0.1721, 0.1253,\n",
      "        0.2876, 0.1806, 0.1684, 0.3568, 0.2039, 0.1205, 0.2229, 0.1889, 0.1728,\n",
      "        0.2419, 0.2387, 0.2502, 0.3400, 0.4540, 0.4409, 0.1544, 0.3071, 0.1914,\n",
      "        0.4072, 0.1875, 0.2177, 0.4455, 0.2414, 0.5779, 0.1616, 0.1856, 0.2917,\n",
      "        0.4956, 0.3340, 0.2757, 0.2020, 0.3985, 0.0799, 0.3755, 0.2595, 0.2793,\n",
      "        0.4673, 0.2594, 0.2160, 0.1617, 0.1552, 0.3130, 0.2213, 0.2042, 0.2445,\n",
      "        0.1166, 0.3224, 0.1782, 0.1878, 0.3246, 0.3715, 0.2338, 0.1562, 0.2512,\n",
      "        0.6185, 0.2356, 0.1625, 0.1856, 0.1996, 0.2785, 0.2104, 0.4504, 0.3273,\n",
      "        0.2113, 0.1521, 0.2279, 0.4468, 0.3959, 0.2145, 0.2268, 0.2400, 0.1839,\n",
      "        0.3760, 0.3187, 0.2059, 0.7000, 0.3043, 0.4119, 0.2599, 0.9141, 0.4442,\n",
      "        0.2128, 0.4831, 0.1918, 0.2359, 0.1869, 0.2349, 0.2101, 0.2249, 0.2737,\n",
      "        0.2119, 0.4104, 0.2055, 0.4105, 0.3278, 0.3336, 0.1851, 0.3541, 0.3158,\n",
      "        0.3363, 0.1856, 0.2627, 0.3601, 0.2198, 0.3394, 0.3559, 0.2445, 0.1603,\n",
      "        0.1958, 0.2863, 0.2382, 0.3164, 0.2597, 0.2023, 0.9287, 0.2271, 0.2927,\n",
      "        0.2666, 0.1831, 0.1110, 0.2044, 0.3921, 0.4388, 0.3343, 0.3924, 0.1803,\n",
      "        0.2836, 0.2651, 0.4843, 0.2234, 0.3000, 0.1676, 0.3252, 0.1353, 0.2554,\n",
      "        0.1542, 0.2196, 0.2685, 0.4152, 0.1585, 0.1515, 0.2945, 0.1181, 0.3235,\n",
      "        0.2758], grad_fn=<MeanBackward1>)\n",
      "[tensor([[0.5472],\n",
      "        [0.5452],\n",
      "        [0.5467],\n",
      "        [0.5496],\n",
      "        [0.5458]])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-25fbd51231fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# specify network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_every\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# specify training and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/Proteomics/TCPA-Imputation/Train_Env.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, width, sample_width, depth, variational, train_dist, test_dist, lr, n_epochs, test_every, trainbool, test_repeats)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrainbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recursive_net.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Proteomics/TCPA-Imputation/Train_Env.py\u001b[0m in \u001b[0;36mtrain_it\u001b[0;34m(self, lr)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_with_names = pd.read_csv('../data2/TCPA_data_sel.csv')\n",
    "ID, data = data_with_names.iloc[:,:2], tc.tensor(data_with_names.iloc[:,2:].values)\n",
    "\n",
    "train_dist = ((0.1,0.9))\n",
    "test_dist = (0.50)\n",
    "activations = [nn.ReLU()]\n",
    "n_epochs = 30\n",
    "test_every = 5\n",
    "width =40\n",
    "depth= 4\n",
    "variational = True\n",
    "lr = 0.0001\n",
    "sample_width = 1024\n",
    "\n",
    "train_env = Train_env(data, load_model=True)  # specify network\n",
    "train_env.train_network(width, sample_width, depth, variational, train_dist, test_dist, n_epochs=n_epochs, test_every=test_every) # specify training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normaldataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i, :].float()\n",
    "    \n",
    "\n",
    "class Mask_n():\n",
    "    def __init__(self, data, batchsize):\n",
    "        self.dataset = Normaldataset(data)\n",
    "        self.nsamples, self.nfeatures = data.shape\n",
    "        self.batchsize = batchsize\n",
    "        self.dataloader = DataLoader(self.dataset, batchsize, shuffle=False)\n",
    "        self.mask = [tc.tensor(np.random.permutation(self.nfeatures)) for _ in range(self.batchsize)]\n",
    "        self.seed = random.random()\n",
    "        \n",
    "    def get_nmasked(self, n): # müsste get_n_unmasked heißen......\n",
    "        n = self.nfeatures-n # einmal umgedreht\n",
    "        batch = next(iter(self.dataloader))\n",
    "        masked_data, target_data = batch.clone(), batch.clone()\n",
    "        for i in range(self.batchsize):\n",
    "            masked_data[i][self.mask[i][:n]] = float('nan')\n",
    "        \n",
    "        last_mask = [mask[-1] for mask in self.mask]\n",
    "        \n",
    "        return masked_data.float(), target_data.float(), last_mask\n",
    "    \n",
    "mask_n = Mask_n(data, 10)\n",
    "ind = mask_n.get_nmasked(5)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 189])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = mask_n.get_nmasked(180)\n",
    "m[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "###batched\n",
    "class MCShapley:\n",
    "    def __init__(data, net, truncation):\n",
    "        self.data = data\n",
    "        self.nsamples, self.nfeatures = data.shape\n",
    "        self.net = net\n",
    "        self.truncation = truncation\n",
    "        self.criterion = F.mse_loss\n",
    "        \n",
    "        self.phi = tc.zeros(self.nfeatures, self.n_features)        \n",
    "    \n",
    "    def step(t):\n",
    "        mask_n = Mask_n(self.data, batch_size=10)\n",
    "        jmasked,target,last_mask = mask.get_nmasked(0)\n",
    "        v_j = self.criterion(net(jmasked), target, reduction='none') \n",
    "        \n",
    "        self.v_all = self.net(mask.get_nmasked(self.nfeatures))\n",
    "        for j in range(1,self.nfeatures):\n",
    "            jmasked, target, last_mask = mask.get_nmasked(j)\n",
    "            v_j_new = self.criterion(self.net(jmasked), target, reduction='none')\n",
    "            for i in range(batch_size):\n",
    "                phi[last_mask[i],:] = (t-1)/t * phi[last_mask[i],:] + 1/t*(v_j_new[i,:]-v_j[i,:])    \n",
    "'''  \n",
    "                \n",
    "###not batched\n",
    "class MCShapley:\n",
    "    def __init__(self, data, net, truncation=0.0001):\n",
    "        self.data = data\n",
    "        self.nsamples, self.nfeatures = data.shape\n",
    "        self.net = net\n",
    "        self.truncation = truncation\n",
    "        self.criterion = F.mse_loss\n",
    "        self.t = tc.tensor([0.0]).to(device)\n",
    "        self.phi = tc.zeros(self.nfeatures, self.nfeatures).to(device)      \n",
    "        print(self.phi)\n",
    "    \n",
    "    def step(self):\n",
    "        self.t+=1\n",
    "        mask_n = Mask_n(self.data, batchsize=1)\n",
    "        jmasked,target,last_mask = mask_n.get_nmasked(0)\n",
    "        jmasked, target = jmasked.to(device), target.to(device)\n",
    "\n",
    "        full_set = mask_n.get_nmasked(self.nfeatures)[0].cuda()\n",
    "        \n",
    "        v_j = self.criterion(self.net(jmasked), target, reduction='none') \n",
    "        v_all = self.net(full_set)\n",
    "        if abs(v_all-v_j)<self.truncation:\n",
    "            continue\n",
    "            \n",
    "        for j in range(1,self.nfeatures):\n",
    "            jmasked, target, last_mask = mask_n.get_nmasked(j)\n",
    "            jmasked, target= jmasked.to(device), target.to(device)\n",
    "            \n",
    "            v_j_new = self.criterion(self.net(jmasked), target, reduction='none')\n",
    "            self.phi[last_mask,:] = (self.t-1)/self.t * self.phi[last_mask,:] + 1/self.t*(v_j_new-v_j)\n",
    "            v_j = v_j_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9c25be1de060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# specify network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#train_env.train_network(width, depth, variational, train_dist, test_dist, n_epochs=n_epochs, test_every=test_every) # specify training and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Train_env' is not defined"
     ]
    }
   ],
   "source": [
    "device = tc.device(\"cpu\")\n",
    "train_env = Train_env(data, load_model=True)  # specify network\n",
    "#train_env.train_network(width, depth, variational, train_dist, test_dist, n_epochs=n_epochs, test_every=test_every) # specify training and test\n",
    "net = train_env.net.cuda().eval()\n",
    "net.SHAP=True\n",
    "mcshapley = MCShapley(data,net,truncation = 0.001)\n",
    "for epoch in range(1000):\n",
    "    mcshapley.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def masker\n",
    "# set p, set q\n",
    "# sample a vector S (selection)\n",
    "# set X to random values where not S (scramble all rows of X where not S)\n",
    "# return with masked p\n",
    "# return without masked p\n",
    "\n",
    "# PQmat = empty_matrix\n",
    "# for p, q in len(dims)\n",
    "\n",
    "    # diffs = []\n",
    "    # while not converged ()\n",
    "        # load batch\n",
    "        # run masker(p, q)\n",
    "        # validate model (later: 3 fold)\n",
    "        # diffs.append(difference(loss(with p), loss(without p)))\n",
    "        # check convergence difference(mean(diffs-t1), mean(diffs-t0)) < epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes\n",
    "# require mask (mask hides values)\n",
    "# require X is n x d\n",
    "\n",
    "# get range e.g. r = np.arange(d)\n",
    "# repeat r (n)-times e.g. R = np.repeat\n",
    "# np.shuffle(R)\n",
    "# Xperm = X[R]\n",
    "# select where X[~mask] Xperm[mask], e.g. numpy.where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[0.4893]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4893]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tc\n",
    "device = tc.device('cpu')\n",
    "import torch.nn as nn\n",
    "import BoostNet\n",
    "import RecursiveNet\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_with_names = pd.read_csv('../data2/TCPA_data_sel.csv')\n",
    "ID, data = data_with_names.iloc[:,:2], tc.tensor(data_with_names.iloc[:,2:].values)\n",
    "\n",
    "\n",
    "train_dist = ((0.1,0.9))\n",
    "test_dist = (0.50)\n",
    "activations = [nn.ReLU()]\n",
    "n_epochs = 1\n",
    "test_every = 1\n",
    "width =20\n",
    "sample_width = 10\n",
    "depth= 5\n",
    "variational = True\n",
    "lr = 0.0001\n",
    "repeats = 3\n",
    "#make training environment\n",
    "train_env = RecursiveNet.Train_env(data, load_model=False, device=device) #use either BoostNet or RecursiveNet\n",
    "# specify and train network\n",
    "train_env.train_network(width, sample_width, depth, variational, train_dist, test_dist, lr=lr, n_epochs=n_epochs, test_every=test_every, repeats = repeats) # specify training and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapleySet(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.nsamples, self.nfeatures = data.shape\n",
    "        self.R = self.init_randomsample()\n",
    "        self.i=0\n",
    "        self.P = None\n",
    "        \n",
    "    def init_randomsample(self):\n",
    "        tensor_list = [self.data[tc.randperm(self.nsamples),i] for i in range(self.nfeatures)]\n",
    "        return tc.stack(tensor_list).t()\n",
    "\n",
    "    def getSets(self):\n",
    "        Set = tc.distributions.bernoulli.Bernoulli(tc.tensor([0.5]*self.nfeatures)).sample()\n",
    "        SetP = Set.clone()\n",
    "        Set[self.P], SetP[self.P] = 0,1\n",
    "        return Set,SetP\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nsamples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        Set, SetP = self.getSets() \n",
    "        \n",
    "        target = self.data[idx,:]\n",
    "        random_values = self.R[idx,:]\n",
    "        \n",
    "        masked_data = tc.where(Set==1, target, random_values)\n",
    "        masked_dataP = tc.where(SetP==1, target, random_values)\n",
    "\n",
    "        if self.i% self.nsamples==0:\n",
    "            self.R = self.init_randomsample()\n",
    "        self.i +=1\n",
    "\n",
    "        return target.float(), masked_data.float(), Set.float(), masked_dataP.float(), SetP.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapley():\n",
    "    def __init__(self, data, net, threshold = 0.0001):\n",
    "        self.data = data\n",
    "        self.nsamples, self.nfeatures = data.shape\n",
    "        self.net = net\n",
    "        self.shapleyset = ShapleySet(data)\n",
    "        self.shapleyvalues = tc.zeros(self.nsamples, self.nfeatures)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def calc_shapleyP(self,P):\n",
    "        self.shapleyset.P = P\n",
    "        self.shapleyloader = DataLoader(self.shapleyset, batch_size = self.nsamples)\n",
    "        t = 1\n",
    "        meandiff = tc.zeros(self.nfeatures)\n",
    "        criterion= F.mse_loss\n",
    "        proceed = True\n",
    "        \n",
    "        while proceed:\n",
    "            for target, masked_data, Set, masked_dataP, SetP in self.shapleyloader:\n",
    "                target, masked_data, Set, masked_dataP, SetP = target.to(device), masked_data.to(device), Set.to(device), masked_dataP.to(device), SetP.to(device)\n",
    "                pred, predP = self.net(masked_data, Set), self.net(masked_dataP, SetP)\n",
    "                loss, lossP = criterion(pred, target, reduction='none'), criterion(predP, target, reduction = 'none')\n",
    "\n",
    "                meanloss, meanlossP = loss.mean(dim=0).to(device), lossP.mean(dim=0).to(device)\n",
    "                meandiff = (t-1)/t * meandiff + 1/t * (meanloss - meanlossP)\n",
    "                t+=1\n",
    "                print(meandiff)\n",
    "                if t ==100:\n",
    "                    proceed = False\n",
    "                    self.shapleyvalues[P,:] = meandiff\n",
    "            \n",
    "    def calc_shapleyAll(self):\n",
    "        for P in range(self.nfeatures):\n",
    "            self.calc_shapleyP(P)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapleyset=ShapleySet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley = Shapley(data, train_env.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.6987e-03,  3.7868e-01,  3.0474e-02,  3.7497e-03, -1.1771e-02,\n",
      "        -2.4117e-02, -1.6990e-03, -3.2011e-02,  1.1242e-02, -9.3672e-04,\n",
      "         3.0170e-02, -4.1566e-02,  1.6231e-02,  1.1657e-02,  1.4959e-02,\n",
      "         9.3423e-03,  5.1097e-03, -2.2245e-02, -3.4730e-02,  6.3842e-03,\n",
      "        -1.7368e-02, -3.6369e-03,  7.1565e-03, -1.6005e-02,  3.3188e-03,\n",
      "         4.8763e-03,  1.3392e-02,  5.2462e-03, -6.4099e-03, -1.2255e-03,\n",
      "         2.1157e-03,  8.6003e-04, -8.5635e-03, -7.4694e-03, -1.8467e-03,\n",
      "        -5.4005e-03,  1.8101e-02,  5.2309e-03,  1.3220e-02,  1.2380e-02,\n",
      "         6.7932e-03,  4.6271e-03,  5.3760e-02,  1.0027e-02,  4.5924e-03,\n",
      "        -1.2245e-03,  2.4802e-03, -4.2051e-03,  2.3889e-02, -2.4209e-03,\n",
      "        -4.8846e-02,  3.2745e-03,  8.9087e-04, -2.4650e-02,  5.9516e-03,\n",
      "        -2.9113e-02, -3.2918e-03,  2.8646e-02,  2.2091e-02,  1.1073e-02,\n",
      "         1.2305e-02, -1.6324e-02,  9.4437e-03,  1.4614e-02, -1.0982e-02,\n",
      "        -3.8378e-02, -1.7920e-03, -1.2852e-02,  1.4578e-02, -3.5684e-02,\n",
      "         7.7858e-03,  7.6090e-03,  1.4539e-02, -4.0210e-03,  3.0420e-02,\n",
      "        -1.8271e-02, -1.1484e-04, -1.1846e-02,  3.4342e-02,  2.8851e-02,\n",
      "        -1.6226e-02,  9.5420e-03,  2.0619e-02,  4.7407e-03,  7.3048e-03,\n",
      "         1.5107e-02, -7.7584e-03,  9.7279e-03, -9.6714e-03,  2.3026e-02,\n",
      "         6.6081e-03,  7.7289e-04, -2.9377e-03,  8.9946e-04,  3.6982e-03,\n",
      "        -5.1223e-02, -8.7259e-03,  9.3424e-03,  2.0613e-02,  1.9082e-02,\n",
      "        -4.3987e-02, -2.8183e-03, -1.1803e-02,  1.8602e-02,  1.6312e-03,\n",
      "        -3.3314e-02, -3.3971e-02, -2.2618e-02,  7.1874e-04, -1.5051e-02,\n",
      "         2.4342e-02,  1.5540e-02,  1.2396e-02, -9.2331e-03, -3.3854e-03,\n",
      "        -3.9840e-03, -1.6604e-02, -1.3020e-02, -6.2851e-03, -2.6542e-02,\n",
      "        -5.5551e-03, -9.1492e-03, -1.8022e-02,  3.7608e-03, -3.4823e-03,\n",
      "        -1.1781e-02,  6.7935e-03,  1.2466e-02, -2.3617e-02, -5.4954e-02,\n",
      "        -8.5956e-03,  1.0643e-03,  2.8659e-02,  3.0856e-02,  1.3972e-02,\n",
      "        -8.7744e-03, -5.2512e-04, -4.7296e-03,  9.8064e-03,  7.0292e-04,\n",
      "        -3.7577e-03, -4.8122e-03, -7.5909e-03,  7.6961e-03,  2.5417e-02,\n",
      "        -1.7021e-03,  6.1809e-03,  1.7321e-03, -2.4579e-02,  9.4968e-03,\n",
      "         7.6304e-03,  3.2105e-02,  8.3465e-03, -1.9895e-02,  9.0215e-03,\n",
      "         1.6482e-02, -2.1682e-03,  6.4633e-03, -3.7686e-03,  2.8661e-03,\n",
      "        -8.3452e-03, -4.2739e-02,  5.0250e-03,  5.4551e-03,  9.0393e-03,\n",
      "        -5.7595e-03,  1.5648e-02, -1.1806e-02, -4.9248e-03, -5.5520e-03,\n",
      "        -2.4322e-04,  2.1221e-02, -1.0172e-03, -6.5591e-03, -3.9221e-02,\n",
      "        -5.5015e-03, -3.0379e-02,  1.0540e-02,  8.7363e-03, -3.1197e-04,\n",
      "         1.9693e-03, -3.5287e-03, -4.5474e-03,  4.9756e-03,  2.5157e-03,\n",
      "         3.8888e-03,  1.2819e-02, -6.2409e-03,  2.6343e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-2.4187e-03,  3.7180e-01,  1.2639e-02,  3.7255e-03,  5.7851e-04,\n",
      "        -1.5641e-02, -7.2911e-04, -1.9686e-02,  8.8362e-03, -6.3232e-03,\n",
      "         2.0373e-02,  3.9484e-02,  1.3918e-02, -9.0127e-03,  1.0611e-02,\n",
      "         1.0128e-02,  4.8236e-03, -1.7201e-02, -6.5541e-03, -2.1073e-03,\n",
      "        -1.0575e-02,  2.8311e-03,  3.9758e-03, -7.5656e-03,  6.9963e-03,\n",
      "         3.9937e-03,  6.7725e-03, -1.2272e-02,  1.6437e-03,  2.2027e-03,\n",
      "        -7.1929e-03, -2.5439e-03, -7.7510e-03, -2.7684e-03, -1.8122e-02,\n",
      "        -1.3528e-02,  1.3722e-02,  1.2327e-02,  2.7352e-03,  1.4369e-02,\n",
      "        -4.1111e-03,  1.7946e-03,  1.8417e-02,  9.6772e-03,  5.2452e-03,\n",
      "        -1.3284e-03,  5.2911e-03,  1.3393e-03,  1.2353e-02, -4.0462e-03,\n",
      "        -3.1649e-02,  3.9382e-03,  7.1934e-04, -1.7166e-02,  1.5458e-03,\n",
      "        -3.0329e-02, -1.7549e-02,  8.2824e-03,  5.8889e-03,  2.8313e-03,\n",
      "        -5.1245e-03, -1.9619e-03,  1.8371e-03,  6.6507e-03, -7.4930e-04,\n",
      "        -1.6854e-02,  4.6305e-04, -2.2032e-03,  4.9383e-03, -1.2462e-02,\n",
      "        -2.4183e-03, -3.2212e-03,  2.7154e-02,  3.4205e-02,  9.9389e-03,\n",
      "        -9.4013e-03,  1.9452e-03, -6.6032e-04,  9.1882e-03,  7.1260e-03,\n",
      "         5.5252e-03,  1.2281e-02,  1.3254e-02, -4.6916e-03,  5.0351e-03,\n",
      "         4.2125e-03,  8.9062e-03,  2.6475e-03, -1.1484e-02,  1.3798e-02,\n",
      "        -1.3907e-03,  3.4932e-03,  4.6676e-03,  2.5231e-03,  2.9132e-03,\n",
      "        -1.4062e-02, -6.2619e-03,  5.8894e-03,  7.8567e-03, -5.6091e-03,\n",
      "        -2.7987e-02, -2.7509e-02, -3.7943e-03,  7.1372e-03, -1.3527e-02,\n",
      "         1.8844e-03, -3.3257e-02, -1.1382e-02, -2.9264e-04,  1.2724e-03,\n",
      "         2.5310e-02,  5.7533e-03, -8.0787e-05, -1.7271e-03, -6.5141e-03,\n",
      "         3.7129e-03, -2.3256e-02, -3.1615e-04,  2.0293e-03, -7.7250e-03,\n",
      "        -1.5501e-03, -1.2923e-02, -2.6628e-02, -1.9478e-03,  7.9441e-03,\n",
      "        -9.6499e-03, -1.2562e-03,  7.4906e-03, -2.7248e-03, -3.4071e-02,\n",
      "        -1.5672e-03,  4.2786e-03,  1.2384e-02,  1.5834e-02,  1.4205e-02,\n",
      "        -5.4717e-03,  1.2202e-02, -5.6773e-03,  8.5514e-03, -2.4492e-03,\n",
      "         7.4813e-03, -4.0971e-03, -7.4829e-03,  3.6860e-03,  5.6772e-03,\n",
      "        -1.2932e-04,  3.9333e-04,  4.9612e-03, -3.3519e-03,  6.8186e-03,\n",
      "         9.8741e-03,  1.0324e-02,  4.5742e-04, -2.0494e-02,  5.8348e-03,\n",
      "         7.4104e-03, -3.3744e-03, -5.4423e-03,  1.1565e-03,  1.1657e-02,\n",
      "        -3.9136e-03, -2.8500e-02,  8.8499e-04,  9.9217e-03,  1.1246e-02,\n",
      "        -1.8811e-03, -2.1047e-03, -5.0827e-03, -1.6443e-02,  3.5841e-03,\n",
      "         1.0419e-02,  6.5981e-03, -9.6213e-03, -1.1865e-02,  2.5840e-03,\n",
      "         3.7743e-03, -1.6692e-02,  8.6345e-03,  4.3245e-03, -6.8317e-03,\n",
      "         2.6271e-03,  2.1482e-04,  1.1984e-03, -1.3050e-03, -6.2279e-03,\n",
      "         1.1000e-03,  2.9306e-03,  6.2342e-03,  1.1005e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-3.8660e-03,  3.6966e-01,  9.5027e-03,  2.1167e-03,  1.5605e-02,\n",
      "        -4.7472e-03, -7.0571e-03, -7.0581e-03,  7.2095e-04,  1.3285e-03,\n",
      "         1.0550e-02,  2.4356e-02,  1.1233e-03, -9.1916e-03,  2.4270e-02,\n",
      "         1.3219e-02,  1.9786e-03, -1.5441e-02, -1.4627e-03, -2.2357e-03,\n",
      "         2.9304e-04, -1.7861e-03,  8.2458e-03, -1.4665e-03,  7.9312e-03,\n",
      "         5.2301e-04,  4.2503e-04, -6.7759e-03,  7.7585e-04,  2.8430e-03,\n",
      "        -6.8125e-03, -3.6608e-03,  5.4231e-03,  5.2643e-04, -8.5039e-03,\n",
      "        -1.6446e-02,  1.1556e-02,  3.1057e-03,  7.8447e-04,  8.4947e-03,\n",
      "        -1.0064e-02,  8.1031e-04,  2.6366e-02,  6.4691e-03,  9.9055e-04,\n",
      "        -4.5819e-03, -1.2715e-03,  1.6293e-03,  5.9407e-03, -3.5278e-03,\n",
      "        -1.3538e-02,  4.7610e-03,  2.8160e-03, -5.4298e-03, -6.0430e-03,\n",
      "        -2.1708e-02, -1.3789e-02,  2.6523e-03, -1.3259e-03, -5.2207e-03,\n",
      "         7.9516e-04,  2.9657e-03,  9.2441e-04,  4.6297e-03, -3.7583e-03,\n",
      "        -1.0698e-03, -8.3482e-04, -3.4012e-03,  8.1527e-03, -8.8685e-03,\n",
      "        -8.0316e-04, -1.9186e-03,  1.4263e-02,  3.0531e-02,  2.8977e-03,\n",
      "        -9.9344e-03,  1.1463e-03, -4.4754e-04,  6.8769e-03,  4.2680e-03,\n",
      "         3.9262e-03,  1.3326e-02,  6.2790e-03, -4.9243e-03,  3.2061e-03,\n",
      "         1.5794e-03, -2.3019e-03,  2.5220e-03, -6.7640e-03,  1.6733e-02,\n",
      "        -7.0637e-03, -4.3794e-03, -1.9259e-03, -8.7877e-05,  8.5442e-04,\n",
      "         6.7157e-03, -5.9013e-03,  7.5295e-03,  9.4588e-03, -1.2226e-02,\n",
      "        -2.3627e-02, -1.7028e-02, -2.5839e-03,  4.6460e-03, -1.3122e-02,\n",
      "         1.5114e-02, -1.6013e-02, -4.4603e-03, -1.5111e-03, -3.2806e-03,\n",
      "         1.6802e-02,  4.2649e-03, -2.8749e-03,  5.3981e-03, -6.3648e-03,\n",
      "        -1.0750e-03, -2.1168e-02,  4.3196e-03, -2.5701e-03, -7.7552e-03,\n",
      "        -7.1439e-03, -1.3848e-02, -2.0475e-02,  1.2370e-03,  1.1552e-02,\n",
      "        -4.7659e-03, -1.0260e-03,  1.2138e-02,  1.3060e-02, -1.8920e-02,\n",
      "        -3.0144e-03,  2.7850e-05,  5.0717e-03,  8.0555e-03,  8.8167e-03,\n",
      "        -8.7785e-03,  6.9251e-03,  2.2230e-03,  1.1224e-02,  2.9104e-03,\n",
      "         8.0695e-03, -6.9296e-03,  1.1294e-04,  8.6744e-04, -3.5894e-03,\n",
      "        -5.8142e-03, -9.4400e-04,  4.8042e-03, -3.8969e-03,  2.5140e-03,\n",
      "         1.6744e-03,  2.9586e-03, -4.1076e-03, -1.3835e-02,  1.9890e-03,\n",
      "         1.9175e-03,  1.5544e-04, -9.3202e-03, -1.1010e-03,  5.3665e-03,\n",
      "        -3.1693e-04, -2.9767e-02,  5.4413e-03,  7.8197e-03, -5.2346e-03,\n",
      "        -1.1407e-03, -1.3326e-02, -5.0506e-03, -2.1181e-02,  1.0194e-03,\n",
      "         4.1944e-03,  1.2409e-02, -6.3214e-03, -5.7916e-03,  9.0086e-03,\n",
      "         2.4813e-03, -1.9632e-02,  8.9115e-03,  1.0525e-02,  1.8072e-03,\n",
      "         5.0674e-03,  3.2529e-03,  3.1195e-03,  1.4005e-03, -5.5678e-03,\n",
      "         1.9071e-03,  6.0486e-03, -4.9519e-03,  2.2525e-03],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4a7f5b0bae2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshapley\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_shapley\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-477687042f4c>\u001b[0m in \u001b[0;36mcalc_shapley\u001b[0;34m(self, P)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_dataP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSetP\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapleyloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_dataP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSetP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_dataP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSetP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_dataP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSetP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Proteomics/TCPA-Imputation/RecursiveNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, Mask)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#only for my readability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursivenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Proteomics/TCPA-Imputation/RecursiveNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, Mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mmean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mlog_var_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogvar_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Proteomics/TCPA-Imputation/RecursiveNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_bool\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;31m#print(get_dataloaders(data,0.3,0.1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shapley.calc_shapley(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =np.load('shapley_values')\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
